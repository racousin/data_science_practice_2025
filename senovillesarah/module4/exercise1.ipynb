{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium -q\n",
        "!apt-get update -q\n",
        "!apt-get install -y chromium-browser chromium-chromedriver -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC6RAuo2mtsI",
        "outputId": "e99723bb-b07a-4fb8-c40c-b63f1403839a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import time\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "\n",
        "train_datas_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/module4_exercise_train.zip'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/Neighborhood_Market_data.csv'\n",
        "\n",
        "def download_file(url, file_name):\n",
        "    if not os.path.exists(file_name):\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        with open(file_name, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f'Downloaded {file_name} from {url}')\n",
        "    else:\n",
        "        print(f'{file_name} already exists, skipping download.')\n",
        "\n",
        "\n",
        "download_file(train_datas_url, 'module4_exercise_train.zip')\n",
        "download_file(test_data_url, 'Neighborhood_Market_data.csv')\n",
        "\n",
        "\n",
        "os.makedirs(\"module4_exercise_train\", exist_ok=True)\n",
        "\n",
        "\n",
        "if not os.listdir(\"module4_exercise_train\"):\n",
        "    with zipfile.ZipFile(\"module4_exercise_train.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"module4_exercise_train\")\n",
        "    print(\"Extraction terminée.\")\n",
        "else:\n",
        "    print(\"Les fichiers sont déjà extraits.\")\n",
        "\n",
        "\n",
        "df_citymart = pd.read_csv(\"module4_exercise_train/CityMart_data.csv\")\n",
        "df_greenfield = pd.read_csv(\"module4_exercise_train/Greenfield_Grocers_data.csv\")\n",
        "with open(\"module4_exercise_train/HighStreet_Bazaar_data.json\", \"r\") as f:\n",
        "    data_highstreet = json.load(f)\n",
        "df_highstreet = pd.DataFrame(data_highstreet)\n",
        "df_supersaver = pd.read_excel(\"module4_exercise_train/SuperSaver_Outlet_data.xlsx\")\n",
        "df_neighborhood = pd.read_csv(\"Neighborhood_Market_data.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YyUrmCb6mxuW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21594793-faec-4a80-f386-233d07bfd0f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_citymart.columns = [c.lower() for c in df_citymart.columns]\n",
        "df_greenfield.columns = [c.lower() for c in df_greenfield.columns]\n",
        "df_highstreet.columns = [c.lower() for c in df_highstreet.columns]\n",
        "df_supersaver.columns = [c.lower() for c in df_supersaver.columns]\n",
        "df_neighborhood.columns = [c.lower() for c in df_neighborhood.columns]"
      ],
      "metadata": {
        "id": "egWRiLIXm2Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "password = \"RcUZjhdsYLRzwi4\"\n",
        "api_url = f\"https://www.raphaelcousin.com/api/exercise/{password}/prices\"\n",
        "response = requests.get(api_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    prices_dict = data.get(\"data\", data)\n",
        "    df_prices = pd.DataFrame(list(prices_dict.items()), columns=[\"item_code\", \"unit_cost\"])\n",
        "else:\n",
        "    print(\" Erreur de récupération des prix.\")"
      ],
      "metadata": {
        "id": "zJrKiyXpm5PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install selenium -q\n",
        "!apt-get update -q\n",
        "!apt-get install -y chromium-browser chromium-chromedriver -q\n",
        "\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "url = \"https://www.raphaelcousin.com/module4/scrapable-data\"\n",
        "driver.get(url)\n",
        "time.sleep(3)\n",
        "html = driver.page_source\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "driver.quit()\n",
        "\n",
        "\n",
        "tables = soup.find_all(\"table\")\n",
        "rows = []\n",
        "for row in tables[1].find(\"tbody\").find_all(\"tr\"):\n",
        "    cols = [c.get_text(strip=True) for c in row.find_all(\"td\")]\n",
        "    rows.append(cols)\n",
        "\n",
        "\n",
        "df_reviews = pd.DataFrame(rows, columns=[\"item_code\", \"customer_score\", \"total_reviews\", \"timestamp\"])\n",
        "df_reviews = df_reviews.drop(columns=[\"timestamp\"])\n",
        "df_reviews[\"customer_score\"] = pd.to_numeric(df_reviews[\"customer_score\"], errors=\"coerce\")\n",
        "df_reviews[\"total_reviews\"] = pd.to_numeric(df_reviews[\"total_reviews\"], errors=\"coerce\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9hIDjbym9R8",
        "outputId": "8428d469-4ea2-4e83-944b-6ce0613ca993"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_train = pd.concat([df_citymart, df_greenfield, df_highstreet, df_supersaver], ignore_index=True)\n",
        "\n",
        "\n",
        "df_train[\"item_code\"] = df_train[\"item_code\"].astype(str).str.strip()\n",
        "df_neighborhood[\"item_code\"] = df_neighborhood[\"item_code\"].astype(str).str.strip()\n",
        "df_prices[\"item_code\"] = df_prices[\"item_code\"].astype(str).str.strip()\n",
        "df_reviews[\"item_code\"] = df_reviews[\"item_code\"].astype(str).str.strip()\n",
        "\n",
        "\n",
        "df_train = pd.merge(df_train, df_prices, on=\"item_code\", how=\"left\")\n",
        "df_neighborhood = pd.merge(df_neighborhood, df_prices, on=\"item_code\", how=\"left\")\n",
        "df_train = pd.merge(df_train, df_reviews, on=\"item_code\", how=\"left\")\n",
        "df_neighborhood = pd.merge(df_neighborhood, df_reviews, on=\"item_code\", how=\"left\")"
      ],
      "metadata": {
        "id": "LgrLQKtmnHZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_train_all_stores = df_train.dropna(subset=[\"quantity_sold\"]).copy()\n",
        "\n",
        "\n",
        "cols_to_impute = [\"mass\", \"dimension_length\", \"dimension_width\", \"dimension_height\",\n",
        "                  \"stock_age\", \"unit_cost\", \"customer_score\", \"total_reviews\"]\n",
        "for col in cols_to_impute:\n",
        "    median_value = df_train_all_stores[col].median()\n",
        "    df_train_all_stores[col] = df_train_all_stores[col].fillna(median_value)\n",
        "\n",
        "df_train_all_stores[\"calc_volume\"] = (\n",
        "    df_train_all_stores[\"dimension_length\"] *\n",
        "    df_train_all_stores[\"dimension_width\"] *\n",
        "    df_train_all_stores[\"dimension_height\"]\n",
        ")\n",
        "\n",
        "\n",
        "df_train_encoded = pd.get_dummies(df_train_all_stores, columns=[\"store_name\"], prefix=\"store\", drop_first=True)\n",
        "\n",
        "\n",
        "features_to_keep = cols_to_impute + [\"calc_volume\"] + [col for col in df_train_encoded.columns if \"store_\" in col]\n",
        "X = df_train_encoded[features_to_keep]\n",
        "y = df_train_encoded[\"quantity_sold\"]\n",
        "\n",
        "\n",
        "model = LinearRegression()\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "mae_scores = []\n",
        "\n",
        "for train_idx, test_idx in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mae_scores.append(mae)\n",
        "\n",
        "print(\"MAE moyen du modèle linéaire :\", np.mean(mae_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GimBZnDrnMOV",
        "outputId": "c1c2bfca-3cf4-4621-9f33-bfba4f624955"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "df_neighborhood_imputed = df_neighborhood.copy()\n",
        "for col in cols_to_impute:\n",
        "    median_value = df_train_all_stores[col].median()\n",
        "    df_neighborhood_imputed[col] = df_neighborhood_imputed[col].fillna(median_value)\n",
        "\n",
        "df_neighborhood_imputed[\"calc_volume\"] = (\n",
        "    df_neighborhood_imputed[\"dimension_length\"] *\n",
        "    df_neighborhood_imputed[\"dimension_width\"] *\n",
        "    df_neighborhood_imputed[\"dimension_height\"]\n",
        ")\n",
        "\n",
        "df_neighborhood_encoded = pd.get_dummies(df_neighborhood_imputed, columns=[\"store_name\"], prefix=\"store\", drop_first=True)\n",
        "\n",
        "for col in [c for c in df_train_encoded.columns if \"store_\" in c]:\n",
        "    if col not in df_neighborhood_encoded.columns:\n",
        "        df_neighborhood_encoded[col] = 0\n",
        "\n",
        "\n",
        "X_final = df_train_encoded[features_to_keep]\n",
        "y_final = df_train_encoded[\"quantity_sold\"]\n",
        "X_test_final = df_neighborhood_encoded[features_to_keep]\n",
        "\n",
        "\n",
        "final_model = LinearRegression()\n",
        "final_model.fit(X_final, y_final)\n",
        "\n",
        "\n",
        "y_pred = final_model.predict(X_test_final)\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"item_code\": df_neighborhood[\"item_code\"],\n",
        "    \"quantity_sold\": np.round(y_pred).astype(int)\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submissionformodule4.csv\", index=False)\n",
        "print(\" submissionformodule4.csv créé :\", submission.shape)\n",
        "submission.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "46NfwFAboK4y",
        "outputId": "b0e84870-a098-4a17-c5ed-7a4630ceb0eb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
