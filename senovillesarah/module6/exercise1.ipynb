{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "1G18iawymuCP",
        "outputId": "ae896f90-8a18-4dd1-8550-017ab0474293"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "import requests\n",
        "\n",
        "\n",
        "train_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module6/exercise/module6_exercise_train.csv'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module6/exercise/module6_exercise_test.csv'\n",
        "\n",
        "\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"Downloaded {file_name} from {url}\")\n",
        "\n",
        "\n",
        "download_file(train_data_url, 'module6_exercise_train.csv')\n",
        "download_file(test_data_url, 'module6_exercise_test.csv')\n",
        "\n",
        "\n",
        "data_train = pd.read_csv('module6_exercise_train.csv', index_col=\"index\")\n",
        "data_test = pd.read_csv('module6_exercise_test.csv', index_col=\"index\")\n",
        "\n",
        "print(\"Shape train:\", data_train.shape)\n",
        "print(\"Shape test:\", data_test.shape)\n",
        "\n",
        "\n",
        "print(\"Colonnes train:\", data_train.columns.tolist()[:10], \"...\")  # aperçu\n",
        "print(\"Colonnes test:\", data_test.columns.tolist()[:10], \"...\")\n",
        "\n",
        "\n",
        "display(data_train.head())\n",
        "display(data_test.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "display(data_train.describe())\n",
        "\n",
        "\n",
        "print(\"Valeurs manquantes train:\", data_train.isnull().sum().sum())\n",
        "print(\"Valeurs manquantes test:\", data_test.isnull().sum().sum())\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data_train['end_of_day_return'], bins=50, kde=True)\n",
        "plt.title('Distribution de End-of-Day Return')\n",
        "plt.xlabel('End-of-Day Return')\n",
        "plt.ylabel('Frequencey')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "y = data_train.pop('end_of_day_return')\n",
        "X = data_train.copy()\n",
        "\n",
        "\n",
        "\n",
        "def weighted_accuracy(y_true, y_pred):\n",
        "\n",
        "    weights = np.abs(y_true)\n",
        "\n",
        "    sign_true = np.sign(y_true)\n",
        "    sign_pred = np.sign(y_pred)\n",
        "\n",
        "    correct_predictions = sign_true == sign_pred\n",
        "\n",
        "    weighted_acc = np.sum(weights * correct_predictions) / np.sum(weights)\n",
        "    return weighted_acc\n",
        "\n",
        "\n",
        "\n",
        "def plot_results(mse_train, mse_test, w_acc_train, w_acc_test):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(mse_train, label=\"Train MSE\", marker='o')\n",
        "    plt.plot(mse_test, label=\"Test MSE\", marker='o')\n",
        "    plt.title(\"MSE over Folds\")\n",
        "    plt.xlabel(\"Fold\")\n",
        "    plt.ylabel(\"MSE\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(w_acc_train, label=\"Train weighted_accuracy\", marker='o')\n",
        "    plt.plot(w_acc_test, label=\"Test weighted_accuracy\", marker='o')\n",
        "    plt.title(\"Weighted Accuracy over Folds\")\n",
        "    plt.xlabel(\"Fold\")\n",
        "    plt.ylabel(\"Weighted Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_multi_model_results(results):\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 20))\n",
        "\n",
        "    train_color = 'pink'\n",
        "    test_color = 'blue'\n",
        "\n",
        "    x = np.arange(len(results))\n",
        "    width = 0.35\n",
        "\n",
        "\n",
        "    ax1.set_title('Comparaison MSE', fontsize=16)\n",
        "    ax1.set_ylabel('MSE')\n",
        "    ax1.grid(True, alpha=0.7)\n",
        "\n",
        "\n",
        "    ax2.set_title('Weighted Accuracy Comparaison', fontsize=16)\n",
        "    ax2.set_ylabel('Weighted Accuracy')\n",
        "    ax2.grid(True, alpha=0.7)\n",
        "\n",
        "    for i, (model_name, scores) in enumerate(results.items()):\n",
        "        mse_train = scores['mse_train']\n",
        "        mse_test = scores['mse_test']\n",
        "        w_acc_train = scores['w_acc_train']\n",
        "        w_acc_test = scores['w_acc_test']\n",
        "\n",
        "\n",
        "        ax1.bar(x[i] - width/2, np.mean(mse_train), width,\n",
        "                color=train_color, alpha=0.7, label=\"Train\" if i == 0 else \"\")\n",
        "        ax1.bar(x[i] + width/2, np.mean(mse_test), width,\n",
        "                color=test_color, alpha=0.7, label=\"Test\" if i == 0 else \"\")\n",
        "\n",
        "\n",
        "        ax2.bar(x[i] - width/2, np.mean(w_acc_train), width,\n",
        "                color=train_color, alpha=0.7, label=\"Train\" if i == 0 else \"\")\n",
        "        ax2.bar(x[i] + width/2, np.mean(w_acc_test), width,\n",
        "                color=test_color, alpha=0.7, label=\"Test\" if i == 0 else \"\")\n",
        "\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(results.keys(), rotation=45, ha='right')\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels(results.keys(), rotation=45, ha='right')\n",
        "\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax2.legend(loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "HOVtWxdAm9z_",
        "outputId": "fb2a0a85-5c62-4d09-f126-4cc1000df2d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test, model):\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "\n",
        "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "\n",
        "    w_acc_train = weighted_accuracy(y_train, y_pred_train)\n",
        "    w_acc_test = weighted_accuracy(y_test, y_pred_test)\n",
        "\n",
        "    return mse_train, mse_test, w_acc_train, w_acc_test\n",
        "\n",
        "\n",
        "\n",
        "def run_multi_model_cv(X, y, models, n_splits=5):\n",
        "    fold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    results = {name: {'mse_train': [], 'mse_test': [],\n",
        "                      'w_acc_train': [], 'w_acc_test': []}\n",
        "               for name in models.keys()}\n",
        "\n",
        "    for train_index, test_index in fold.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
        "        y_train, y_test = y.iloc[train_index].copy(), y.iloc[test_index].copy()\n",
        "\n",
        "        for name, model in models.items():\n",
        "            mse_train, mse_test, w_acc_train, w_acc_test = train_and_evaluate(\n",
        "                X_train, X_test, y_train, y_test, model\n",
        "            )\n",
        "            results[name]['mse_train'].append(mse_train)\n",
        "            results[name]['mse_test'].append(mse_test)\n",
        "            results[name]['w_acc_train'].append(w_acc_train)\n",
        "            results[name]['w_acc_test'].append(w_acc_test)\n",
        "\n",
        "\n",
        "    best_mean_w_acc = -1\n",
        "    best_model = None\n",
        "\n",
        "    for name, result in results.items():\n",
        "        mean_w_acc_test = np.mean(result['w_acc_test'])\n",
        "        if mean_w_acc_test > best_mean_w_acc:\n",
        "            best_mean_w_acc = mean_w_acc_test\n",
        "            best_model = name\n",
        "\n",
        "    print(f\"meilleur modèle: {best_model} avec mean weighted accuracy {best_mean_w_acc:.4f}\")\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "baseline_models = {\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(n_jobs=-1, random_state=42)\n",
        "}\n",
        "\n",
        "\n",
        "results_baseline = run_multi_model_cv(X, y, baseline_models)\n",
        "\n",
        "\n",
        "plot_multi_model_results(results_baseline)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1jQdM0skndT2",
        "outputId": "72c040db-2cf8-453b-b302-9a16546ad24a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    from data_preprocessing import X, y, weighted_accuracy\n",
        "except ImportError:\n",
        "    print(\"WARNING: Assurez-vous que X, y, et weighted_accuracy sont disponibles dans votre environnement.\")\n",
        "    pass\n",
        "\n",
        "\n",
        "w_acc_scorer = make_scorer(weighted_accuracy, greater_is_better=True)\n",
        "\n",
        "\n",
        "rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "\n",
        "param_distributions = {\n",
        "    # On utilise sp_randint ou des listes courtes\n",
        "    'n_estimators': [200, 500, 800],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "\n",
        "cv_fold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "grid_search = RandomizedSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=20,\n",
        "    scoring=w_acc_scorer,\n",
        "    cv=cv_fold,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "\n",
        "print(\"\\n--- Résultats de la Recherche Aléatoire (Random Forest Optimisé) ---\")\n",
        "print(f\"Meilleure Weighted Accuracy CV: {grid_search.best_score_:.4f}\")\n",
        "print(f\"Meilleurs Hyperparamètres: {grid_search.best_params_}\")\n",
        "\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_lgbm_model = best_rf_model\n",
        "\n",
        "print(f\"\\nLe modèle optimisé (Random Forest) a atteint une Weighted Accuracy moyenne de {grid_search.best_score_:.4f} sur la Cross-Validation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7VAfvg3oHGx",
        "outputId": "b0afc342-733c-4ac7-a101-4f5fbd23f84a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "\n",
        "    best_params = {\n",
        "        'n_estimators': 200,\n",
        "        'max_depth': 10,\n",
        "        'min_samples_split': 5,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'log2',\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "\n",
        "    stability_pipeline = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", RandomForestRegressor(**best_params))\n",
        "    ])\n",
        "\n",
        "\n",
        "    w_acc_scorer = make_scorer(weighted_accuracy, greater_is_better=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    cv_scores = cross_val_score(\n",
        "        estimator=stability_pipeline,\n",
        "        X=X,\n",
        "        y=y,\n",
        "        scoring=w_acc_scorer,\n",
        "        cv=5,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "\n",
        "    mean_score = np.mean(cv_scores)\n",
        "    std_dev = np.std(cv_scores)\n",
        "\n",
        "\n",
        "    print(f\"Scores par fold (Weighted Accuracy): {cv_scores}\")\n",
        "    print(f\"Score Moyen CV: {mean_score:.4f}\")\n",
        "    print(f\"Écart-type des scores: {std_dev:.4f}\")\n",
        "\n",
        "\n",
        "    if std_dev < 0.01:\n",
        "        print(\"Très bien\")\n",
        "    elif std_dev < 0.03:\n",
        "        print(\"Ca va \")\n",
        "    else:\n",
        "        print(\"TERRIBLE\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"Erreur: Assurez-vous que X, y, et weighted_accuracy sont définis.\")\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s65_r0pZs1EB",
        "outputId": "7d05e809-f4f2-45fe-d3dc-d9908310dcfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "final_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", RandomForestRegressor(\n",
        "        n_estimators=200,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=1,\n",
        "        max_features='log2',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "\n",
        "final_pipeline.fit(X, y)\n",
        "\n",
        "\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module6/exercise/module6_exercise_test.csv'\n",
        "X_test = pd.read_csv('module6_exercise_test.csv', index_col='index')\n",
        "\n",
        "\n",
        "y_pred_test = final_pipeline.predict(X_test)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'index': X_test.index,\n",
        "    'end_of_day_return': y_pred_test\n",
        "})\n",
        "\n",
        "submission.to_csv('submission_module6.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ruB_k3edquW4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
