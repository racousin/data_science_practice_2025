{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca9a2cb9-0f35-4cc4-a7f3-e7c579bab4dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52fdfdbf-f191-4b95-ae21-aa2d6e3bec3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# URLs of the files\n",
        "train_datas_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/module4_exercise_train.zip'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/Neighborhood_Market_data.csv'\n",
        "\n",
        "# Function to download a file\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure we notice bad responses\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "# Downloading the files\n",
        "download_file(train_datas_url, 'module4_exercise_train.zip')\n",
        "download_file(test_data_url, 'Neighborhood_Market_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93fcfb1-8ce0-4af6-b6c7-0ec6212c4621",
      "metadata": {},
      "source": [
        "## 1) Load and combine data from multiple sources (files, API, web scraping)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9384d31d-3fd2-493e-b16d-10d72f9e53cc",
      "metadata": {},
      "source": [
        " #### CityMart_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74bc8f6d-1738-4b68-8707-aa05bc9951c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# read\n",
        "df_CityMart_data =  pd.read_csv(\"CityMart_data.csv\", sep=\",\", index_col='item_code')\n",
        "df_CityMart_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8234d465-9047-43e2-97b2-c6e4f5398a39",
      "metadata": {},
      "source": [
        "#### Greenfield_Grocers_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6563ec5-4fb9-4bd2-a250-cf6e1ef978d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# read\n",
        "df_Greenfield_Grocers_data = pd.read_csv(\"Greenfield_Grocers_data.csv\", sep='|', skiprows=2)\n",
        "df_Greenfield_Grocers_data.columns = df_Greenfield_Grocers_data.iloc[0]\n",
        "df_Greenfield_Grocers_data = df_Greenfield_Grocers_data[1:] \n",
        "\n",
        "# Nettoyer les noms de colonnes (les transformer en chaînes)\n",
        "df_Greenfield_Grocers_data.columns = df_Greenfield_Grocers_data.columns.astype(str).str.strip()\n",
        "\n",
        "# Supprimer les colonnes '1.0', 'nan', ou 'Unnamed'\n",
        "cols_to_drop = [col for col in df_Greenfield_Grocers_data.columns if col in ['1.0', 'nan'] or col.startswith('Unnamed')]\n",
        "df_Greenfield_Grocers_data.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "df_Greenfield_Grocers_data.set_index('ITEM_CODE', inplace=True)\n",
        "\n",
        "# Renommer l’index\n",
        "df_Greenfield_Grocers_data.index.name = 'item_code'\n",
        "\n",
        "# Ecrire les noms de colonne en minuscule\n",
        "df_Greenfield_Grocers_data.columns = [col.lower() for col in df_Greenfield_Grocers_data.columns]\n",
        "\n",
        "df_Greenfield_Grocers_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "658c2d93-2a3e-4ad3-8bc0-5025c298ce86",
      "metadata": {},
      "source": [
        "#### Neighborhood_Market_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8af265b5-c8f6-4453-a49a-324d1887d775",
      "metadata": {},
      "outputs": [],
      "source": [
        "# read\n",
        "df_Neighborhood_Market_data =  pd.read_csv(\"Neighborhood_Market_data.csv\", sep=\",\", index_col = 'item_code')\n",
        "df_Neighborhood_Market_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ac5cd82-0af2-4fdd-8228-bad1c0d7ca04",
      "metadata": {},
      "source": [
        "#### HighStreet_Bazaar_data.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b4894ae-3246-4739-8aa4-ccf82888de98",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_HighStreet_Bazaar_data = pd.read_json('HighStreet_Bazaar_data.json', orient='records')\n",
        "df_HighStreet_Bazaar_data.set_index('item_code', inplace=True)\n",
        "df_HighStreet_Bazaar_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92e65433-dce9-4ecf-8d64-cc66633da284",
      "metadata": {},
      "source": [
        "#### SuperSaver_Outlet_data.xlsx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "735fe413-efc3-4db6-9413-f0cb8da1a4d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lire un fichier excel\n",
        "df_SuperSaver_Outlet_data_b =  pd.read_excel(\"SuperSaver_Outlet_data.xlsx\", sheet_name=None)\n",
        "df_SuperSaver_Outlet_data_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3bc0464-5cd2-410a-90d6-2473b89d7ef5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lire les deux feuilles du classeur\n",
        "df_sheet1 = df_SuperSaver_Outlet_data_b[\"Quantity\"]\n",
        "df_sheet2 = df_SuperSaver_Outlet_data_b[\"Info\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd466c51-b60c-4aff-a0d5-e210bfefcc27",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sheet1.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f560397-125b-469f-bad2-eb0ccb474081",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sheet2.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b2d642-1003-4b36-93ce-d803c0d000ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# suppression des entêtes\n",
        "df_sheet2.columns = range(df_sheet2.shape[1])\n",
        "\n",
        "# Attribution des noms\n",
        "df_sheet2.columns = [\n",
        "    \"item_code\",\n",
        "    \"store_name\",\n",
        "    \"mass\",\n",
        "    \"dimension_length\",\n",
        "    \"dimension_width\",\n",
        "    \"dimension_height\",\n",
        "    \"days_since_last_purchase\",\n",
        "    \"package_volume\",\n",
        "    \"stock_age\",\n",
        "    \"supp\"  \n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "932b149a-cdab-4015-b0dc-5b063bb840b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sheet2.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd00588f-8d18-47a3-85dc-5d9fcd7616ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sheet2.drop(columns=[\"supp\"], errors=\"ignore\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d69896e-2ff3-410b-adee-6b5d8b52d755",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sheet2.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77b4e0f1-51e4-4e10-8524-249f1854cf69",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_SuperSaver_Outlet_data = pd.merge(df_sheet2, df_sheet1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3e25701-abc2-48bf-b3cf-81ded414a87f",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_SuperSaver_Outlet_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "004bfe99-c300-4484-b885-8981cb803b11",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_SuperSaver_Outlet_data.set_index('item_code', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb0e14c0-6d5c-4b8a-83a5-fc88a7644497",
      "metadata": {},
      "source": [
        "#### Agregate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18a09411-0358-46ba-9335-63318919bc10",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.concat([df_CityMart_data, df_Greenfield_Grocers_data, df_Neighborhood_Market_data, df_HighStreet_Bazaar_data, df_SuperSaver_Outlet_data], axis=0)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82800581-caea-46b2-b319-ad7120a09c39",
      "metadata": {},
      "source": [
        "#### API source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1878df38-ae4c-4418-af78-ac72ba6cc15d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Récupere les output des endpoints qui sont des dictionnaires\n",
        "def get_api(endpoint_url):\n",
        "    try:\n",
        "        # Make the GET request to the mock API\n",
        "        response = requests.get(endpoint_url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            print(data[\"message\"])\n",
        "            return data['data']\n",
        "        else:\n",
        "            print(f\"Failed to retrieve volume data. Status code: {response.status_code}\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "password = get_api(\"https://www.raphaelcousin.com/api/exercise/auth\")[\"password\"]\n",
        "print(password)\n",
        "prices = get_api(f\"https://www.raphaelcousin.com/api/exercise/{password}/prices\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30bee1dd-09ec-4e07-9a34-e1e8aae44cb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertion d'un dictionnaire en dataframe\n",
        "# orient='index' : indique que les clés du dictionnaire deviendront les index du DataFrame\n",
        "#columns=['price'] : nom de la colonne contenant les valeurs du dictionnaire\n",
        "\n",
        "df_prices = pd.DataFrame.from_dict(prices, orient='index', columns=['unit_cost'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9261bbc9-d102-48d8-8683-15ab8f4882fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_prices.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1fe80dd-4e60-4e7d-891e-adfd7dded092",
      "metadata": {},
      "source": [
        "#### Aggregate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfdbd639-cb2e-47f5-8c06-123d6c10f4b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.merge(data, df_prices, left_index=True, right_index=True, how='left')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cc37e6c-eaff-4975-b78e-f0c9921c96d5",
      "metadata": {},
      "source": [
        "#### Scrapping sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e80583f5-5563-4cd5-83d2-a832cb985a55",
      "metadata": {},
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Permet de lancer un moteur de recherche\n",
        "# Set up the Selenium WebDriver (e.g., Chrome)\n",
        "driver = webdriver.Chrome()  # Make sure ChromeDriver is installed\n",
        "# driver = webdriver.Firefox()\n",
        "# driver = webdriver.Edge()\n",
        "# driver = webdriver.Safari()\n",
        "\n",
        "# Open the URL\n",
        "url = 'https://www.raphaelcousin.com/module4/scrapable-data'\n",
        "driver.get(url)\n",
        "\n",
        "# Wait for the page to fully load (increase time if needed)\n",
        "time.sleep(5)\n",
        "\n",
        "# Get the fully rendered page source\n",
        "html = driver.page_source\n",
        "\n",
        "# Parse the HTML with BeautifulSoup\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# Initialize lists to store scraped data\n",
        "exercise_data = []\n",
        "\n",
        "# Charge tous les tableaux numeroté de 0,1,2, etc\n",
        "# Find both tables\n",
        "tables = soup.find_all('table')\n",
        "\n",
        "# Close the Selenium WebDriver\n",
        "driver.quit()\n",
        "\n",
        "# On recupere les données des colonnes du tableau 1 qu'on veut stocker en attribuant les mêmes noms que la page web\n",
        "# Scrape the first table (Course Data)\n",
        "course_table = tables[1]\n",
        "for row in course_table.find('tbody').find_all('tr'):\n",
        "    cols = row.find_all('td')\n",
        "    exercise_data.append({\n",
        "        'item_code': cols[0].text,\n",
        "        'customer_score': int(cols[1].text),\n",
        "        'total_reviews': int(cols[2].text),\n",
        "        # 'Updated Timestamp': cols[3].text\n",
        "    })\n",
        "\n",
        "# Convert the lists to pandas DataFrames\n",
        "df_course_exo = pd.DataFrame(exercise_data)\n",
        "df_course_exo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79f381a-8484-4d2f-bd2d-6ee73ca123a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_course_exo.set_index('item_code', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30fa08ee-8627-47ab-8b7c-e823fdc10401",
      "metadata": {},
      "source": [
        "#### Aggregate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "220fd61c-94e7-4878-93b9-9fb96fb18090",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.merge(data, df_course_exo, left_index=True, right_index=True, how='left')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c95cad78-ba69-49a3-9a5b-ad10e039e61c",
      "metadata": {},
      "source": [
        "## 2) Perform exploratory data analysis (EDA) on the combined dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7a80fb-be3b-4693-800f-3d761cf3a3a6",
      "metadata": {},
      "source": [
        "### Comprehension des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "255c851a-0865-433d-9645-071e3cc4cb6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Aperçu du dataset\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e816f4df-8095-4d14-a8ec-b709a078cfb5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affichage des 10 premières lignes\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec4fcf8-2e89-45a8-81f2-1590826f17de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affichage des 10 dernières lignes\n",
        "data.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6051028-7f50-4887-a6a4-edb2c408dc60",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affichage aléatoire de 10 lignes\n",
        "data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed568049-9675-412a-86ad-9c523cd1ee08",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Info générale sur le data\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f73d3cdf-5f9d-4e79-bd97-4bda7dddeee7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affichage des types des variables\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f2d6054-9d26-4b7b-9e69-99458e7c9905",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction pour un nettoyage partiel des données\n",
        "def dataClean(df):\n",
        "    # Colonnes numériques potentielles\n",
        "    num_cols = [\n",
        "        'mass', 'dimension_length', 'dimension_width', 'dimension_height',\n",
        "        'days_since_last_purchase', 'package_volume', 'stock_age',\n",
        "        'quantity_sold', 'unit_cost', 'customer_score', 'total_reviews'\n",
        "    ]\n",
        "\n",
        "    # Colonnes réellement présentes\n",
        "    existing_cols = [col for col in num_cols if col in df.columns]\n",
        "\n",
        "    # Convertir les colonnes numériques en float\n",
        "    df[existing_cols] = df[existing_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # Remplacer les NaN par la moyenne\n",
        "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "    # Supprimer les outliers si 'quantity_sold' existe\n",
        "    #if 'quantity_sold' in df.columns:\n",
        "     #   Q1 = df['quantity_sold'].quantile(0.25)\n",
        "      #  Q3 = df['quantity_sold'].quantile(0.75)\n",
        "       # IQR = Q3 - Q1\n",
        "     #   lower = Q1 - 1.5 * IQR\n",
        "     #   upper = Q3 + 1.5 * IQR\n",
        "      #  df = df[(df['quantity_sold'] >= lower) & (df['quantity_sold'] <= upper)]\n",
        "\n",
        "    # Supprimer les colonnes inutiles si elles existent\n",
        "    df.drop(columns=[\"last_modified\", \"store_name\"], errors=\"ignore\", inplace=True)\n",
        "\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17453e77-49c9-4147-8bf3-de2823d5e2d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = dataClean(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "845f3c60-3aee-448e-8fe6-93cbd15fc1d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "811e80a5-ef64-4422-ab4c-e2acdf57b2f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Résumer sur les variables\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1042138-7e64-492f-b28f-767d71ea04a8",
      "metadata": {},
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494ab67b-66c5-4c25-971e-a5b5646d1f75",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Les valeurs manquantes\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c571aa50-448f-4f57-b8e4-38ed1a89a0da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affichage des lignes ayant les valeurs manquantes\n",
        "data[data.isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dcb64cf-5074-45b6-a580-a2bc238763e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nombre de lignes dupliquées\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e3c72b-a86c-4e43-b0ac-4c72246a787b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affichage des lignes dupliquées\n",
        "data[data.duplicated(keep=False)].sort_values(by=data.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcdc2f1d-5098-409d-a637-c50f5bc4e5d2",
      "metadata": {},
      "source": [
        "## Comprendre les features univariés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9fa3b7-d2aa-4c32-9944-ac1dfac00974",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histogramme pour tous les features numériques\n",
        "data.hist(figsize=(10,8))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b47c0038-5262-46aa-a51f-ba0f90bccde4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detection des outliers\n",
        "\n",
        "# Box plots for numerical variables to check outliers\n",
        "print(\"\\nBox plots to check for outliers:\")\n",
        "#numeric_cols = [\"unit_cost\", \"customer_score\", \"total_reviews\"]\n",
        "\n",
        "# Sélection automatique des colonnes numériques\n",
        "numeric_cols = data.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# Set up the plot grid\n",
        "n_cols = 2\n",
        "n_rows = int(np.ceil(len(numeric_cols) / n_cols))\n",
        "\n",
        "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(8, n_rows*6))\n",
        "fig.tight_layout(pad=4.0)\n",
        "\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    row = i // n_cols\n",
        "    col_pos = i % n_cols\n",
        "    sns.boxplot(x=data[col], ax=axes[row, col_pos])\n",
        "    axes[row, col_pos].set_title(f'Box plot of {col}')\n",
        "\n",
        "# Remove empty subplots if the number of columns is odd\n",
        "if len(numeric_cols) % n_cols != 0:\n",
        "    for j in range(len(numeric_cols), n_rows * n_cols):\n",
        "        fig.delaxes(axes.flatten()[j])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6b6185f-9280-40b8-b7ad-bebf77ed2066",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "print(\"\\nCorrelation matrix:\")\n",
        "#corr_matrix = data.corr()\n",
        "corr_matrix = data.corr(numeric_only=True)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4c6c455-5f45-4608-99bc-28c66bd2c0af",
      "metadata": {},
      "source": [
        "### Simple baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3565048-7479-418e-a1fe-64f4a6e45138",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "def get_simple_baseline(data, fillna_value=-1, drop_cols=None, k_fold=5, scaler='standard', model='linear', metric='mae', target_col=None, X_data_test=None):\n",
        "    \n",
        "    data = data.copy()\n",
        "    # Handle missing values\n",
        "    data.fillna(fillna_value, inplace=True)\n",
        "    if X_data_test is not None:\n",
        "        X_data_test = X_data_test.copy()\n",
        "        X_data_test.fillna(fillna_value, inplace=True)\n",
        "    \n",
        "    # Drop unwanted columns\n",
        "    if drop_cols:\n",
        "        data.drop(drop_cols, axis=1, inplace=True)\n",
        "        if X_data_test is not None:\n",
        "            X_data_test.drop(drop_cols, axis=1, inplace=True)\n",
        "\n",
        "    # Split data into features (X) and target (y)\n",
        "    y = data[target_col]\n",
        "    X = data.drop(target_col, axis=1)\n",
        "\n",
        "    # Feature scaling\n",
        "    if scaler == 'standard':\n",
        "        scaler = StandardScaler()\n",
        "    elif scaler == 'minmax':\n",
        "        scaler = MinMaxScaler()\n",
        "    else:\n",
        "        scaler = None\n",
        "    \n",
        "    if scaler:\n",
        "        X = scaler.fit_transform(X)\n",
        "        if X_data_test is not None:\n",
        "            X_data_test = scaler.transform(X_data_test)\n",
        "\n",
        "    # Initialize the model\n",
        "    if model == 'linear':\n",
        "        model = LinearRegression()\n",
        "    elif model == 'logistic':\n",
        "        model = LogisticRegression()\n",
        "    elif model == 'random_forest':\n",
        "        model = RandomForestClassifier()\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model type\")\n",
        "\n",
        "    # Initialize cross-validation\n",
        "    kf = KFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    # Train and evaluate using k-fold cross-validation\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # Evaluate using the specified metric\n",
        "        if metric == 'mae':\n",
        "            score = mean_absolute_error(y_test, y_pred)\n",
        "        elif metric == 'accuracy':\n",
        "            score = accuracy_score(y_test, np.round(y_pred))\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported metric\")\n",
        "\n",
        "        scores.append(score)\n",
        "\n",
        "    if X_data_test is not None:\n",
        "        model.fit(X, y)\n",
        "        return np.mean(scores), model.predict(X_data_test)\n",
        "    \n",
        "    # Return the average score\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9bd9fb9-54c2-4b88-90e3-dfa88b6ac493",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrainement du model\n",
        "supp =['mass', 'dimension_length', 'dimension_width', 'dimension_height','days_since_last_purchase', 'stock_age']\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2fbf906-ff8e-4e2e-a06f-f2f70fdebbff",
      "metadata": {},
      "outputs": [],
      "source": [
        "get_simple_baseline(data, drop_cols=supp, k_fold=5, scaler='standard', model='linear', metric='mae', target_col='quantity_sold')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47f7505b-59d4-4783-8c83-7367eb38e3d7",
      "metadata": {},
      "source": [
        "# Get test data and Predict baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7385fcdb-8370-4876-8217-e50d89a4f13a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# read\n",
        "df_StoreE =  pd.read_csv(\"Neighborhood_Market_data.csv\", sep=\",\", index_col='item_code')\n",
        "df_StoreE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ec36a71-7423-4a63-a86e-3d3707beb9fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# On ajoute les colonnes de df_volumes et df_course\n",
        "df_StoreE = pd.merge(df_StoreE, df_prices, left_index=True, right_index=True, how='left')\n",
        "df_StoreE = pd.merge(df_StoreE, df_course_exo, left_index=True, right_index=True, how='left')\n",
        "df_StoreE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ddbcdcd-da1a-4f78-83b9-68615dc2c2f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_StoreE = dataClean(df_StoreE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3611769-af86-479b-bb5f-789871f87777",
      "metadata": {},
      "outputs": [],
      "source": [
        "_, y_pred = get_simple_baseline(data,\n",
        "                    fillna_value=-1,\n",
        "                    drop_cols=supp,\n",
        "                    k_fold=5,\n",
        "                    scaler='standard',\n",
        "                    model='linear',\n",
        "                    metric='mae',\n",
        "                    target_col='quantity_sold',\n",
        "                    X_data_test=df_StoreE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c3535d-47be-46d2-805c-31004d0dfa23",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1b4594-db85-4671-a60d-0b2d7f57aa5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "    'item_code': df_StoreE.index,\n",
        "    'quantity_sold': y_pred # your_prediction\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False, sep=',')\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241543e4-335d-4cc4-8f40-31c6fd62e5b6",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e98658-15aa-4b24-affd-20c7563d4438",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
