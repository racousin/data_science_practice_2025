import random

class Agent:
    # Constante pour la tolÃ©rance des flottants
    Q_TOLERANCE = 1e-6
    DEFAULT_ACTION = 0

    def __init__(self, env):
        self.jeu_environnement = env
        
        self.politique_reference = [[0.37982205 , 0.38120805, 0.38129605, 0.38198705], [0.38768605, 0.39383405, 0.39678905, 0.39216805], [0.40126305, 0.39391905, 0.41157705, 0.40427805], [0.41209905, 0.42378805, 0.42839305, 0.41851005], [0.43932105, 0.43719305, 0.44680705, 0.43564105], [0.46194705, 0.43749705, 0.47756805, 0.47008705], [0.48972405, 0.49168705, 0.50789105, 0.50056105], [0.50882605, 0.49532705, 0.52197505, 0.50777205], [0.37279205, 0.37856905, 0.37278305, 0.38057005], [0.37841905, 0.37911005, 0.38861605, 0.39086105], [0.37890105, 0.38472305, 0.38949105, 0.40777005], [0.30609205, 0.27126105, 0.19267705, 0.42503205], [0.42457305, 0.42443905, 0.43024505, 0.44788305], [0.46208405, 0.46709005, 0.47514605, 0.48498505], [0.50374205, 0.50555605, 0.51197805, 0.49541405], [0.51993605, 0.52410505, 0.53558305, 0.51207905], [0.36373105, 0.35704105, 0.36604805, 0.36827405], [0.36779705, 0.35771705, 0.36227305, 0.37224205], [0.36007105, 0.20300305, 0.21238605, 0.28884405], [0.00000005, 0.00000005, 0.00000005, 0.00000005], [0.16520705, 0.26189005, 0.39798705, 0.31324005], [0.24477305, 0.31085505, 0.34271905, 0.40962105], [0.48539105, 0.50853705, 0.50918305, 0.50561805], [0.54613405, 0.53650305, 0.55499605, 0.53303205], [0.34697905, 0.33118405, 0.34546105, 0.35248605], [0.31750305, 0.31010905, 0.32791705, 0.33950505], [0.29461605, 0.28433105, 0.22326105, 0.30175805], [0.12413205, 0.19764005, 0.04423105, 0.21145805], [0.27847005, 0.18401305, 0.20684805, 0.15530905], [0.00000005, 0.00000005, 0.00000005, 0.00000005], [0.25391705, 0.31449305, 0.50928805, 0.39108605], [0.54856605, 0.56727605, 0.58816405, 0.55128705], [0.30224905, 0.29091505, 0.31125705, 0.32087305], [0.25623105, 0.16441305, 0.18738205, 0.28932105], [0.15205305, 0.04332905, 0.13713405, 0.18496205], [0.00000005, 0.00000005, 0.00000005, 0.00000005], [0.15349405, 0.16745205, 0.23180405, 0.19930205], [0.13382305, 0.30548605, 0.26470805, 0.20358805], [0.15801705, 0.35627005, 0.30830805, 0.44046905], [0.55775505, 0.62241305, 0.64386405, 0.58857405], [0.27929405, 0.15310605, 0.22982705, 0.20437805], [0.00000005, 0.00000005, 0.00000005, 0.00000005], [0.00000005, 0.00000005, 0.00000005, 0.00000005], [0.00394605, 0.05527005, 0.06525705, 0.06779705], [0.12266405, 0.09387605, 0.15439505, 0.15934405], [0.18602205, 0.08813805, 0.12862505, 0.16266205], [0.00000005, 0.00000005, 0.00000005, 0.00000005], [0.55199805, 0.65393905, 0.71316305, 0.45725705], [0.26178305, 0.14002805, 0.18017805, 0.22238805], [0.00000005, 0.00000005, 0.00000005, 0.00000005], [0.01848205, 0.00597005, 0.01352105, 0.00094105], [0.01914405, 0.00129605, 0.00772205, 0.02424005], [0.00000005, 0.00000005, 0.00000005, 0.00000005], [0.06991305, 0.03243905, 0.10077905, 0.08485005], [0.00000005, 0.00000005, 0.00000005, 0.00000005], [0.60985205, 0.81818405, 0.91050205, 0.41261805], [0.25791205, 0.22596405, 0.23532405, 0.20154705], [0.14447305, 0.18208605, 0.09843205, 0.09591005], [0.08118205, 0.05015805, 0.02626805, 0.04798105], [0.00000005, 0.00000005, 0.00000005, 0.00000005], [0.00080905, 0.00907805, 0.00102805, 0.00166305], [0.02416705, 0.06492205, 0.08572705, 0.05538405], [0.02692305, 0.23448405, 0.19660705, 0.19000005], [0.00000005, 0.00000005, 0.00000005, 0.00000005]]
        
        self.nombre_etats = len(self.politique_reference) 
        self.nombre_actions = len(self.politique_reference[0]) if self.nombre_etats > 0 else env.action_space.n

    def choose_action(self, observation, reward=0.0, terminated=False, truncated=False, info=None):
        etat_courant_idx = int(observation)

        if etat_courant_idx < 0 or etat_courant_idx >= self.nombre_etats:
            return self.DEFAULT_ACTION

        valeurs_q_etat = self.politique_reference[etat_courant_idx]
        valeur_q_maximale = max(valeurs_q_etat)
    
        actions_optimales = []
        for index_action, valeur_q in enumerate(valeurs_q_etat):
            if abs(valeur_q - valeur_q_maximale) < self.Q_TOLERANCE:
                actions_optimales.append(index_action)
        if actions_optimales:
            return actions_optimales[0]
        else:
            return self.DEFAULT_ACTION