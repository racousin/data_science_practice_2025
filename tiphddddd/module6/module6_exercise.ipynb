{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fd09113-2f55-43ea-914c-ab3c0e3ee3d1",
      "metadata": {
        "id": "0fd09113-2f55-43ea-914c-ab3c0e3ee3d1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge, RidgeClassifier\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, BaggingRegressor, StackingRegressor, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.base import RegressorMixin, ClassifierMixin, BaseEstimator\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from lightgbm import LGBMClassifier, LGBMRegressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80dc69a1-e21d-4310-a0a4-5cb5b7d69fb4",
      "metadata": {
        "id": "80dc69a1-e21d-4310-a0a4-5cb5b7d69fb4"
      },
      "source": [
        "### Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae3aeb5-dcdf-4690-b869-d211a02f303c",
      "metadata": {
        "id": "fae3aeb5-dcdf-4690-b869-d211a02f303c",
        "outputId": "47fd89c0-5abc-4ccf-839c-2b1e5f3ff351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# URLs of the files\n",
        "train_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module6/exercise/module6_exercise_train.csv'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module6/exercise/module6_exercise_test.csv'\n",
        "\n",
        "# Function to download a file\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure we notice bad responses\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "# Downloading the files\n",
        "download_file(train_data_url, 'module6_exercise_train.csv')\n",
        "download_file(test_data_url, 'module6_exercise_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83ae6bb0-639c-472a-8748-4bbbdb96e142",
      "metadata": {
        "id": "83ae6bb0-639c-472a-8748-4bbbdb96e142"
      },
      "outputs": [],
      "source": [
        "data_train = pd.read_csv('module6_exercise_train.csv', index_col='index')\n",
        "data_test = pd.read_csv('module6_exercise_test.csv', index_col='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea77dab9-6dcc-42bc-894b-1d8a23774d33",
      "metadata": {
        "id": "ea77dab9-6dcc-42bc-894b-1d8a23774d33"
      },
      "source": [
        "### Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a92c5579-a099-4018-a22e-06513a885133",
      "metadata": {
        "id": "a92c5579-a099-4018-a22e-06513a885133",
        "outputId": "aa3b725a-1ae4-470f-b904-004b0ae3f975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "outputs": [],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead6e347-8a41-489d-a184-98d4259ff9be",
      "metadata": {
        "id": "ead6e347-8a41-489d-a184-98d4259ff9be",
        "outputId": "50132d3b-7c65-4d86-ae00-895e0c971c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "outputs": [],
      "source": [
        "data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d62d9ab-50b9-4d5b-9611-adbd10840ae5",
      "metadata": {
        "id": "4d62d9ab-50b9-4d5b-9611-adbd10840ae5",
        "outputId": "b12e9e46-200f-40e4-f6cf-be39a38f8689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "outputs": [],
      "source": [
        "data_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5babb7-ad30-43eb-b3ec-4eebca726764",
      "metadata": {
        "id": "6b5babb7-ad30-43eb-b3ec-4eebca726764",
        "outputId": "7397f41c-445b-408a-a934-ce73013ab286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "outputs": [],
      "source": [
        "data_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e5dd21-1d73-415c-a4a7-c1c869ded46b",
      "metadata": {
        "id": "56e5dd21-1d73-415c-a4a7-c1c869ded46b",
        "outputId": "e5f8e1d0-9748-4527-c46a-af915344afd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        }
      },
      "outputs": [],
      "source": [
        "data_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314189f7-31bb-47a9-afca-97d9ec489b60",
      "metadata": {
        "id": "314189f7-31bb-47a9-afca-97d9ec489b60",
        "outputId": "c1d67c6d-d8e5-4f72-d5e1-2dae219ede68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "outputs": [],
      "source": [
        "# Plot the distribution using seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data_train['end_of_day_return'], bins=50, kde=True)\n",
        "plt.title('Distribution of End of Day Return')\n",
        "plt.xlabel('End of Day Return')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab85a4fe-b7d4-47f7-9d4a-4a155c44e24c",
      "metadata": {
        "id": "ab85a4fe-b7d4-47f7-9d4a-4a155c44e24c"
      },
      "source": [
        "### Model Building and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a86f0e4-55fa-46a9-8f53-735cf62aa6ff",
      "metadata": {
        "id": "6a86f0e4-55fa-46a9-8f53-735cf62aa6ff"
      },
      "outputs": [],
      "source": [
        "y = data_train.pop('end_of_day_return')\n",
        "X = data_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "746ed3ab-0de5-4c35-94aa-76251187dede",
      "metadata": {
        "id": "746ed3ab-0de5-4c35-94aa-76251187dede"
      },
      "outputs": [],
      "source": [
        "def weighted_accuracy(y_true, y_pred):\n",
        "    weights = np.abs(y_true)\n",
        "\n",
        "    # Compute the sign of true and predicted values\n",
        "    sign_true = np.sign(y_true)\n",
        "    sign_pred = np.sign(y_pred)\n",
        "\n",
        "    # Correct predictions where the sign of the true and predicted values match\n",
        "    correct_predictions = sign_true == sign_pred\n",
        "\n",
        "    # Compute the weighted accuracy\n",
        "    weighted_acc = np.sum(weights * correct_predictions) / np.sum(weights)\n",
        "\n",
        "    return weighted_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04424025-b909-46d3-af2d-0e7d6fb9107b",
      "metadata": {
        "id": "04424025-b909-46d3-af2d-0e7d6fb9107b"
      },
      "outputs": [],
      "source": [
        "# Function to plot the evaluation results\n",
        "def plot_results(mse_train, mse_test, w_acc_train, w_acc_test):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # MSE plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(mse_train, label=\"Train MSE\", marker='o')\n",
        "    plt.plot(mse_test, label=\"Test MSE\", marker='o')\n",
        "    plt.fill_between(range(len(mse_train)), np.min(mse_train), np.max(mse_train), color='blue', alpha=0.1)\n",
        "    plt.fill_between(range(len(mse_test)), np.min(mse_test), np.max(mse_test), color='orange', alpha=0.1)\n",
        "    plt.title(\"MSE over Folds\")\n",
        "    plt.xlabel(\"Fold\")\n",
        "    plt.ylabel(\"MSE\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # weighted_accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(w_acc_train, label=\"Train weighted_accuracy\", marker='o')\n",
        "    plt.plot(w_acc_test, label=\"Test weighted_accuracy\", marker='o')\n",
        "    plt.fill_between(range(len(w_acc_train)), np.min(w_acc_train), np.max(w_acc_train), color='blue', alpha=0.1)\n",
        "    plt.fill_between(range(len(w_acc_test)), np.min(w_acc_test), np.max(w_acc_test), color='orange', alpha=0.1)\n",
        "    plt.title(\"weighted_accuracy over Folds\")\n",
        "    plt.xlabel(\"Fold\")\n",
        "    plt.ylabel(\"weighted_accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_multi_model_results(results):\n",
        "    # Set up the plot\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 20))\n",
        "\n",
        "    # Colors for train and test\n",
        "    train_color = 'skyblue'\n",
        "    test_color = 'lightgreen'\n",
        "\n",
        "    # Plot MSE\n",
        "    ax1.set_title('Mean Squared Error (MSE) Comparison', fontsize=16)\n",
        "    ax1.set_ylabel('MSE', fontsize=12)\n",
        "    ax1.set_xlabel('Models', fontsize=12)\n",
        "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Plot weighted_accuracy\n",
        "    ax2.set_title('weighted_accuracy Comparison', fontsize=16)\n",
        "    ax2.set_ylabel('weighted_accuracy', fontsize=12)\n",
        "    ax2.set_xlabel('Models', fontsize=12)\n",
        "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    x = np.arange(len(results))\n",
        "    width = 0.35\n",
        "\n",
        "    for i, (model_name, scores) in enumerate(results.items()):\n",
        "        # MSE\n",
        "        mse_train = scores['mse_train']\n",
        "        mse_test = scores['mse_test']\n",
        "\n",
        "        ax1.bar(x[i] - width/2, np.mean(mse_train), width, label='Train' if i == 0 else \"\",\n",
        "                color=train_color, alpha=0.7)\n",
        "        ax1.bar(x[i] + width/2, np.mean(mse_test), width, label='Test' if i == 0 else \"\",\n",
        "                color=test_color, alpha=0.7)\n",
        "\n",
        "        ax1.errorbar(x[i] - width/2, np.mean(mse_train),\n",
        "                     yerr=[[np.mean(mse_train)-np.min(mse_train)], [np.max(mse_train)-np.mean(mse_train)]],\n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "        ax1.errorbar(x[i] + width/2, np.mean(mse_test),\n",
        "                     yerr=[[np.mean(mse_test)-np.min(mse_test)], [np.max(mse_test)-np.mean(mse_test)]],\n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "\n",
        "        # weighted_accuracy\n",
        "        w_acc_train = scores['w_acc_train']\n",
        "        w_acc_test = scores['w_acc_test']\n",
        "\n",
        "        ax2.bar(x[i] - width/2, np.mean(w_acc_train), width, label='Train' if i == 0 else \"\",\n",
        "                color=train_color, alpha=0.7)\n",
        "        ax2.bar(x[i] + width/2, np.mean(w_acc_test), width, label='Test' if i == 0 else \"\",\n",
        "                color=test_color, alpha=0.7)\n",
        "\n",
        "        ax2.errorbar(x[i] - width/2, np.mean(w_acc_train),\n",
        "                     yerr=[[np.mean(w_acc_train)-np.min(w_acc_train)], [np.max(w_acc_train)-np.mean(w_acc_train)]],\n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "        ax2.errorbar(x[i] + width/2, np.mean(w_acc_test),\n",
        "                     yerr=[[np.mean(w_acc_test)-np.min(w_acc_test)], [np.max(w_acc_test)-np.mean(w_acc_test)]],\n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(results.keys(), rotation=45, ha='right')\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels(results.keys(), rotation=45, ha='right')\n",
        "\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax2.legend(loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6c73c55-9684-411c-9ad3-ba6f9ba7de8d",
      "metadata": {
        "id": "f6c73c55-9684-411c-9ad3-ba6f9ba7de8d"
      },
      "source": [
        "#### Simple Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d6a7f41-1184-4172-ab8b-220f45ab2172",
      "metadata": {
        "id": "3d6a7f41-1184-4172-ab8b-220f45ab2172"
      },
      "outputs": [],
      "source": [
        "# Function to handle train-test evaluation in a fold\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test, model):\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on train set\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    # Make predictions on train set\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Compute MSE for train and test\n",
        "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "    # Compute weighted_accuracy\n",
        "\n",
        "    w_acc_train = weighted_accuracy(y_train, y_pred_train)\n",
        "    w_acc_test = weighted_accuracy(y_test, y_pred_test)\n",
        "\n",
        "    return mse_train, mse_test, w_acc_train, w_acc_test\n",
        "\n",
        "\n",
        "def run_multi_model_cv(X, y, models, n_splits=5):\n",
        "    fold = KFold(n_splits=n_splits)\n",
        "    results = {name: {'mse_train': [], 'mse_test': [], 'w_acc_train': [], 'w_acc_test': []}\n",
        "               for name in models.keys()}\n",
        "\n",
        "    for train_index, test_index in fold.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
        "        y_train, y_test = y.iloc[train_index].copy(), y.iloc[test_index].copy()\n",
        "\n",
        "        for name, model in models.items():\n",
        "            mse_train, mse_test, w_acc_train, w_acc_test = train_and_evaluate(\n",
        "                X_train, X_test, y_train, y_test, model\n",
        "            )\n",
        "            results[name]['mse_train'].append(mse_train)\n",
        "            results[name]['mse_test'].append(mse_test)\n",
        "            results[name]['w_acc_train'].append(w_acc_train)\n",
        "            results[name]['w_acc_test'].append(w_acc_test)\n",
        "        # Find the model with the best mean w_acc test score\n",
        "    best_mean_w_acc = -1\n",
        "    best_model = None\n",
        "    best_min_w_acc = None\n",
        "    best_max_w_acc = None\n",
        "\n",
        "    for name, result in results.items():\n",
        "        w_acc_test_scores = result['w_acc_test']\n",
        "        mean_w_acc_test = sum(w_acc_test_scores) / len(w_acc_test_scores)  # Calculate mean w_acc score\n",
        "        min_w_acc_test = min(w_acc_test_scores)  # Minimum w_acc score\n",
        "        max_w_acc_test = max(w_acc_test_scores)  # Maximum w_acc score\n",
        "\n",
        "        if mean_w_acc_test > best_mean_w_acc:\n",
        "            best_mean_w_acc = mean_w_acc_test\n",
        "            best_min_w_acc = min_w_acc_test\n",
        "            best_max_w_acc = max_w_acc_test\n",
        "            best_model = name\n",
        "\n",
        "    # Print the best mean w_acc test score, min, max, and the associated model\n",
        "    print(f\"Best mean w_acc test score: {best_mean_w_acc:.4f} by model: {best_model}\")\n",
        "    print(f\"Min w_acc test score: {best_min_w_acc:.4f}, Max w_acc test score: {best_max_w_acc:.4f}\")\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891e158b-b199-41ac-a244-537429eb1d22",
      "metadata": {
        "id": "891e158b-b199-41ac-a244-537429eb1d22",
        "outputId": "284a28fe-d8f5-410b-9b1a-51133336fd1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [],
      "source": [
        "# Step 1: Run cross-validation\n",
        "results = run_multi_model_cv(X, y, {\"RandomForestRegressor\": RandomForestRegressor(n_jobs=-1)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b0380d-c7ee-413e-9b13-756f8e7e3847",
      "metadata": {
        "id": "34b0380d-c7ee-413e-9b13-756f8e7e3847",
        "outputId": "d2cf77d0-4e45-4938-d9f7-6146d82744e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "outputs": [],
      "source": [
        "# Step 2: Plot the results\n",
        "plot_results(results[\"RandomForestRegressor\"][\"mse_train\"],\n",
        "             results[\"RandomForestRegressor\"][\"mse_test\"],\n",
        "             results[\"RandomForestRegressor\"][\"w_acc_train\"],\n",
        "             results[\"RandomForestRegressor\"][\"w_acc_test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different models"
      ],
      "metadata": {
        "id": "LFvPjfYo6cdU"
      },
      "id": "LFvPjfYo6cdU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc76e0a4-6af0-43eb-af13-0bad0adbbdbd",
      "metadata": {
        "id": "bc76e0a4-6af0-43eb-af13-0bad0adbbdbd"
      },
      "outputs": [],
      "source": [
        "# 放在你的 import 区域\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from xgboost import XGBRegressor       # 若已导入可忽略\n",
        "from lightgbm import LGBMRegressor     # 若已导入可忽略\n",
        "from sklearn.tree import DecisionTreeRegressor  # 若想要真正的“单棵决策树”\n",
        "\n",
        "models = {\n",
        "    'Ridge': Ridge(),\n",
        "    'DecisionTree': DecisionTreeRegressor(),          # 如果你想要单棵树\n",
        "    'RandomForest': RandomForestRegressor(n_jobs=-1),\n",
        "    'ExtraTrees': ExtraTreesRegressor(n_jobs=-1),\n",
        "    'LGBM': LGBMRegressor(),\n",
        "    'XGB': XGBRegressor(),\n",
        "    'KNN Regressor': KNeighborsRegressor(),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "264692a5-ce69-4567-a108-669d0cfcc3a1",
      "metadata": {
        "id": "264692a5-ce69-4567-a108-669d0cfcc3a1",
        "outputId": "4abf0a4b-2c92-4f1c-b963-232dc8e34944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [],
      "source": [
        "# Run cross-validation for regression models\n",
        "results = run_multi_model_cv(X, y, models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250f1f68-32b7-47d3-8934-952785a3046f",
      "metadata": {
        "id": "250f1f68-32b7-47d3-8934-952785a3046f",
        "outputId": "74ba6f76-3456-4550-e4b8-e66307f224d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [],
      "source": [
        "# Plot MSE results for regression models\n",
        "plot_multi_model_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0e21e12-8f5d-4fe5-beb0-566d8a971ae7",
      "metadata": {
        "id": "b0e21e12-8f5d-4fe5-beb0-566d8a971ae7"
      },
      "source": [
        "#### Manage properly the objective weighted_accuracy\n",
        "should we create different classes? custom loss?\n",
        "\n",
        "Create Compare and Optimize different models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
        "\n",
        "class ClassifierAsRegressor(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"\n",
        "    用分类器学 sign(y)，输出 p=Pr(up)，再映射回数值：\n",
        "      y_hat = (2p - 1) * m\n",
        "    其中 m = 训练集 |y| 的稳健尺度（默认用 median(|y|)）\n",
        "    \"\"\"\n",
        "    def __init__(self, clf, scale_mode='median'):\n",
        "        self.clf = clf\n",
        "        self.scale_mode = scale_mode\n",
        "        self._m = None\n",
        "        self._clf_fitted = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        y = np.asarray(y)\n",
        "        z = (y > 0).astype(int)  # 二分类标签\n",
        "        self._m = np.median(np.abs(y)) if self.scale_mode == 'median' else np.mean(np.abs(y))\n",
        "        self._clf_fitted = clone(self.clf).fit(X, z)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # 需要支持 predict_proba 或 decision_function\n",
        "        if hasattr(self._clf_fitted, \"predict_proba\"):\n",
        "            p = self._clf_fitted.predict_proba(X)[:, 1]\n",
        "        elif hasattr(self._clf_fitted, \"decision_function\"):\n",
        "            # 将 margin 通过sigmoid近似成概率\n",
        "            margin = self._clf_fitted.decision_function(X)\n",
        "            p = 1.0 / (1.0 + np.exp(-margin))\n",
        "        else:\n",
        "            # 只有 predict 的话就没法做概率—退化为 +/-1\n",
        "            z_hat = self._clf_fitted.predict(X)\n",
        "            p = 0.5 + 0.5 * (z_hat > 0).astype(float)\n",
        "        return (2.0 * p - 1.0) * self._m\n"
      ],
      "metadata": {
        "id": "YURomwYNk3B9"
      },
      "id": "YURomwYNk3B9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import KFold, TimeSeriesSplit, cross_val_score\n",
        "import pandas as pd\n",
        "\n",
        "# —— 你的数据 ——\n",
        "# X, y 已在前面准备好（y = data_train.pop('end_of_day_return'); X = data_train）\n",
        "\n",
        "# 模型池（不加参数版）\n",
        "models = {\n",
        "    'Ridge': Ridge(),\n",
        "    'Lasso': Lasso(),\n",
        "    'ElasticNet': ElasticNet(),\n",
        "    'RandomForest': RandomForestRegressor(n_jobs=-1),\n",
        "    'ExtraTrees': ExtraTreesRegressor(n_jobs=-1),\n",
        "    'LGBM': LGBMRegressor(),\n",
        "    'XGB': XGBRegressor(),\n",
        "    'KNN': KNeighborsRegressor(),\n",
        "    'SVR': SVR(),\n",
        "\n",
        "    # 分类→回归（两个常见选择）\n",
        "    'Cls2Reg_LGBM': ClassifierAsRegressor(LGBMClassifier()),\n",
        "    # 也可以试 XGBClassifier，但先给一个\n",
        "}\n",
        "\n",
        "# 交叉验证：若要严格时间不泄露，建议换 TimeSeriesSplit\n",
        "# cv = TimeSeriesSplit(n_splits=5)\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "def compare_models(X, y, models, cv, scorer):\n",
        "    rows = []\n",
        "    for name, mdl in models.items():\n",
        "        scores = cross_val_score(mdl, X, y, cv=cv, scoring=scorer, n_jobs=-1)\n",
        "        rows.append({\n",
        "            \"model\": name,\n",
        "            \"cv_mean_wa\": scores.mean(),\n",
        "            \"cv_std_wa\": scores.std(),\n",
        "            \"cv_min_wa\": scores.min(),\n",
        "            \"cv_max_wa\": scores.max(),\n",
        "            \"n_splits\": cv.get_n_splits()\n",
        "        })\n",
        "    df = pd.DataFrame(rows).sort_values(\"cv_mean_wa\", ascending=False).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "df_cmp = compare_models(X, y, models, cv=cv, scorer=WA_SCORER)\n",
        "df_cmp\n"
      ],
      "metadata": {
        "id": "KtApFfZqk29Z",
        "outputId": "c46a1cce-2e34-4ace-a9dd-c413390c5be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "id": "KtApFfZqk29Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 可视化 cross_val_score 比较结果 ===\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(df_cmp['model'], df_cmp['cv_mean_wa'], xerr=df_cmp['cv_std_wa'],\n",
        "         color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.xlabel(\"Weighted Accuracy (mean ± std)\")\n",
        "plt.ylabel(\"Model\")\n",
        "plt.title(\"Model Comparison by Weighted Accuracy (5-Fold CV)\")\n",
        "plt.gca().invert_yaxis()  # 让最高的模型在上面\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "for i, v in enumerate(df_cmp['cv_mean_wa']):\n",
        "    plt.text(v + 0.001, i, f\"{v:.3f}\", va='center')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hMoltTO-qWso",
        "outputId": "544a21b8-f3a5-4bcb-fbbd-fe1b15139ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "id": "hMoltTO-qWso",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 例子1：ExtraTrees（很常见地能把 w-acc 拉高且方差小）\n",
        "et = ExtraTreesRegressor(n_jobs=-1, random_state=42)\n",
        "et_grid = {\n",
        "    \"n_estimators\": [300, 600, 900],\n",
        "    \"max_depth\": [None, 10, 20, 30],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "}\n",
        "\n",
        "et_search = RandomizedSearchCV(\n",
        "    et, et_grid, n_iter=15, scoring=WA_SCORER,\n",
        "    cv=cv, n_jobs=-1, random_state=42, verbose=1\n",
        ")\n",
        "et_search.fit(X, y)\n",
        "et_best = et_search.best_estimator_\n",
        "print(\"Best ET weighted_accuracy (CV):\", et_search.best_score_)\n",
        "print(et_search.best_params_)\n",
        "\n",
        "# 例子2：LGBM（更强但易过拟合，随机搜小范围）\n",
        "lgbm = LGBMRegressor(random_state=42)\n",
        "lgbm_grid = {\n",
        "    \"n_estimators\": [400, 800, 1200],\n",
        "    \"learning_rate\": [0.03, 0.05, 0.1],\n",
        "    \"num_leaves\": [15, 31, 63],\n",
        "    \"subsample\": [0.7, 0.9, 1.0],\n",
        "    \"colsample_bytree\": [0.7, 0.9, 1.0],\n",
        "    \"reg_alpha\": [0.0, 1.0, 2.0],\n",
        "    \"reg_lambda\": [0.0, 1.0, 2.0],\n",
        "}\n",
        "lgbm_search = RandomizedSearchCV(\n",
        "    lgbm, lgbm_grid, n_iter=20, scoring=WA_SCORER,\n",
        "    cv=cv, n_jobs=-1, random_state=42, verbose=1\n",
        ")\n",
        "lgbm_search.fit(X, y)\n",
        "lgbm_best = lgbm_search.best_estimator_\n",
        "print(\"Best LGBM weighted_accuracy (CV):\", lgbm_search.best_score_)\n",
        "print(lgbm_search.best_params_)\n"
      ],
      "metadata": {
        "id": "ksqMFn4jk21z",
        "outputId": "bb6eab6a-596f-4853-fec5-530d88876c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ksqMFn4jk21z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ET seems good, so i planned to do more on ET"
      ],
      "metadata": {
        "id": "uorxSZRlsnjr"
      },
      "id": "uorxSZRlsnjr"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "WA_SCORER = make_scorer(lambda yt, yp: weighted_accuracy(yt, yp), greater_is_better=True)\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)  # 和你之前一致\n"
      ],
      "metadata": {
        "id": "H4XS6fTHshkV"
      },
      "id": "H4XS6fTHshkV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools, random\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def score_et_configs(config_list, X, y, cv, scorer):\n",
        "    rows = []\n",
        "    for i, cfg in enumerate(config_list, 1):\n",
        "        # oob 仅在 bootstrap=True 时可用；这里不启用 oob 以保持CV一致\n",
        "        mdl = ExtraTreesRegressor(\n",
        "            random_state=42, n_jobs=-1, **cfg\n",
        "        )\n",
        "        scores = cross_val_score(mdl, X, y, cv=cv, scoring=WA_SCORER, n_jobs=-1)\n",
        "        mean_, std_, mn_, mx_ = scores.mean(), scores.std(), scores.min(), scores.max()\n",
        "        print(f\"[{i:02d}/{len(config_list)}] cfg={cfg} -> \"\n",
        "              f\"w_acc(mean)={mean_:.4f}  std={std_:.4f}  range=[{mn_:.4f}, {mx_:.4f}]\")\n",
        "        rows.append({**cfg, \"wa_mean\": mean_, \"wa_std\": std_, \"wa_min\": mn_, \"wa_max\": mx_})\n",
        "    df = pd.DataFrame(rows).sort_values(\"wa_mean\", ascending=False).reset_index(drop=True)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "mebLFj9gsiUD"
      },
      "id": "mebLFj9gsiUD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 参数空间（不要全笛卡尔积，太大；我们随机采样一些组合）\n",
        "space = {\n",
        "    \"n_estimators\":   [600, 900, 1200, 1500],\n",
        "    \"max_depth\":      [None, 12, 20, 30],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\":  [1, 2, 4, 6],\n",
        "    \"max_features\":   [\"sqrt\", \"log2\", 0.5, 0.8, 1.0],\n",
        "    \"criterion\":      [\"squared_error\", \"absolute_error\"],\n",
        "    \"bootstrap\":      [False],   # 设 True+oob 也行，但与CV重复评估；先关掉保证速度与一致性\n",
        "}\n",
        "\n",
        "# 随机采样 N 组候选（例如 24 组），你也可以调大到 36/48 组\n",
        "keys = list(space.keys())\n",
        "cands = []\n",
        "N = 24\n",
        "rng = random.Random(42)\n",
        "for _ in range(N):\n",
        "    cfg = {k: rng.choice(space[k]) for k in keys}\n",
        "    cands.append(cfg)\n",
        "\n",
        "df_et = score_et_configs(cands, X, y, cv, WA_SCORER)\n",
        "df_et.head(10)\n"
      ],
      "metadata": {
        "id": "oDHR9J23sklW",
        "outputId": "0e5144a4-98e9-44a7-b9ec-257a0ba985e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "id": "oDHR9J23sklW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I noticed that the parameter set [01/24] already performed very well, so I decided to stop the training early. The final selected model is ExtraTrees with the following parameters:\n",
        "{\n",
        "    'n_estimators': 600,\n",
        "    'max_depth': None,\n",
        "    'min_samples_split': 10,\n",
        "    'min_samples_leaf': 4,\n",
        "    'max_features': 'log2',\n",
        "    'criterion': 'squared_error',\n",
        "    'bootstrap': False\n",
        "}"
      ],
      "metadata": {
        "id": "gsjg-NxjznYR"
      },
      "id": "gsjg-NxjznYR"
    },
    {
      "cell_type": "markdown",
      "id": "f0431ff6-0e5d-4ead-8735-84e1a728ef11",
      "metadata": {
        "id": "f0431ff6-0e5d-4ead-8735-84e1a728ef11"
      },
      "source": [
        "### Submission:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe4a5d9-be2e-40f1-b1b4-59cac5e7197b",
      "metadata": {
        "id": "dbe4a5d9-be2e-40f1-b1b4-59cac5e7197b"
      },
      "outputs": [],
      "source": [
        "data_train = pd.read_csv('module6_exercise_train.csv', index_col='index')\n",
        "X_test = pd.read_csv('module6_exercise_test.csv', index_col='index')\n",
        "y_train = data_train.pop('end_of_day_return')\n",
        "X_train = data_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db2ea4cd-5463-41ac-b49a-6ec38252b5b6",
      "metadata": {
        "id": "db2ea4cd-5463-41ac-b49a-6ec38252b5b6",
        "outputId": "7f66181f-41c1-4c98-edbf-3a26fecdc1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "outputs": [],
      "source": [
        "# Train on complete data (X_train, y_train) and predict on X_test\n",
        "# 2) 最终模型（你选定的 ExtraTrees 参数）\n",
        "best_model = ExtraTreesRegressor(\n",
        "    n_estimators=600,\n",
        "    max_depth=None,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=4,\n",
        "    max_features='log2',\n",
        "    criterion='squared_error',\n",
        "    bootstrap=False,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 3) 全量训练\n",
        "best_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9877df-0e30-40ed-91a0-69511d359033",
      "metadata": {
        "id": "ac9877df-0e30-40ed-91a0-69511d359033"
      },
      "outputs": [],
      "source": [
        "\n",
        "submission = pd.DataFrame({\n",
        "    'index': X_test.index,\n",
        "    'end_of_day_return': best_model.predict(X_test)\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False, sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d162216-2f3a-4d63-bbbb-66f0a4ce6bcb",
      "metadata": {
        "id": "1d162216-2f3a-4d63-bbbb-66f0a4ce6bcb",
        "outputId": "32b917d2-a08d-4f53-f736-7fc10c2d76e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('submission.csv')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
