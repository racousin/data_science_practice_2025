{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6314701b-8e9a-4984-be12-6b67ed11eb5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b02c5c8-5383-4f41-8eec-baa16e5b3300",
      "metadata": {},
      "source": [
        "### Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850f0188-75e0-4591-bfb2-430be0f5f089",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# URLs of the files\n",
        "train_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module5/exercise/module5_exercise_train.csv'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module5/exercise/module5_exercise_test.csv'\n",
        "\n",
        "# Function to download a file\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure we notice bad responses\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "# Downloading the files\n",
        "download_file(train_data_url, 'module5_exercise_train.csv')\n",
        "download_file(test_data_url, 'module5_exercise_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aec8aa5-d188-407d-8422-cf4d54ccac63",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train =  pd.read_csv(\"module5_exercise_train.csv\", sep=\",\")\n",
        "df_test =  pd.read_csv(\"module5_exercise_test.csv\", sep=\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60fa867-ddfe-403d-ba84-071792339e6f",
      "metadata": {},
      "source": [
        "### Data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "823a4916-1a3a-4f43-989e-4b9441cc142d",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Make a complete analysis on data preprocessing\n",
        "\n",
        "data = pd.concat([df_train, df_test], axis=0)\n",
        "\n",
        "# Inconsistencies\n",
        "print(\"数据类型：\")\n",
        "print(data.dtypes) \n",
        "\n",
        "# Duplicates (data.duplicated().sum())\n",
        "print(\"重复行数量：\", data.duplicated().sum())\n",
        "\n",
        "# Missing values (data.isnull().sum())\n",
        "print(\"缺失值数量：\")\n",
        "print(data.isnull().sum().sort_values(ascending=False))\n",
        "\n",
        "# Categorical\n",
        "print(\"天气变量分布：\")\n",
        "print(data['weather_condition'].value_counts())\n",
        "\n",
        "# Outliers\n",
        "# Feature Engineering\n",
        "# Feature Selection and/or Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a852e1b0-224e-4db6-921e-3ac3df414bec",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c046b07a-845c-460b-a692-27a97ec3d613",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bed93e3-c3df-44a1-ab90-9b35157ffa24",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_feature_over_time(df, feature, date_id_start, date_id_end):\n",
        "    df_filtered = df[(df['date'] >= date_id_start) & (df['date'] <= date_id_end)]\n",
        "    \n",
        "    if feature not in df_filtered.columns:\n",
        "        print(f\"Feature '{feature}' not found in the DataFrame.\")\n",
        "        return\n",
        "    \n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(df_filtered['date'], df_filtered[feature], label=feature, linestyle='-')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(feature)\n",
        "    plt.title(f'{feature} from {date_id_start} to {date_id_end}')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1fe2013-d460-46c4-a461-b9dfed5478f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['date'] = pd.to_datetime(data['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baeaef1e-284b-416c-9cae-91948a7b6878",
      "metadata": {},
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc88499-aa6c-4bf6-84c6-04a4a266602e",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['wind_speed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec12450c-af79-42c4-9b7e-2ef9a1366fb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_feature_over_time(data, 'electricity_demand', '2017-01-01', '2019-09-07')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c5efed-7530-4934-92ea-60ec12bf00ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_feature_over_time(data, 'humidity', '2016-06-01', '2016-12-01')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d00dd628-b436-4f3b-829d-38b18589a12b",
      "metadata": {},
      "source": [
        "### Data Preprocessing Evaluation Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86971ab4-1ef8-464b-afb5-0d750a8c4035",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Provide a complete data preprocessing transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f88259d1-ad73-41e8-bb6a-a9a0b8820e81",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 1. Handle Inconsistencies\n",
        "def handle_inconsistencies(X_train, y_train, X_val=None):\n",
        "    def handle_windspeed(windspeed):\n",
        "        windspeed = str(windspeed).strip()\n",
        "        if \"km/h\" in windspeed:\n",
        "            return float(windspeed.replace(\"km/h\", \"\").strip())\n",
        "        elif \"m/s\" in windspeed:\n",
        "            return float(windspeed.replace(\"m/s\", \"\").strip()) * 3.6\n",
        "        else:\n",
        "            return float(windspeed)\n",
        "\n",
        "    X_train['wind_speed'] = X_train['wind_speed'].apply(handle_windspeed)\n",
        "    if X_val is not None:\n",
        "        X_val['wind_speed'] = X_val['wind_speed'].apply(handle_windspeed)\n",
        "        return X_train, y_train, X_val\n",
        "    return X_train, y_train\n",
        "\n",
        "\n",
        "# 2. Handling Duplicates\n",
        "def handle_duplicates(X_train, y_train, X_val=None):\n",
        "    before_len = len(X_train)\n",
        "    X_train_no_duplicates = X_train.drop_duplicates()\n",
        "    y_train_no_duplicates = y_train.loc[X_train_no_duplicates.index]\n",
        "    after_len = len(X_train_no_duplicates)\n",
        "\n",
        "    if before_len != after_len:\n",
        "        print(f\"Removed {before_len - after_len} duplicate rows.\")\n",
        "\n",
        "    if X_val is not None:\n",
        "        return X_train_no_duplicates, y_train_no_duplicates, X_val\n",
        "    return X_train_no_duplicates, y_train_no_duplicates\n",
        "\n",
        "\n",
        "# 3. Handling Missing Values\n",
        "def handle_missing_values(X_train, y_train, X_val=None):\n",
        "    features = [\n",
        "        'humidity', 'wind_speed',\n",
        "        'temperature_station1', 'temperature_station2', 'temperature_station3',\n",
        "        'temperature_station4', 'temperature_station5', 'temperature_station6',\n",
        "        'temperature_station7', 'temperature_station8', 'temperature_station9',\n",
        "        'temperature_station10'\n",
        "    ]\n",
        "\n",
        "    X_train[features] = X_train[features].ffill()\n",
        "    if X_val is not None:\n",
        "        X_val['weather_condition'] = X_val['weather_condition'].fillna('Unknown')\n",
        "        X_val[features] = X_val[features].ffill()\n",
        "        return X_train, y_train, X_val\n",
        "    return X_train, y_train\n",
        "\n",
        "\n",
        "# 4. Handling Categorical Values\n",
        "def handle_categorical(X_train, y_train, X_val=None):\n",
        "    mapping = {'Very Low': 0, 'Low': 1, 'Moderate': 2, 'High': 3, 'Very High': 4}\n",
        "\n",
        "    X_train_encoded = pd.get_dummies(X_train, columns=['weather_condition'])\n",
        "    X_train_encoded['oil_brent_price_indicator'] = X_train_encoded['oil_brent_price_indicator'].map(mapping)\n",
        "\n",
        "    if X_val is not None:\n",
        "        X_val_encoded = pd.get_dummies(X_val, columns=['weather_condition'])\n",
        "        X_val_encoded['oil_brent_price_indicator'] = X_val_encoded['oil_brent_price_indicator'].map(mapping)\n",
        "        # 对齐列\n",
        "        X_val_encoded = X_val_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
        "        return X_train_encoded, y_train, X_val_encoded\n",
        "    return X_train_encoded, y_train\n",
        "\n",
        "\n",
        "# 5. Handling Outliers\n",
        "def handle_outliers(X_train, y_train, X_val=None):\n",
        "    def IQR_clip(df, columns):\n",
        "        for column in columns:\n",
        "            Q1, Q3 = df[column].quantile(0.25), df[column].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
        "            df[column] = np.clip(df[column], lower, upper)\n",
        "        return df\n",
        "\n",
        "    def clip_y(y):\n",
        "        Q1, Q3 = y.quantile(0.25), y.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
        "        return np.clip(y, lower, upper)\n",
        "\n",
        "    X_train = IQR_clip(X_train, ['humidity'])\n",
        "    y_train = clip_y(y_train)\n",
        "\n",
        "    if X_val is not None:\n",
        "        X_val = IQR_clip(X_val, ['humidity'])\n",
        "        return X_train, y_train, X_val\n",
        "    return X_train, y_train\n",
        "\n",
        "\n",
        "# 6. Feature Engineering\n",
        "def feature_engineering(X_train, y_train, X_val=None):\n",
        "    def add_datetime_features(df):\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        df['year'] = df['date'].dt.year\n",
        "        df['month'] = df['date'].dt.month\n",
        "        df['day'] = df['date'].dt.day\n",
        "        return df\n",
        "\n",
        "    X_train = add_datetime_features(X_train)\n",
        "    if X_val is not None:\n",
        "        X_val = add_datetime_features(X_val)\n",
        "        return X_train, y_train, X_val\n",
        "    return X_train, y_train\n",
        "\n",
        "\n",
        "# 7. Feature Selection\n",
        "def feature_selection(X_train, X_val=None):\n",
        "    selected_columns = [\n",
        "        'humidity',\n",
        "        'temperature_station1', 'temperature_station2', 'temperature_station3',\n",
        "        'temperature_station4', 'temperature_station5', 'temperature_station6',\n",
        "        'temperature_station7', 'temperature_station8', 'temperature_station9',\n",
        "        'temperature_station10',\n",
        "        'year', 'month', 'day',\n",
        "        'oil_brent_price_indicator',\n",
        "        'weather_condition_Cloudy', 'weather_condition_Sunny',\n",
        "        'weather_condition_Rainy', 'weather_condition_Snowy'\n",
        "    ]\n",
        "\n",
        "    X_train_selected = X_train[selected_columns]\n",
        "    if X_val is not None:\n",
        "        X_val_selected = X_val[selected_columns]\n",
        "        return X_train_selected, X_val_selected\n",
        "    return X_train_selected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec963bf-cf9b-417c-9645-b99491dad1fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "def evaluate_pipeline(X, y, n_splits=5):\n",
        "    # 一次性全局预处理\n",
        "    X, y = handle_inconsistencies(X, y)\n",
        "    X, y = handle_duplicates(X, y)\n",
        "    X, y = handle_missing_values(X, y)\n",
        "    X, y = handle_categorical(X, y)\n",
        "    X, y = handle_outliers(X, y)\n",
        "    X, y = feature_engineering(X, y)\n",
        "    X = feature_selection(X)\n",
        "\n",
        "    model = XGBRegressor()\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "    train_scores, val_scores = [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
        "        print(f\"Processing fold {fold + 1}/{n_splits}...\")\n",
        "\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        train_mse = mean_squared_error(y_train, model.predict(X_train))\n",
        "        val_mse = mean_squared_error(y_val, model.predict(X_val))\n",
        "\n",
        "        train_scores.append(train_mse)\n",
        "        val_scores.append(val_mse)\n",
        "\n",
        "        print(f\"Fold {fold + 1} Train MSE: {train_mse:.4f}, Validation MSE: {val_mse:.4f}\")\n",
        "\n",
        "    # 输出汇总结果\n",
        "    print(\"\\nTrain MSE:\")\n",
        "    print(f\"Mean: {np.mean(train_scores):.4f}, Max: {np.max(train_scores):.4f}, Min: {np.min(train_scores):.4f}\")\n",
        "\n",
        "    print(\"\\nValidation MSE:\")\n",
        "    print(f\"Mean: {np.mean(val_scores):.4f}, Max: {np.max(val_scores):.4f}, Min: {np.min(val_scores):.4f}\")\n",
        "\n",
        "    return np.mean(val_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b3f51e5-d32e-4227-9707-3af61413fe78",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare X and y\n",
        "X = df_train.copy().drop(columns=['electricity_demand'], axis=1)\n",
        "y = df_train.copy().pop('electricity_demand')\n",
        "\n",
        "# Run the evaluation\n",
        "evaluate_pipeline(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30e27e3b-7641-4107-be8c-50104d473cd9",
      "metadata": {},
      "source": [
        "### Generating Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49733a5-e2f6-4839-8063-2a6f5b2dfc28",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and submit your results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4a55e93-fbec-4d09-8a81-c7a80c457f56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FULL PIPELINE (XGB ONLY) — PREPROCESS, AUDIT, CV, SUBMISSION\n",
        "# ============================================================\n",
        "\n",
        "# -----------------\n",
        "# Imports\n",
        "# -----------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# -----------------\n",
        "# Safety helpers\n",
        "# -----------------\n",
        "def _assert_no_nans(name, arr):\n",
        "    if isinstance(arr, pd.Series):\n",
        "        nn = int(arr.isna().sum())\n",
        "    else:\n",
        "        nn = int(pd.isna(arr).sum().sum())\n",
        "    if nn > 0:\n",
        "        raise ValueError(f\"{name} still has {nn} NaNs after preprocessing.\")\n",
        "\n",
        "def _ensure_all_numeric(df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
        "    non_num_cols = df.columns[~df.dtypes.apply(lambda t: np.issubdtype(t, np.number))]\n",
        "    if len(non_num_cols) > 0:\n",
        "        df = df.copy()\n",
        "        for c in non_num_cols:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "# -----------------\n",
        "# 1) Handle Inconsistencies\n",
        "# -----------------\n",
        "def handle_inconsistencies(X_train, y_train, X_val=None):\n",
        "    def handle_windspeed(windspeed):\n",
        "        s = str(windspeed).strip()\n",
        "        try:\n",
        "            if \"km/h\" in s:\n",
        "                return float(s.replace(\"km/h\", \"\").strip())\n",
        "            elif \"m/s\" in s:\n",
        "                return float(s.replace(\"m/s\", \"\").strip()) * 3.6\n",
        "            else:\n",
        "                return float(s)\n",
        "        except Exception:\n",
        "            return np.nan  # leave NaN, impute later\n",
        "\n",
        "    X_train = X_train.copy()\n",
        "    if 'wind_speed' in X_train.columns:\n",
        "        X_train['wind_speed'] = X_train['wind_speed'].apply(handle_windspeed)\n",
        "\n",
        "    if X_val is not None:\n",
        "        X_val = X_val.copy()\n",
        "        if 'wind_speed' in X_val.columns:\n",
        "            X_val['wind_speed'] = X_val['wind_speed'].apply(handle_windspeed)\n",
        "        return X_train, y_train, X_val\n",
        "    return X_train, y_train\n",
        "\n",
        "# -----------------\n",
        "# 2) Handling Duplicates\n",
        "# -----------------\n",
        "def handle_duplicates(X_train, y_train, X_val=None):\n",
        "    before_len = len(X_train)\n",
        "    X_train_no_duplicates = X_train.drop_duplicates()\n",
        "    y_train_no_duplicates = y_train.loc[X_train_no_duplicates.index]\n",
        "    removed = before_len - len(X_train_no_duplicates)\n",
        "    if removed > 0:\n",
        "        print(f\"Removed {removed} duplicate rows.\")\n",
        "    if X_val is not None:\n",
        "        return X_train_no_duplicates, y_train_no_duplicates, X_val\n",
        "    return X_train_no_duplicates, y_train_no_duplicates\n",
        "\n",
        "# -----------------\n",
        "# 3) Handling Missing Values\n",
        "# -----------------\n",
        "def handle_missing_values(X_train, y_train, X_val=None):\n",
        "    numeric_features = [\n",
        "        'humidity', 'wind_speed',\n",
        "        'temperature_station1', 'temperature_station2', 'temperature_station3',\n",
        "        'temperature_station4', 'temperature_station5', 'temperature_station6',\n",
        "        'temperature_station7', 'temperature_station8', 'temperature_station9',\n",
        "        'temperature_station10'\n",
        "    ]\n",
        "\n",
        "    X_train = X_train.copy()\n",
        "    exist_train = [c for c in numeric_features if c in X_train.columns]\n",
        "    if exist_train:\n",
        "        X_train[exist_train] = X_train[exist_train].ffill().bfill()\n",
        "    if 'weather_condition' in X_train.columns:\n",
        "        X_train['weather_condition'] = X_train['weather_condition'].fillna('Unknown')\n",
        "\n",
        "    if X_val is not None:\n",
        "        X_val = X_val.copy()\n",
        "        exist_val = [c for c in numeric_features if c in X_val.columns]\n",
        "        if exist_val:\n",
        "            X_val[exist_val] = X_val[exist_val].ffill().bfill()\n",
        "        if 'weather_condition' in X_val.columns:\n",
        "            X_val['weather_condition'] = X_val['weather_condition'].fillna('Unknown')\n",
        "        return X_train, y_train, X_val\n",
        "    return X_train, y_train\n",
        "\n",
        "# -----------------\n",
        "# 4) Handling Categorical Values\n",
        "# -----------------\n",
        "def handle_categorical(X_train, y_train, X_val=None):\n",
        "    mapping = {'Very Low': 0, 'Low': 1, 'Moderate': 2, 'High': 3, 'Very High': 4}\n",
        "    expected_weather_cols = [\n",
        "        'weather_condition_Cloudy', 'weather_condition_Sunny',\n",
        "        'weather_condition_Rainy', 'weather_condition_Snowy'\n",
        "    ]\n",
        "\n",
        "    # train encoding\n",
        "    if 'weather_condition' in X_train.columns:\n",
        "        X_train_encoded = pd.get_dummies(X_train, columns=['weather_condition'])\n",
        "    else:\n",
        "        X_train_encoded = X_train.copy()\n",
        "\n",
        "    if 'oil_brent_price_indicator' in X_train_encoded.columns:\n",
        "        X_train_encoded['oil_brent_price_indicator'] = (\n",
        "            X_train_encoded['oil_brent_price_indicator']\n",
        "            .map(mapping).fillna(2).astype(int)\n",
        "        )\n",
        "\n",
        "    for col in expected_weather_cols:\n",
        "        if col not in X_train_encoded.columns:\n",
        "            X_train_encoded[col] = 0\n",
        "\n",
        "    if X_val is not None:\n",
        "        if 'weather_condition' in X_val.columns:\n",
        "            X_val_encoded = pd.get_dummies(X_val, columns=['weather_condition'])\n",
        "        else:\n",
        "            X_val_encoded = X_val.copy()\n",
        "\n",
        "        if 'oil_brent_price_indicator' in X_val_encoded.columns:\n",
        "            X_val_encoded['oil_brent_price_indicator'] = (\n",
        "                X_val_encoded['oil_brent_price_indicator']\n",
        "                .map(mapping).fillna(2).astype(int)\n",
        "            )\n",
        "\n",
        "        # align columns identically\n",
        "        X_val_encoded = X_val_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
        "        return X_train_encoded, y_train, X_val_encoded\n",
        "\n",
        "    return X_train_encoded, y_train\n",
        "\n",
        "# -----------------\n",
        "# 5) Handling Outliers\n",
        "# -----------------\n",
        "def handle_outliers(X_train, y_train, X_val=None):\n",
        "    def IQR_clip(df, columns):\n",
        "        df = df.copy()\n",
        "        for column in columns:\n",
        "            if column not in df.columns:\n",
        "                continue\n",
        "            Q1, Q3 = df[column].quantile(0.25), df[column].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
        "            df[column] = np.clip(df[column], lower, upper)\n",
        "        return df\n",
        "\n",
        "    def clip_y(y):\n",
        "        Q1, Q3 = y.quantile(0.25), y.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
        "        return np.clip(y, lower, upper)\n",
        "\n",
        "    X_train = IQR_clip(X_train, ['humidity'])\n",
        "    y_train = clip_y(y_train)\n",
        "\n",
        "    if X_val is not None:\n",
        "        X_val = IQR_clip(X_val, ['humidity'])\n",
        "        return X_train, y_train, X_val\n",
        "    return X_train, y_train\n",
        "\n",
        "# -----------------\n",
        "# 6) Feature Engineering\n",
        "# -----------------\n",
        "def feature_engineering(X_train, y_train, X_val=None):\n",
        "    def add_datetime_features(df):\n",
        "        df = df.copy()\n",
        "        if 'date' in df.columns:\n",
        "            dt = pd.to_datetime(df['date'], errors='coerce')\n",
        "            df['year']  = dt.dt.year\n",
        "            df['month'] = dt.dt.month\n",
        "            df['day']   = dt.dt.day\n",
        "        return df\n",
        "\n",
        "    X_train = add_datetime_features(X_train)\n",
        "    if X_val is not None:\n",
        "        X_val = add_datetime_features(X_val)\n",
        "        return X_train, y_train, X_val\n",
        "    return X_train, y_train\n",
        "\n",
        "# -----------------\n",
        "# 7) Feature Selection (column subset)\n",
        "# -----------------\n",
        "def feature_selection(X_train, X_val=None):\n",
        "    selected_columns = [\n",
        "        'humidity',\n",
        "        'temperature_station1', 'temperature_station2', 'temperature_station3',\n",
        "        'temperature_station4', 'temperature_station5', 'temperature_station6',\n",
        "        'temperature_station7', 'temperature_station8', 'temperature_station9',\n",
        "        'temperature_station10',\n",
        "        'year', 'month', 'day',\n",
        "        'oil_brent_price_indicator',\n",
        "        'weather_condition_Cloudy', 'weather_condition_Sunny',\n",
        "        'weather_condition_Rainy', 'weather_condition_Snowy'\n",
        "    ]\n",
        "    cols_train = [c for c in selected_columns if c in X_train.columns]\n",
        "    X_train_selected = X_train[cols_train]\n",
        "    if X_val is not None:\n",
        "        X_val_selected = X_val.reindex(columns=X_train_selected.columns, fill_value=0)\n",
        "        return X_train_selected, X_val_selected\n",
        "    return X_train_selected\n",
        "\n",
        "# -----------------\n",
        "# Preview & Audit utilities\n",
        "# -----------------\n",
        "def preprocess_for_preview(X_train, y_train, X_test=None):\n",
        "    \"\"\"Apply the exact same preprocessing as in submission path.\"\"\"\n",
        "    X_train = X_train.copy()\n",
        "    X_test  = None if X_test is None else X_test.copy()\n",
        "\n",
        "    if X_test is None:\n",
        "        X_train, y_train = handle_inconsistencies(X_train, y_train)\n",
        "        X_train, y_train = handle_duplicates(X_train, y_train)\n",
        "        X_train, y_train = handle_missing_values(X_train, y_train)\n",
        "        X_train, y_train = handle_categorical(X_train, y_train)\n",
        "        X_train, y_train = handle_outliers(X_train, y_train)\n",
        "        X_train, y_train = feature_engineering(X_train, y_train)\n",
        "        X_train          = feature_selection(X_train)\n",
        "    else:\n",
        "        X_train, y_train, X_test = handle_inconsistencies(X_train, y_train, X_test)\n",
        "        X_train, y_train, X_test = handle_duplicates(X_train, y_train, X_test)\n",
        "        X_train, y_train, X_test = handle_missing_values(X_train, y_train, X_test)\n",
        "        X_train, y_train, X_test = handle_categorical(X_train, y_train, X_test)\n",
        "        X_train, y_train, X_test = handle_outliers(X_train, y_train, X_test)\n",
        "        X_train, y_train, X_test = feature_engineering(X_train, y_train, X_test)\n",
        "        X_train, X_test          = feature_selection(X_train, X_test)\n",
        "\n",
        "    # explicit final impute (train medians)\n",
        "    num_cols = X_train.select_dtypes(include='number').columns\n",
        "    med = X_train[num_cols].median()\n",
        "    X_train[num_cols] = X_train[num_cols].fillna(med)\n",
        "    if X_test is not None:\n",
        "        X_test[num_cols] = X_test[num_cols].fillna(med)\n",
        "\n",
        "    # force numeric\n",
        "    X_train = _ensure_all_numeric(X_train, \"X_train\")\n",
        "    if X_test is not None:\n",
        "        X_test = _ensure_all_numeric(X_test, \"X_test\")\n",
        "\n",
        "    return X_train, y_train, X_test\n",
        "\n",
        "def audit_frame(df: pd.DataFrame, name: str):\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"shape: {df.shape}\")\n",
        "    print(f\"columns ({len(df.columns)}): {list(df.columns)[:10]}{' ...' if df.shape[1] > 10 else ''}\")\n",
        "\n",
        "    non_num = df.columns[~df.dtypes.apply(lambda t: np.issubdtype(t, np.number))]\n",
        "    if len(non_num):\n",
        "        print(\"⚠️ Non-numeric columns:\", list(non_num))\n",
        "    else:\n",
        "        print(\"All columns are numeric ✅\")\n",
        "\n",
        "    na_total = int(df.isna().sum().sum())\n",
        "    if na_total == 0:\n",
        "        print(\"No missing values ✅\")\n",
        "    else:\n",
        "        na_cols = df.isna().sum()\n",
        "        na_cols = na_cols[na_cols > 0].sort_values(ascending=False)\n",
        "        print(f\"⚠️ Missing values total = {na_total}\")\n",
        "        print(na_cols.head(10))\n",
        "\n",
        "    display(df.head(5))\n",
        "    display(df.describe(include='all').T.head(12))\n",
        "\n",
        "    if 'oil_brent_price_indicator' in df.columns:\n",
        "        vc = df['oil_brent_price_indicator'].value_counts(dropna=False).sort_index()\n",
        "        print(\"oil_brent_price_indicator value counts:\\n\", vc)\n",
        "    wc_cols = [c for c in df.columns if c.startswith('weather_condition_')]\n",
        "    if wc_cols:\n",
        "        print(\"weather_condition dummies present:\", wc_cols)\n",
        "    if 'wind_speed' in df.columns:\n",
        "        ws = df['wind_speed']\n",
        "        print(f\"wind_speed range: min={ws.min():.3f}, max={ws.max():.3f}\")\n",
        "\n",
        "def compare_train_test(X_tr: pd.DataFrame, X_te: pd.DataFrame):\n",
        "    print(\"\\n=== Train/Test Column Alignment ===\")\n",
        "    only_in_tr = [c for c in X_tr.columns if c not in X_te.columns]\n",
        "    only_in_te = [c for c in X_te.columns if c not in X_tr.columns]\n",
        "    if not only_in_tr and not only_in_te and list(X_tr.columns) == list(X_te.columns):\n",
        "        print(\"Columns identical and in the same order ✅\")\n",
        "    else:\n",
        "        if only_in_tr:\n",
        "            print(\"⚠️ Columns only in TRAIN:\", only_in_tr)\n",
        "        if only_in_te:\n",
        "            print(\"⚠️ Columns only in TEST:\", only_in_te)\n",
        "        if list(X_tr.columns) != list(X_te.columns):\n",
        "            print(\"⚠️ Column order differs.\")\n",
        "\n",
        "    print(\"\\nSample mean/std comparison (first 8 cols):\")\n",
        "    cols = X_tr.columns[:8]\n",
        "    stats = pd.DataFrame({\n",
        "        'train_mean': X_tr[cols].mean(),\n",
        "        'test_mean':  X_te[cols].mean(),\n",
        "        'train_std':  X_tr[cols].std(),\n",
        "        'test_std':   X_te[cols].std()\n",
        "    })\n",
        "    display(stats)\n",
        "\n",
        "# -----------------\n",
        "# Cross-validated evaluation (XGB)\n",
        "# -----------------\n",
        "def evaluate_pipeline(X, y, n_splits=5):\n",
        "    X, y = handle_inconsistencies(X, y)\n",
        "    X, y = handle_duplicates(X, y)\n",
        "    X, y = handle_missing_values(X, y)\n",
        "    X, y = handle_categorical(X, y)\n",
        "    X, y = handle_outliers(X, y)\n",
        "    X, y = feature_engineering(X, y)\n",
        "    X = feature_selection(X)\n",
        "\n",
        "    base_params = dict(\n",
        "        n_estimators=400,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_lambda=1.0,\n",
        "        reg_alpha=0.0,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "    train_scores, val_scores = [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
        "        print(f\"Processing fold {fold + 1}/{n_splits}...\")\n",
        "        X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n",
        "        y_train, y_val = y.iloc[train_idx].copy(), y.iloc[val_idx].copy()\n",
        "\n",
        "        model = XGBRegressor(**base_params)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=False,\n",
        "            early_stopping_rounds=50\n",
        "        )\n",
        "\n",
        "        y_tr_pred = model.predict(X_train)\n",
        "        y_va_pred = model.predict(X_val)\n",
        "        train_mse = mean_squared_error(y_train, y_tr_pred)\n",
        "        val_mse   = mean_squared_error(y_val,   y_va_pred)\n",
        "        train_scores.append(train_mse)\n",
        "        val_scores.append(val_mse)\n",
        "\n",
        "        print(f\"Fold {fold + 1} Train MSE: {train_mse:.4f}, Validation MSE: {val_mse:.4f}\")\n",
        "\n",
        "    print(\"\\nTrain MSE:\")\n",
        "    print(f\"Mean: {np.mean(train_scores):.4f}, Max: {np.max(train_scores):.4f}, Min: {np.min(train_scores):.4f}\")\n",
        "    print(\"\\nValidation MSE:\")\n",
        "    print(f\"Mean: {np.mean(val_scores):.4f}, Max: {np.max(val_scores):.4f}, Min: {np.min(val_scores):.4f}\")\n",
        "\n",
        "    return float(np.mean(val_scores))\n",
        "\n",
        "# -----------------\n",
        "# Final train & predict for submission (XGB)\n",
        "# -----------------\n",
        "def train_and_predict_to_submit(X_train, y_train, X_test):\n",
        "    X_train = X_train.copy()\n",
        "    X_test  = X_test.copy()\n",
        "    y_train = y_train.copy()\n",
        "\n",
        "    # unified preprocessing with X_val path (keeps alignment)\n",
        "    X_train, y_train, X_test = handle_inconsistencies(X_train, y_train, X_test)\n",
        "    X_train, y_train, X_test = handle_duplicates(X_train, y_train, X_test)\n",
        "    _assert_no_nans(\"y_train after duplicates\", y_train)\n",
        "\n",
        "    X_train, y_train, X_test = handle_missing_values(X_train, y_train, X_test)\n",
        "    X_train, y_train, X_test = handle_categorical(X_train, y_train, X_test)\n",
        "    X_train, y_train, X_test = handle_outliers(X_train, y_train, X_test)\n",
        "    X_train, y_train, X_test = feature_engineering(X_train, y_train, X_test)\n",
        "    X_train, X_test          = feature_selection(X_train, X_test)\n",
        "\n",
        "    # final impute based on TRAIN medians only\n",
        "    num_cols = X_train.select_dtypes(include=\"number\").columns\n",
        "    med = X_train[num_cols].median()\n",
        "    X_train[num_cols] = X_train[num_cols].fillna(med)\n",
        "    X_test[num_cols]  = X_test[num_cols].fillna(med)\n",
        "\n",
        "    # enforce numeric\n",
        "    X_train = _ensure_all_numeric(X_train, \"X_train\")\n",
        "    X_test  = _ensure_all_numeric(X_test,  \"X_test\")\n",
        "\n",
        "    # sanity checks\n",
        "    _assert_no_nans(\"X_train\", X_train)\n",
        "    _assert_no_nans(\"X_test\",  X_test)\n",
        "    _assert_no_nans(\"y_train\", y_train)\n",
        "\n",
        "    if list(X_train.columns) != list(X_test.columns):\n",
        "        missing_in_test = [c for c in X_train.columns if c not in X_test.columns]\n",
        "        extra_in_test   = [c for c in X_test.columns if c not in X_train.columns]\n",
        "        raise ValueError(\n",
        "            \"Train/Test columns misaligned.\\n\"\n",
        "            f\"Only in TRAIN: {missing_in_test}\\n\"\n",
        "            f\"Only in TEST:  {extra_in_test}\"\n",
        "        )\n",
        "\n",
        "    final_model = XGBRegressor(\n",
        "        n_estimators=400,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_lambda=1.0,\n",
        "        reg_alpha=0.0,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    print(f\"Training XGBRegressor on dataset: {X_train.shape}\")\n",
        "    final_model.fit(X_train, y_train, verbose=False)\n",
        "\n",
        "    print(f\"Predicting on test dataset: {X_test.shape}\")\n",
        "    y_test_pred = final_model.predict(X_test)\n",
        "    return y_test_pred\n",
        "\n",
        "# -----------------\n",
        "# Example Usage\n",
        "# -----------------\n",
        "# Load data\n",
        "df_train = pd.read_csv(\"module5_exercise_train.csv\")\n",
        "X_train = df_train.drop(columns=['electricity_demand'])\n",
        "y_train = df_train['electricity_demand']\n",
        "X_test  = pd.read_csv(\"module5_exercise_test.csv\")\n",
        "\n",
        "# (Optional) Preview & checks\n",
        "X_pp, y_pp, Xtest_pp = preprocess_for_preview(X_train, y_train, X_test)\n",
        "audit_frame(X_pp, \"X_train_preprocessed\")\n",
        "audit_frame(Xtest_pp, \"X_test_preprocessed\")\n",
        "compare_train_test(X_pp, Xtest_pp)\n",
        "\n",
        "# (Optional) Cross-validated evaluation\n",
        "# _ = evaluate_pipeline(X_train, y_train, n_splits=5)\n",
        "\n",
        "# Final train & predict, then save\n",
        "y_test_pred = train_and_predict_to_submit(X_train, y_train, X_test)\n",
        "pd.DataFrame({'electricity_demand': y_test_pred}).to_csv(\"submission2.csv\", index=False)\n",
        "print(\"✅ Saved predictions to 'submission2.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b65ca09-9367-4d7a-a144-0e83c605395c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def view_and_validate_submission(submission_path: str,\n",
        "                                 x_test_path: str = \"module5_exercise_test.csv\",\n",
        "                                 target_col: str = \"electricity_demand\"):\n",
        "    # Load files\n",
        "    sub = pd.read_csv(submission_path)\n",
        "    X_test = pd.read_csv(x_test_path)\n",
        "\n",
        "    print(\"=== Basic Info ===\")\n",
        "    print(f\"Submission shape: {sub.shape}\")\n",
        "    print(f\"Submission columns: {list(sub.columns)}\")\n",
        "    print(f\"Test shape: {X_test.shape}\")\n",
        "    print()\n",
        "\n",
        "    # Preview\n",
        "    print(\"=== Head (first 10 rows) ===\")\n",
        "    display(sub.head(10))\n",
        "\n",
        "    print(\"\\n=== Dtypes ===\")\n",
        "    print(sub.dtypes)\n",
        "\n",
        "    # Checks\n",
        "    print(\"\\n=== Validation Checks ===\")\n",
        "    # 1) Target column present\n",
        "    if target_col not in sub.columns:\n",
        "        print(f\"❌ Missing required column: '{target_col}'\")\n",
        "    else:\n",
        "        print(f\"✅ Found target column: '{target_col}'\")\n",
        "\n",
        "    # 2) Row count matches test\n",
        "    n_test = len(X_test)\n",
        "    n_sub = len(sub)\n",
        "    if n_sub == n_test:\n",
        "        print(f\"✅ Row count OK: submission rows = test rows = {n_sub}\")\n",
        "    else:\n",
        "        print(f\"❌ Row count mismatch: submission {n_sub} vs test {n_test}\")\n",
        "\n",
        "    # 3) No NaNs\n",
        "    nan_total = int(sub.isna().sum().sum())\n",
        "    if nan_total == 0:\n",
        "        print(\"✅ No NaNs in submission\")\n",
        "    else:\n",
        "        print(f\"❌ Found {nan_total} NaNs in submission\")\n",
        "        print(sub.isna().sum()[sub.isna().sum() > 0])\n",
        "\n",
        "    # 4) Numeric target\n",
        "    if target_col in sub.columns:\n",
        "        if np.issubdtype(sub[target_col].dtype, np.number):\n",
        "            print(f\"✅ '{target_col}' is numeric\")\n",
        "        else:\n",
        "            print(f\"❌ '{target_col}' is not numeric (dtype={sub[target_col].dtype})\")\n",
        "\n",
        "    # 5) Quick stats\n",
        "    if target_col in sub.columns:\n",
        "        print(\"\\n=== Target Summary ===\")\n",
        "        display(sub[target_col].describe())\n",
        "\n",
        "    return sub, X_test\n",
        "\n",
        "# Inspect your file\n",
        "sub, X_test_check = view_and_validate_submission(\"submission2.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f558b85-7970-4c24-95a8-fd6a37da930b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_predict_to_submit(X_train, y_train, X_test):\n",
        "    # Defensive copies (avoid SettingWithCopy warnings downstream)\n",
        "    X_train = X_train.copy()\n",
        "    X_test  = X_test.copy()\n",
        "\n",
        "    # === Preprocess (use the X_val path so each function returns 3 values) ===\n",
        "    X_train, y_train, X_test = handle_inconsistencies(X_train, y_train, X_test)\n",
        "    X_train, y_train, X_test = handle_duplicates(X_train, y_train, X_test)\n",
        "    X_train, y_train, X_test = handle_missing_values(X_train, y_train, X_test)\n",
        "    X_train, y_train, X_test = handle_categorical(X_train, y_train, X_test)\n",
        "    X_train, y_train, X_test = handle_outliers(X_train, y_train, X_test)\n",
        "    X_train, y_train, X_test = feature_engineering(X_train, y_train, X_test)\n",
        "\n",
        "    # Feature selection returns 2 values when X_val is provided\n",
        "    X_train, X_test = feature_selection(X_train, X_test)\n",
        "\n",
        "    # === Train & predict ===\n",
        "    model = LinearRegression()\n",
        "    print(f\"Training model on entire dataset of shape: {X_train.shape}\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Predicting on test dataset of shape: {X_test.shape}\")\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    return y_test_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81488d3e-2dde-4904-ac69-430e55df0cc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"module5_exercise_train.csv\")\n",
        "X_train = df_train.drop(columns=['electricity_demand'])\n",
        "y_train = df_train['electricity_demand']\n",
        "\n",
        "X_test = pd.read_csv(\"module5_exercise_test.csv\")\n",
        "\n",
        "y_test_pred = train_and_predict_to_submit(X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44a7efc0-16fa-41f9-a8d9-6e90ba3c8bb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call serve_model to train and predict\n",
        "y_test_pred = train_and_predict_to_submit(X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "538cf936-7872-46ad-b02f-422a0aec3806",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generating Submission File\n",
        "submission = pd.DataFrame({\n",
        "    'date': X_test['date'],\n",
        "    'electricity_demand': y_test_pred\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission.to_csv('submission.csv', index=False, sep=',')\n",
        "print(\"Submission file saved as 'submission.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "220ed9c3-00d4-44fb-982b-e894b7844703",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc633bb-3f63-41dc-b020-f7a868c38b6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.read_csv('submission2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d324190-c23b-44d5-b626-b53330361c9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c1fe56-f27d-47b3-825c-dc0dce1b00d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35591bb7-ec8d-46ae-b5b3-258ecf86a23b",
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df_train.pop('electricity_demand')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f390ca6f-3550-42ca-abeb-732803ec2229",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd3ced55-93ad-4d54-970f-beef0658fa9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9044ab9-ae50-49c0-9296-566121aac64b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def handle_missing_values(X_train, y_train, X_val=None):\n",
        "    numeric_features = [\n",
        "        'humidity', 'wind_speed',\n",
        "        'temperature_station1', 'temperature_station2', 'temperature_station3',\n",
        "        'temperature_station4', 'temperature_station5', 'temperature_station6',\n",
        "        'temperature_station7', 'temperature_station8', 'temperature_station9',\n",
        "        'temperature_station10'\n",
        "    ]\n",
        "\n",
        "    # Forward then backward fill to remove leading/trailing NaNs\n",
        "    exist_train = [c for c in numeric_features if c in X_train.columns]\n",
        "    if exist_train:\n",
        "        X_train.loc[:, exist_train] = X_train[exist_train].ffill().bfill()\n",
        "    if 'weather_condition' in X_train.columns:\n",
        "        X_train.loc[:, 'weather_condition'] = X_train['weather_condition'].fillna('Unknown')\n",
        "\n",
        "    if X_val is not None:\n",
        "        exist_val = [c for c in numeric_features if c in X_val.columns]\n",
        "        if exist_val:\n",
        "            X_val.loc[:, exist_val] = X_val[exist_val].ffill().bfill()\n",
        "        if 'weather_condition' in X_val.columns:\n",
        "            X_val.loc[:, 'weather_condition'] = X_val['weather_condition'].fillna('Unknown')\n",
        "        return X_train, y_train, X_val\n",
        "\n",
        "    return X_train, y_train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742f72c2-03b8-42e8-9cf8-742d7d94d43d",
      "metadata": {},
      "outputs": [],
      "source": [
        "x,y = handle_missing_values(df_train, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f645ac8-73f1-4f76-a6ed-9487b9dcceb8",
      "metadata": {},
      "outputs": [],
      "source": [
        "x.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d40796-f3bd-4757-8ffd-45fe026e548c",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
