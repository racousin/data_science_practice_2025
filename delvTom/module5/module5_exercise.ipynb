{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6314701b-8e9a-4984-be12-6b67ed11eb5f",
      "metadata": {
        "id": "6314701b-8e9a-4984-be12-6b67ed11eb5f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b02c5c8-5383-4f41-8eec-baa16e5b3300",
      "metadata": {
        "id": "7b02c5c8-5383-4f41-8eec-baa16e5b3300"
      },
      "source": [
        "### Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850f0188-75e0-4591-bfb2-430be0f5f089",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "850f0188-75e0-4591-bfb2-430be0f5f089",
        "outputId": "74da1077-b89e-4dcf-e3fa-ed5208826c10"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# URLs of the files\n",
        "train_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module5/exercise/module5_exercise_train.csv'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module5/exercise/module5_exercise_test.csv'\n",
        "\n",
        "# Function to download a file\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure we notice bad responses\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "# Downloading the files\n",
        "download_file(train_data_url, 'module5_exercise_train.csv')\n",
        "download_file(test_data_url, 'module5_exercise_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aec8aa5-d188-407d-8422-cf4d54ccac63",
      "metadata": {
        "id": "6aec8aa5-d188-407d-8422-cf4d54ccac63"
      },
      "outputs": [],
      "source": [
        "df_train =  pd.read_csv(\"module5_exercise_train.csv\", sep=\",\")\n",
        "df_test =  pd.read_csv(\"module5_exercise_test.csv\", sep=\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60fa867-ddfe-403d-ba84-071792339e6f",
      "metadata": {
        "id": "a60fa867-ddfe-403d-ba84-071792339e6f"
      },
      "source": [
        "### Data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "823a4916-1a3a-4f43-989e-4b9441cc142d",
      "metadata": {
        "id": "823a4916-1a3a-4f43-989e-4b9441cc142d"
      },
      "outputs": [],
      "source": [
        "#### Make a complete analysis on data preprocessing\n",
        "# Inconsistencies\n",
        "# Duplicates (data.duplicated().sum())\n",
        "# Missing values (data.isnull().sum())\n",
        "# Categorical\n",
        "# Outliers\n",
        "# Feature Engineering\n",
        "# Feature Selection and/or Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2a9ca3-d867-41aa-9cd2-67aadf0df23d",
      "metadata": {
        "id": "9b2a9ca3-d867-41aa-9cd2-67aadf0df23d"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([df_train, df_test], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a852e1b0-224e-4db6-921e-3ac3df414bec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a852e1b0-224e-4db6-921e-3ac3df414bec",
        "outputId": "dc3c9e6a-7649-41ae-9636-669857573540"
      },
      "outputs": [],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c046b07a-845c-460b-a692-27a97ec3d613",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c046b07a-845c-460b-a692-27a97ec3d613",
        "outputId": "f85dd166-f8f4-4f0d-c901-e683bc158fbc"
      },
      "outputs": [],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bed93e3-c3df-44a1-ab90-9b35157ffa24",
      "metadata": {
        "id": "4bed93e3-c3df-44a1-ab90-9b35157ffa24"
      },
      "outputs": [],
      "source": [
        "def plot_feature_over_time(df, feature, date_id_start, date_id_end):\n",
        "    df_filtered = df[(df['date'] >= date_id_start) & (df['date'] <= date_id_end)]\n",
        "\n",
        "    if feature not in df_filtered.columns:\n",
        "        print(f\"Feature '{feature}' not found in the DataFrame.\")\n",
        "        return\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(df_filtered['date'], df_filtered[feature], label=feature, linestyle='-')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(feature)\n",
        "    plt.title(f'{feature} from {date_id_start} to {date_id_end}')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1fe2013-d460-46c4-a461-b9dfed5478f3",
      "metadata": {
        "id": "c1fe2013-d460-46c4-a461-b9dfed5478f3"
      },
      "outputs": [],
      "source": [
        "data['date'] = pd.to_datetime(data['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baeaef1e-284b-416c-9cae-91948a7b6878",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "baeaef1e-284b-416c-9cae-91948a7b6878",
        "outputId": "b42965ed-054b-4c19-da84-b38f3ef08639"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc88499-aa6c-4bf6-84c6-04a4a266602e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ecc88499-aa6c-4bf6-84c6-04a4a266602e",
        "outputId": "fe3f7443-e6c7-452d-c0df-427a8ede0701"
      },
      "outputs": [],
      "source": [
        "data['wind_speed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec12450c-af79-42c4-9b7e-2ef9a1366fb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ec12450c-af79-42c4-9b7e-2ef9a1366fb9",
        "outputId": "07a6fd11-4b97-4191-a41f-aaacda393d1f"
      },
      "outputs": [],
      "source": [
        "plot_feature_over_time(data, 'electricity_demand', '2017-01-01', '2019-09-07')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c5efed-7530-4934-92ea-60ec12bf00ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "10c5efed-7530-4934-92ea-60ec12bf00ad",
        "outputId": "8cb51aa0-6431-4a5a-c9b3-dc2dbc396113"
      },
      "outputs": [],
      "source": [
        "plot_feature_over_time(data, 'humidity', '2016-06-01', '2016-12-01')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d00dd628-b436-4f3b-829d-38b18589a12b",
      "metadata": {
        "id": "d00dd628-b436-4f3b-829d-38b18589a12b"
      },
      "source": [
        "### Data Preprocessing Evaluation Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86971ab4-1ef8-464b-afb5-0d750a8c4035",
      "metadata": {
        "id": "86971ab4-1ef8-464b-afb5-0d750a8c4035"
      },
      "outputs": [],
      "source": [
        "# Provide a complete data preprocessing transformations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "def find_bad_targets(df, target=\"electricity_demand\", n_splits=5, thr_abs=1000):\n",
        "    X = df.drop(columns=[target]).copy()\n",
        "    y = pd.to_numeric(df[target], errors=\"coerce\")\n",
        "    # trier par date si dispo\n",
        "    if \"date\" in X.columns:\n",
        "        order = pd.to_datetime(X[\"date\"], errors=\"coerce\").sort_values().index\n",
        "        X, y = X.loc[order].reset_index(drop=True), y.loc[order].reset_index(drop=True)\n",
        "\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "    bad_rows = []\n",
        "\n",
        "    for k, (tr, va) in enumerate(tscv.split(X), 1):\n",
        "        y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
        "\n",
        "        # critères simples : négatifs / trop grands en absolu\n",
        "        bad_tr_idx = y_tr.index[(y_tr <= 0) | (y_tr.abs() > thr_abs)].tolist()\n",
        "        bad_va_idx = y_va.index[(y_va <= 0) | (y_va.abs() > thr_abs)].tolist()\n",
        "\n",
        "        if bad_tr_idx or bad_va_idx:\n",
        "            bad_rows.append({\n",
        "                \"fold\": k,\n",
        "                \"bad_train_count\": len(bad_tr_idx),\n",
        "                \"bad_val_count\": len(bad_va_idx),\n",
        "                \"bad_train_examples\": bad_tr_idx[:5],\n",
        "                \"bad_val_examples\": bad_va_idx[:5],\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(bad_rows)\n",
        "\n",
        "# Exemple:\n",
        "# bad = find_bad_targets(df_train, target=\"electricity_demand\", n_splits=5, thr_abs=1000)\n",
        "# print(bad)\n"
      ],
      "metadata": {
        "id": "IjAww8G3HUS_"
      },
      "id": "IjAww8G3HUS_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sanitize_target(df, target=\"electricity_demand\"):\n",
        "    df = df.copy()\n",
        "    # passer en numérique propre\n",
        "    df[target] = pd.to_numeric(df[target], errors=\"coerce\")\n",
        "    # enlever impossibles / manifestement corrompus\n",
        "    df.loc[df[target] <= 0, target] = np.nan\n",
        "    # winsorize par quantiles robustes (évite les énormes outliers)\n",
        "    lo, hi = df[target].quantile([0.005, 0.995])\n",
        "    df[target] = df[target].clip(lo, hi)\n",
        "    # drop les NaN restants sur la cible\n",
        "    df = df.dropna(subset=[target]).reset_index(drop=True)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "T0H0blR4HXL3"
      },
      "id": "T0H0blR4HXL3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) assainir\n",
        "df_clean = sanitize_target(df_train, target=\"electricity_demand\")\n",
        "\n",
        "# 2) préparer X/y\n",
        "X = df_clean.drop(columns=[\"electricity_demand\"])\n",
        "y = df_clean[\"electricity_demand\"].copy()\n",
        "\n",
        "# 3) (re)lancer ton éval (ta version “camarade” ou la mienne strict-CV)\n",
        "mean_val_mse, X_trs, X_vas, y_trs, y_vas = evaluate_pipeline(X, y, n_splits=5, alpha=10.0, scale=True)\n",
        "print(\"\\nScore final (mean Val MSE):\", mean_val_mse)\n"
      ],
      "metadata": {
        "id": "sEl2raAMHZqT",
        "outputId": "5bd962ba-1b84-4824-c639-227f7e5fa649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sEl2raAMHZqT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def diagnose_timeseries(X: pd.DataFrame, y: pd.Series, n_splits=5):\n",
        "    # On trie par date si elle existe\n",
        "    if \"date\" in X.columns:\n",
        "        order = pd.to_datetime(X[\"date\"], errors=\"coerce\").sort_values().index\n",
        "        X = X.loc[order].reset_index(drop=True)\n",
        "        y = y.loc[order].reset_index(drop=True)\n",
        "\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "    rows = []\n",
        "\n",
        "    for k, (tr, va) in enumerate(tscv.split(X), 1):\n",
        "        y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
        "\n",
        "        # baselines : moyenne du train / valeur décalée (naïf)\n",
        "        mean_pred = np.full_like(y_va, fill_value=y_tr.mean(), dtype=np.float64)\n",
        "        lag1_pred = pd.Series(y).iloc[va-1].reset_index(drop=True) if (va[0]-1)>=0 else pd.Series(y_va).fillna(y_tr.mean())\n",
        "        lag1_pred = np.array(lag1_pred.fillna(method='bfill'))\n",
        "\n",
        "        rows.append({\n",
        "            \"fold\": k,\n",
        "            \"y_train_mean\": float(y_tr.mean()), \"y_val_mean\": float(y_va.mean()),\n",
        "            \"y_train_std\": float(y_tr.std()),   \"y_val_std\": float(y_va.std()),\n",
        "            \"MSE_mean_baseline\": float(mean_squared_error(y_va, mean_pred)),\n",
        "            \"MSE_lag1_baseline\": float(mean_squared_error(y_va, lag1_pred)),\n",
        "            \"val_len\": int(len(y_va))\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n"
      ],
      "metadata": {
        "id": "1sUED5IUGojg"
      },
      "id": "1sUED5IUGojg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diag = diagnose_timeseries(\n",
        "    df_train.drop(columns=[\"electricity_demand\"]),\n",
        "    df_train[\"electricity_demand\"], n_splits=5\n",
        ")\n",
        "print(diag)\n"
      ],
      "metadata": {
        "id": "jvHmhJm0Gqg-",
        "outputId": "6c07675a-9165-42aa-97bb-bfc72ae8eb84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jvHmhJm0Gqg-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Sélection de features *stables*\n",
        "SELECTED_COLS = [\n",
        "    \"humidity\",\n",
        "    \"temperature_station1\",\"temperature_station2\",\"temperature_station3\",\n",
        "    \"temperature_station4\",\"temperature_station5\",\"temperature_station6\",\n",
        "    \"temperature_station7\",\"temperature_station8\",\"temperature_station9\",\n",
        "    \"temperature_station10\"\n",
        "]\n",
        "\n",
        "def _to_ms(val):\n",
        "    try:\n",
        "        if isinstance(val, str):\n",
        "            s = val.strip()\n",
        "            if \"km/h\" in s: return float(s.replace(\"km/h\",\"\").strip())/3.6\n",
        "            if \"m/s\"  in s: return float(s.replace(\"m/s\",\"\").strip())\n",
        "        return float(val)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def _deterministic_preclean(X: pd.DataFrame) -> pd.DataFrame:\n",
        "    X = X.copy()\n",
        "    # wind_speed -> m/s\n",
        "    if \"wind_speed\" in X.columns:\n",
        "        X[\"wind_speed\"] = X[\"wind_speed\"].apply(_to_ms)\n",
        "    # date -> mois / jour semaine\n",
        "    if \"date\" in X.columns:\n",
        "        d = pd.to_datetime(X[\"date\"], errors=\"coerce\")\n",
        "        X[\"month\"] = d.dt.month\n",
        "        X[\"dayofweek\"] = d.dt.dayofweek\n",
        "        X = X.drop(columns=[\"date\"])\n",
        "    # humidity bornée\n",
        "    if \"humidity\" in X.columns:\n",
        "        X[\"humidity\"] = pd.to_numeric(X[\"humidity\"], errors=\"coerce\").clip(0, 100)\n",
        "    return X\n",
        "\n",
        "def _select_features(X: pd.DataFrame) -> pd.DataFrame:\n",
        "    keep = [c for c in SELECTED_COLS if c in X.columns]\n",
        "    for extra in [\"month\",\"dayofweek\"]:\n",
        "        if extra in X.columns: keep.append(extra)\n",
        "    if not keep: keep = list(X.columns)\n",
        "    return X[keep]\n",
        "\n",
        "def evaluate_pipeline_strict(X: pd.DataFrame, y: pd.Series,\n",
        "                             n_splits=5, alpha=150.0, clip_quantiles=(0.01, 0.99)):\n",
        "    # Trier par date si dispo (sécurité)\n",
        "    if \"date\" in X.columns:\n",
        "        order = pd.to_datetime(X[\"date\"], errors=\"coerce\").sort_values().index\n",
        "        X = X.loc[order].reset_index(drop=True)\n",
        "        y = y.loc[order].reset_index(drop=True)\n",
        "\n",
        "    # Aucune étape apprenante hors CV\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "    train_scores, val_scores = [], []\n",
        "\n",
        "    for fold, (tr, va) in enumerate(tscv.split(X), 1):\n",
        "        print(f\"Processing fold {fold}/{n_splits}...\")\n",
        "\n",
        "        X_tr, X_va = X.iloc[tr].copy(), X.iloc[va].copy()\n",
        "        y_tr, y_va = y.iloc[tr].copy(), y.iloc[va].copy()\n",
        "\n",
        "        # Nettoyage déterministe + sélection stable (dans le fold, pas de fit global)\n",
        "        X_tr = _select_features(_deterministic_preclean(X_tr))\n",
        "        X_va = _select_features(_deterministic_preclean(X_va))\n",
        "\n",
        "        # Pipeline impute -> scale -> ridge\n",
        "        pipe = Pipeline([\n",
        "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"ridge\", Ridge(alpha=alpha, random_state=0))\n",
        "        ])\n",
        "\n",
        "        pipe.fit(X_tr, y_tr)\n",
        "\n",
        "        # Prédictions\n",
        "        y_tr_pred = pipe.predict(X_tr)\n",
        "        y_va_pred = pipe.predict(X_va)\n",
        "\n",
        "        # CLIP fort basé sur le train (quantiles)\n",
        "        if clip_quantiles is not None:\n",
        "            lo = float(y_tr.quantile(clip_quantiles[0]))\n",
        "            hi = float(y_tr.quantile(clip_quantiles[1]))\n",
        "            y_tr_pred = np.clip(y_tr_pred, lo, hi)\n",
        "            y_va_pred = np.clip(y_va_pred, lo, hi)\n",
        "\n",
        "        tr_mse = mean_squared_error(y_tr, y_tr_pred)\n",
        "        va_mse = mean_squared_error(y_va, y_va_pred)\n",
        "        train_scores.append(tr_mse); val_scores.append(va_mse)\n",
        "\n",
        "        print(f\"Fold {fold} — Train MSE: {tr_mse:.4f} | Val MSE: {va_mse:.4f}\")\n",
        "\n",
        "    print(\"\\nTrain MSE:\")\n",
        "    print(f\"Mean: {np.mean(train_scores):.4f}, Max: {np.max(train_scores):.4f}, Min: {np.min(train_scores):.4f}\")\n",
        "    print(\"\\nValidation MSE:\")\n",
        "    print(f\"Mean: {np.mean(val_scores):.4f}, Max: {np.max(val_scores):.4f}, Min: {np.min(val_scores):.4f}\")\n",
        "    return float(np.mean(val_scores))\n",
        "\n"
      ],
      "metadata": {
        "id": "WOVuF5cLCyU4"
      },
      "id": "WOVuF5cLCyU4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b67a4532-14bc-4590-90ed-d39044dfc6fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b67a4532-14bc-4590-90ed-d39044dfc6fc",
        "outputId": "d6ac2f90-3b56-42e9-fee5-2d02804a4c06"
      },
      "outputs": [],
      "source": [
        "X = df_train.drop(columns=[\"electricity_demand\"])\n",
        "y = df_train[\"electricity_demand\"].copy()\n",
        "\n",
        "print(diagnose_timeseries(X, y, n_splits=5))  # <- d'abord le diag\n",
        "\n",
        "mean_val_mse = evaluate_pipeline_strict(X, y, n_splits=5, alpha=150.0, clip_quantiles=(0.01,0.99))\n",
        "print(\"\\nScore final (mean Val MSE):\", mean_val_mse)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# mêmes colonnes stables que dans l’éval\n",
        "SELECTED_COLS = [\n",
        "    \"humidity\",\n",
        "    \"temperature_station1\",\"temperature_station2\",\"temperature_station3\",\n",
        "    \"temperature_station4\",\"temperature_station5\",\"temperature_station6\",\n",
        "    \"temperature_station7\",\"temperature_station8\",\"temperature_station9\",\n",
        "    \"temperature_station10\"\n",
        "]\n",
        "\n",
        "def _to_ms(val):\n",
        "    try:\n",
        "        if isinstance(val, str):\n",
        "            s = val.strip()\n",
        "            if \"km/h\" in s: return float(s.replace(\"km/h\",\"\").strip())/3.6\n",
        "            if \"m/s\"  in s: return float(s.replace(\"m/s\",\"\").strip())\n",
        "        return float(val)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def deterministic_preclean(X: pd.DataFrame) -> pd.DataFrame:\n",
        "    X = X.copy()\n",
        "    if \"wind_speed\" in X.columns:\n",
        "        X[\"wind_speed\"] = X[\"wind_speed\"].apply(_to_ms)\n",
        "    if \"date\" in X.columns:\n",
        "        d = pd.to_datetime(X[\"date\"], errors=\"coerce\")\n",
        "        X[\"month\"] = d.dt.month\n",
        "        X[\"dayofweek\"] = d.dt.dayofweek\n",
        "        X = X.drop(columns=[\"date\"])\n",
        "    if \"humidity\" in X.columns:\n",
        "        X[\"humidity\"] = pd.to_numeric(X[\"humidity\"], errors=\"coerce\").clip(0, 100)\n",
        "    return X\n",
        "\n",
        "def select_features(X: pd.DataFrame) -> pd.DataFrame:\n",
        "    keep = [c for c in SELECTED_COLS if c in X.columns]\n",
        "    for extra in [\"month\",\"dayofweek\"]:\n",
        "        if extra in X.columns: keep.append(extra)\n",
        "    return X[keep] if keep else X\n",
        "\n",
        "def build_final_pipeline(alpha: float = 150.0) -> Pipeline:\n",
        "    return Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"ridge\", Ridge(alpha=alpha, random_state=0))\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "k2RiiHbgH13G"
      },
      "id": "k2RiiHbgH13G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) (optionnel) assainir la cible — comme on l’a fait pour fixer l’explosion\n",
        "def sanitize_target(df, target=\"electricity_demand\"):\n",
        "    df = df.copy()\n",
        "    df[target] = pd.to_numeric(df[target], errors=\"coerce\")\n",
        "    df.loc[df[target] <= 0, target] = np.nan\n",
        "    lo, hi = df[target].quantile([0.005, 0.995])\n",
        "    df[target] = df[target].clip(lo, hi)\n",
        "    df = df.dropna(subset=[target]).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "# --- prépare train\n",
        "df_clean = sanitize_target(df_train, target=\"electricity_demand\")\n",
        "X_train_full = df_clean.drop(columns=[\"electricity_demand\"])\n",
        "y_train_full = df_clean[\"electricity_demand\"].copy()\n",
        "\n",
        "# mêmes pré-traitements déterministes que pendant la CV\n",
        "X_train_full = select_features(deterministic_preclean(X_train_full))\n",
        "\n",
        "# fit pipeline final\n",
        "pipe_final = build_final_pipeline(alpha=150.0)\n",
        "pipe_final.fit(X_train_full, y_train_full)\n",
        "\n",
        "# --- prépare test\n",
        "X_test = df_test.copy()\n",
        "X_test_proc = select_features(deterministic_preclean(X_test))\n",
        "\n",
        "# IMPORTANT: aligner les colonnes train/test (au cas où)\n",
        "X_test_proc = X_test_proc.reindex(columns=X_train_full.columns, fill_value=np.nan)\n",
        "\n",
        "# prédiction brute\n",
        "y_pred = pipe_final.predict(X_test_proc)\n",
        "\n",
        "# clipping doux par quantiles du train (sécurise encore un peu)\n",
        "lo = float(y_train_full.quantile(0.01))\n",
        "hi = float(y_train_full.quantile(0.99))\n",
        "y_pred = np.clip(y_pred, lo, hi)\n"
      ],
      "metadata": {
        "id": "WNWrW89uH4cW"
      },
      "id": "WNWrW89uH4cW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "30e27e3b-7641-4107-be8c-50104d473cd9",
      "metadata": {
        "id": "30e27e3b-7641-4107-be8c-50104d473cd9"
      },
      "source": [
        "### Generating Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "538cf936-7872-46ad-b02f-422a0aec3806",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "538cf936-7872-46ad-b02f-422a0aec3806",
        "outputId": "57b3d78b-cd06-453d-c678-debeeed02588"
      },
      "outputs": [],
      "source": [
        "# Generating Submission File\n",
        "# Variante A : si on attend une colonne 'electricity_demand' (sans id)\n",
        "submission = pd.DataFrame({\n",
        "    \"electricity_demand\": y_pred\n",
        "})\n",
        "\n",
        "# Variante B : si on attend ['id','electricity_demand']\n",
        "if \"id\" in df_test.columns:\n",
        "    submission = pd.DataFrame({\n",
        "        \"id\": df_test[\"id\"].values,\n",
        "        \"electricity_demand\": y_pred\n",
        "    })\n",
        "\n",
        "# Variante C : si on attend ['date','electricity_demand']\n",
        "if \"date\" in df_test.columns:\n",
        "    submission = pd.DataFrame({\n",
        "        \"date\": df_test[\"date\"].values,\n",
        "        \"electricity_demand\": y_pred\n",
        "    })\n",
        "\n",
        "# Sauvegarde\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Submission saved -> submission.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files  # uniquement si tu es sur Google Colab\n",
        "\n",
        "# Sauvegarde locale\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "# Téléchargement\n",
        "files.download(\"submission.csv\")\n"
      ],
      "metadata": {
        "id": "xRntWyVyIN4U",
        "outputId": "860a929a-5314-4bed-c685-f03d3c50620d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "id": "xRntWyVyIN4U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lD8T1617I0u2"
      },
      "id": "lD8T1617I0u2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
