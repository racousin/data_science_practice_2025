{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fd09113-2f55-43ea-914c-ab3c0e3ee3d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge, RidgeClassifier\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, BaggingRegressor, StackingRegressor, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.base import RegressorMixin, ClassifierMixin, BaseEstimator\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "#from xgboost import XGBClassifier, XGBRegressor\n",
        "#from lightgbm import LGBMClassifier, LGBMRegressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80dc69a1-e21d-4310-a0a4-5cb5b7d69fb4",
      "metadata": {},
      "source": [
        "### Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae3aeb5-dcdf-4690-b869-d211a02f303c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# URLs of the files\n",
        "train_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module6/exercise/module6_exercise_train.csv'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module6/exercise/module6_exercise_test.csv'\n",
        "\n",
        "# Function to download a file\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure we notice bad responses\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "# Downloading the files\n",
        "download_file(train_data_url, 'module6_exercise_train.csv')\n",
        "download_file(test_data_url, 'module6_exercise_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83ae6bb0-639c-472a-8748-4bbbdb96e142",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train = pd.read_csv('module6_exercise_train.csv', index_col='index')\n",
        "data_test = pd.read_csv('module6_exercise_test.csv', index_col='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea77dab9-6dcc-42bc-894b-1d8a23774d33",
      "metadata": {},
      "source": [
        "### Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a92c5579-a099-4018-a22e-06513a885133",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead6e347-8a41-489d-a184-98d4259ff9be",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d62d9ab-50b9-4d5b-9611-adbd10840ae5",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5babb7-ad30-43eb-b3ec-4eebca726764",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e5dd21-1d73-415c-a4a7-c1c869ded46b",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314189f7-31bb-47a9-afca-97d9ec489b60",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the distribution using seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data_train['end_of_day_return'], bins=50, kde=True)\n",
        "plt.title('Distribution of End of Day Return')\n",
        "plt.xlabel('End of Day Return')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab85a4fe-b7d4-47f7-9d4a-4a155c44e24c",
      "metadata": {},
      "source": [
        "### Model Building and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a86f0e4-55fa-46a9-8f53-735cf62aa6ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "y = data_train.pop('end_of_day_return')\n",
        "X = data_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "746ed3ab-0de5-4c35-94aa-76251187dede",
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_accuracy(y_true, y_pred):\n",
        "    weights = np.abs(y_true)\n",
        "    \n",
        "    # Compute the sign of true and predicted values\n",
        "    sign_true = np.sign(y_true)\n",
        "    sign_pred = np.sign(y_pred)\n",
        "    \n",
        "    # Correct predictions where the sign of the true and predicted values match\n",
        "    correct_predictions = sign_true == sign_pred\n",
        "    \n",
        "    # Compute the weighted accuracy\n",
        "    weighted_acc = np.sum(weights * correct_predictions) / np.sum(weights)\n",
        "    \n",
        "    return weighted_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04424025-b909-46d3-af2d-0e7d6fb9107b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to plot the evaluation results\n",
        "def plot_results(mse_train, mse_test, w_acc_train, w_acc_test):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # MSE plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(mse_train, label=\"Train MSE\", marker='o')\n",
        "    plt.plot(mse_test, label=\"Test MSE\", marker='o')\n",
        "    plt.fill_between(range(len(mse_train)), np.min(mse_train), np.max(mse_train), color='blue', alpha=0.1)\n",
        "    plt.fill_between(range(len(mse_test)), np.min(mse_test), np.max(mse_test), color='orange', alpha=0.1)\n",
        "    plt.title(\"MSE over Folds\")\n",
        "    plt.xlabel(\"Fold\")\n",
        "    plt.ylabel(\"MSE\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # weighted_accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(w_acc_train, label=\"Train weighted_accuracy\", marker='o')\n",
        "    plt.plot(w_acc_test, label=\"Test weighted_accuracy\", marker='o')\n",
        "    plt.fill_between(range(len(w_acc_train)), np.min(w_acc_train), np.max(w_acc_train), color='blue', alpha=0.1)\n",
        "    plt.fill_between(range(len(w_acc_test)), np.min(w_acc_test), np.max(w_acc_test), color='orange', alpha=0.1)\n",
        "    plt.title(\"weighted_accuracy over Folds\")\n",
        "    plt.xlabel(\"Fold\")\n",
        "    plt.ylabel(\"weighted_accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_multi_model_results(results):\n",
        "    # Set up the plot\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 20))\n",
        "    \n",
        "    # Colors for train and test\n",
        "    train_color = 'skyblue'\n",
        "    test_color = 'lightgreen'\n",
        "    \n",
        "    # Plot MSE\n",
        "    ax1.set_title('Mean Squared Error (MSE) Comparison', fontsize=16)\n",
        "    ax1.set_ylabel('MSE', fontsize=12)\n",
        "    ax1.set_xlabel('Models', fontsize=12)\n",
        "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
        "    \n",
        "    # Plot weighted_accuracy\n",
        "    ax2.set_title('weighted_accuracy Comparison', fontsize=16)\n",
        "    ax2.set_ylabel('weighted_accuracy', fontsize=12)\n",
        "    ax2.set_xlabel('Models', fontsize=12)\n",
        "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
        "    \n",
        "    x = np.arange(len(results))\n",
        "    width = 0.35\n",
        "    \n",
        "    for i, (model_name, scores) in enumerate(results.items()):\n",
        "        # MSE\n",
        "        mse_train = scores['mse_train']\n",
        "        mse_test = scores['mse_test']\n",
        "        \n",
        "        ax1.bar(x[i] - width/2, np.mean(mse_train), width, label='Train' if i == 0 else \"\", \n",
        "                color=train_color, alpha=0.7)\n",
        "        ax1.bar(x[i] + width/2, np.mean(mse_test), width, label='Test' if i == 0 else \"\", \n",
        "                color=test_color, alpha=0.7)\n",
        "        \n",
        "        ax1.errorbar(x[i] - width/2, np.mean(mse_train), \n",
        "                     yerr=[[np.mean(mse_train)-np.min(mse_train)], [np.max(mse_train)-np.mean(mse_train)]], \n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "        ax1.errorbar(x[i] + width/2, np.mean(mse_test), \n",
        "                     yerr=[[np.mean(mse_test)-np.min(mse_test)], [np.max(mse_test)-np.mean(mse_test)]], \n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "        \n",
        "        # weighted_accuracy\n",
        "        w_acc_train = scores['w_acc_train']\n",
        "        w_acc_test = scores['w_acc_test']\n",
        "        \n",
        "        ax2.bar(x[i] - width/2, np.mean(w_acc_train), width, label='Train' if i == 0 else \"\", \n",
        "                color=train_color, alpha=0.7)\n",
        "        ax2.bar(x[i] + width/2, np.mean(w_acc_test), width, label='Test' if i == 0 else \"\", \n",
        "                color=test_color, alpha=0.7)\n",
        "        \n",
        "        ax2.errorbar(x[i] - width/2, np.mean(w_acc_train), \n",
        "                     yerr=[[np.mean(w_acc_train)-np.min(w_acc_train)], [np.max(w_acc_train)-np.mean(w_acc_train)]], \n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "        ax2.errorbar(x[i] + width/2, np.mean(w_acc_test), \n",
        "                     yerr=[[np.mean(w_acc_test)-np.min(w_acc_test)], [np.max(w_acc_test)-np.mean(w_acc_test)]], \n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "    \n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(results.keys(), rotation=45, ha='right')\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels(results.keys(), rotation=45, ha='right')\n",
        "    \n",
        "    ax1.legend(loc='upper left')\n",
        "    ax2.legend(loc='upper left')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6c73c55-9684-411c-9ad3-ba6f9ba7de8d",
      "metadata": {},
      "source": [
        "#### Simple Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d6a7f41-1184-4172-ab8b-220f45ab2172",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to handle train-test evaluation in a fold\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test, model):\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions on train set\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    # Make predictions on train set\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    \n",
        "    # Compute MSE for train and test\n",
        "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "    \n",
        "    # Compute weighted_accuracy\n",
        "    \n",
        "    w_acc_train = weighted_accuracy(y_train, y_pred_train)\n",
        "    w_acc_test = weighted_accuracy(y_test, y_pred_test)\n",
        "    \n",
        "    return mse_train, mse_test, w_acc_train, w_acc_test\n",
        "\n",
        "\n",
        "def run_multi_model_cv(X, y, models, n_splits=5):\n",
        "    fold = KFold(n_splits=n_splits)\n",
        "    results = {name: {'mse_train': [], 'mse_test': [], 'w_acc_train': [], 'w_acc_test': []} \n",
        "               for name in models.keys()}\n",
        "    \n",
        "    for train_index, test_index in fold.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
        "        y_train, y_test = y.iloc[train_index].copy(), y.iloc[test_index].copy()\n",
        "        \n",
        "        for name, model in models.items():\n",
        "            mse_train, mse_test, w_acc_train, w_acc_test = train_and_evaluate(\n",
        "                X_train, X_test, y_train, y_test, model\n",
        "            )\n",
        "            results[name]['mse_train'].append(mse_train)\n",
        "            results[name]['mse_test'].append(mse_test)\n",
        "            results[name]['w_acc_train'].append(w_acc_train)\n",
        "            results[name]['w_acc_test'].append(w_acc_test)\n",
        "        # Find the model with the best mean w_acc test score\n",
        "    best_mean_w_acc = -1\n",
        "    best_model = None\n",
        "    best_min_w_acc = None\n",
        "    best_max_w_acc = None\n",
        "    \n",
        "    for name, result in results.items():\n",
        "        w_acc_test_scores = result['w_acc_test']\n",
        "        mean_w_acc_test = sum(w_acc_test_scores) / len(w_acc_test_scores)  # Calculate mean w_acc score\n",
        "        min_w_acc_test = min(w_acc_test_scores)  # Minimum w_acc score\n",
        "        max_w_acc_test = max(w_acc_test_scores)  # Maximum w_acc score\n",
        "        \n",
        "        if mean_w_acc_test > best_mean_w_acc:\n",
        "            best_mean_w_acc = mean_w_acc_test\n",
        "            best_min_w_acc = min_w_acc_test\n",
        "            best_max_w_acc = max_w_acc_test\n",
        "            best_model = name\n",
        "    \n",
        "    # Print the best mean w_acc test score, min, max, and the associated model\n",
        "    print(f\"Best mean w_acc test score: {best_mean_w_acc:.4f} by model: {best_model}\")\n",
        "    print(f\"Min w_acc test score: {best_min_w_acc:.4f}, Max w_acc test score: {best_max_w_acc:.4f}\")\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891e158b-b199-41ac-a244-537429eb1d22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Run cross-validation\n",
        "results = run_multi_model_cv(X, y, {\"RandomForestRegressor\": RandomForestRegressor(n_jobs=-1)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b0380d-c7ee-413e-9b13-756f8e7e3847",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Plot the results\n",
        "plot_results(results[\"RandomForestRegressor\"][\"mse_train\"],\n",
        "             results[\"RandomForestRegressor\"][\"mse_test\"],\n",
        "             results[\"RandomForestRegressor\"][\"w_acc_train\"],\n",
        "             results[\"RandomForestRegressor\"][\"w_acc_test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc76e0a4-6af0-43eb-af13-0bad0adbbdbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Ridge': Ridge(),\n",
        "    'Decision Tree Regressor': RandomForestRegressor(n_jobs=-1)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "264692a5-ce69-4567-a108-669d0cfcc3a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run cross-validation for regression models\n",
        "results = run_multi_model_cv(X, y, models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78ea32cf",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250f1f68-32b7-47d3-8934-952785a3046f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot MSE results for regression models\n",
        "plot_multi_model_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0e21e12-8f5d-4fe5-beb0-566d8a971ae7",
      "metadata": {},
      "source": [
        "#### Manage properly the objective weighted_accuracy\n",
        "should we create different classes? custom loss?\n",
        "\n",
        "Create Compare and Optimize different models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "922f9c81",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# ---- ta m√©trique ----\n",
        "def weighted_accuracy(y_true, y_pred):\n",
        "    weights = np.abs(y_true)\n",
        "    sign_true = np.sign(y_true)\n",
        "    sign_pred = np.sign(y_pred)\n",
        "    correct_predictions = sign_true == sign_pred\n",
        "    weighted_acc = np.sum(weights * correct_predictions) / np.sum(weights)\n",
        "    return weighted_acc\n",
        "\n",
        "# ---- cr√©ation du scorer ----\n",
        "weighted_acc_scorer = make_scorer(weighted_accuracy, greater_is_better=True)\n",
        "\n",
        "# ---- pipeline Ridge ----\n",
        "pipe = make_pipeline(StandardScaler(), Ridge())\n",
        "\n",
        "# ---- espace de recherche ----\n",
        "param_space = {'ridge__alpha': Real(1e3, 1e+6, prior='log-uniform')}\n",
        "\n",
        "# ---- optimisation bay√©sienne ----\n",
        "opt = BayesSearchCV(\n",
        "    estimator=pipe,\n",
        "    search_spaces=param_space,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    scoring=weighted_acc_scorer,  # ‚¨ÖÔ∏è ici ta m√©trique personnalis√©e\n",
        "    random_state=0,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# ---- apprentissage ----\n",
        "opt.fit(X, y)\n",
        "\n",
        "# ---- r√©sultats ----\n",
        "print(\"‚úÖ Meilleur alpha :\", opt.best_params_['ridge__alpha'])\n",
        "print(\"üìà Meilleur score (Weighted Accuracy) :\", opt.best_score_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0431ff6-0e5d-4ead-8735-84e1a728ef11",
      "metadata": {},
      "source": [
        "### Submission:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9e1e0ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "data_train = pd.read_csv('module6_exercise_train.csv', index_col='index')\n",
        "y_train = data_train.pop('end_of_day_return')\n",
        "X_train = data_train.copy()\n",
        "X,y = X_train, y_train\n",
        "\n",
        "# --- Ta m√©trique personnalis√©e ---\n",
        "def weighted_accuracy(y_true, y_pred):\n",
        "    weights = np.abs(y_true)\n",
        "    sign_true = np.sign(y_true)\n",
        "    sign_pred = np.sign(y_pred)\n",
        "    correct_predictions = sign_true == sign_pred\n",
        "    weighted_acc = np.sum(weights * correct_predictions) / np.sum(weights)\n",
        "    return weighted_acc\n",
        "\n",
        "weighted_acc_scorer = make_scorer(weighted_accuracy, greater_is_better=True)\n",
        "\n",
        "# --- Pipeline Random Forest ---\n",
        "pipe = make_pipeline(\n",
        "    StandardScaler(), \n",
        "    RandomForestRegressor(random_state=0)\n",
        ")\n",
        "\n",
        "# --- Espace de recherche hyperparam√®tres ---\n",
        "param_space = {\n",
        "    'randomforestregressor__n_estimators': Integer(20,40),\n",
        "    'randomforestregressor__max_depth': Integer(2, 20),\n",
        "    'randomforestregressor__min_samples_split': Integer(2, 20),\n",
        "    'randomforestregressor__min_samples_leaf': Integer(1, 20)\n",
        "}\n",
        "\n",
        "# --- Optimisation bay√©sienne ---\n",
        "opt = BayesSearchCV(\n",
        "    estimator=pipe,\n",
        "    search_spaces=param_space,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    scoring=weighted_acc_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "# --- Apprentissage ---\n",
        "opt.fit(X, y)\n",
        "\n",
        "# --- R√©sultats ---\n",
        "print(\"‚úÖ Meilleurs hyperparam√®tres :\", opt.best_params_)\n",
        "print(\"üìà Weighted accuracy :\", opt.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfc1d195",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = run_multi_model_cv(X, y, {\"RandomForest\": RandomForestRegressor(n_estimators=20, max_depth=20, min_samples_split=18,min_samples_leaf=3,n_jobs=-1)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f21c4ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = run_multi_model_cv(X, y, {\"Ridge\": Ridge(alpha = 23709.55850416396)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1343bf72",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = run_multi_model_cv(X, y, {\"Ridge\": Ridge()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe4a5d9-be2e-40f1-b1b4-59cac5e7197b",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train = pd.read_csv('module6_exercise_train.csv', index_col='index')\n",
        "X_test = pd.read_csv('module6_exercise_test.csv', index_col='index')\n",
        "y_train = data_train.pop('end_of_day_return')\n",
        "X_train = data_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da617b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = RandomForestRegressor(n_estimators=20, max_depth=20, min_samples_split=18,min_samples_leaf=3,n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77593908",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(y_pred)\n",
        "plt.plot(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9877df-0e30-40ed-91a0-69511d359033",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "submission = pd.DataFrame({\n",
        "    'index': X_test.index,\n",
        "    'end_of_day_return': y_pred #best_model.predict(X_test_final)\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False, sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d162216-2f3a-4d63-bbbb-66f0a4ce6bcb",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
