{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ed6d52b-732b-4462-8f1d-75741067ecba",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea3ee8dd-5dae-4900-8f89-2f57a02231ff",
      "metadata": {},
      "source": [
        "## Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dff7b6c3-5df9-4f2c-87e9-38d9a812cbcc",
      "metadata": {},
      "source": [
        "### Files sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19b8c48c-9f5c-4796-b25e-cd52e1a5dc22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# URLs of the files\n",
        "train_datas_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/module4_exercise_train.zip'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module4/exercise/Neighborhood_Market_data.csv'\n",
        "\n",
        "# Function to download a file\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure we notice bad responses\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "# Downloading the files\n",
        "download_file(train_datas_url, 'module4_exercise_train.zip')\n",
        "download_file(test_data_url, 'Neighborhood_Market_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee90a752",
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "# Unzipping the training data\n",
        "with zipfile.ZipFile('module4_exercise_train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('module4_exercise_train')\n",
        "print('Unzipped training data to module4_exercise_train/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72397636-457a-4f62-818c-18d4967396d1",
      "metadata": {},
      "source": [
        "#### CityMart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13aa4dce-b3ac-4b52-939c-081445f17494",
      "metadata": {},
      "outputs": [],
      "source": [
        "# read \"CityMart_data.csv\"\n",
        "citymart_data = pd.read_csv(\"module4_exercise_train/CityMart_data.csv\", index_col=0, parse_dates=[\"last_modified\"], dtype={\"store_name\": \"category\"})\n",
        "#pd.read_csv('Neighborhood_Market_data.csv',index_col=\"item_code\")\n",
        "\n",
        "display(citymart_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce18f0d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "citymart_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b0d90a",
      "metadata": {},
      "outputs": [],
      "source": [
        "citymart_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47706737",
      "metadata": {},
      "outputs": [],
      "source": [
        "citymart_data.dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d16f20-40d2-457c-a3fc-5f7a416be0aa",
      "metadata": {},
      "source": [
        "#### Greenfield_Grocers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c00cc32",
      "metadata": {},
      "outputs": [],
      "source": [
        "greenfield_data = pd.read_csv('module4_exercise_train/Greenfield_Grocers_data.csv',sep=\"|\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3800ea14",
      "metadata": {},
      "outputs": [],
      "source": [
        "greenfield_data = pd.read_csv('module4_exercise_train/Greenfield_Grocers_data.csv',sep=\"|\")\n",
        "greenfield_data.columns = greenfield_data.iloc[2]  \n",
        "greenfield_data.columns=list(greenfield_data.columns.str.lower())\n",
        "greenfield_data=greenfield_data.drop([0,1,2])\n",
        "greenfield_data=greenfield_data.set_index(\"item_code\")\n",
        "greenfield_data=greenfield_data[[              'store_name',                     'mass',\n",
        "               'dimension_length',          'dimension_width',\n",
        "               'dimension_height', 'days_since_last_purchase',\n",
        "                 'package_volume',                'stock_age',\n",
        "                  'quantity_sold',            'last_modified']]\n",
        "display(greenfield_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5c0084",
      "metadata": {},
      "outputs": [],
      "source": [
        "greenfield_data.info()\n",
        "greenfield_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6711a8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "greenfield_data.dtypes\n",
        "print(greenfield_data.columns)\n",
        "# conversion auto de toutes les colonnes numériques possibles\n",
        "for col in [ 'mass', 'dimension_length', 'dimension_width',\n",
        "       'dimension_height', 'days_since_last_purchase', 'package_volume',\n",
        "       'stock_age', 'quantity_sold']:\n",
        "    greenfield_data[col] = pd.to_numeric(greenfield_data[col], errors=\"ignore\")\n",
        "greenfield_data.dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86db4848-6a0f-4742-b4ce-4afe50fd1c09",
      "metadata": {},
      "source": [
        "#### Outlet_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7738fac-9711-4cc7-9b12-e564c539ba9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# read \"SuperSaver_Outlet_data.xlsx\"\n",
        "supersaver_data = pd.read_excel('module4_exercise_train/SuperSaver_Outlet_data.xlsx',sheet_name=None)\n",
        "\n",
        "supersaver_data_quantity = supersaver_data[\"Quantity\"]\n",
        "supersaver_data_info = supersaver_data[\"Info\"]\n",
        "display(supersaver_data_info)\n",
        "display(supersaver_data_quantity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d33d5c52",
      "metadata": {},
      "outputs": [],
      "source": [
        "supersaver_data_info.columns=['item code', 'store name', 'mass', 'dimension length', 'dimension width', 'dimension height', 'days_since last_purchase', 'package volume', 'stock age','suppp']\n",
        "supersaver_data_info=supersaver_data_info[['item code', 'store name', 'mass', 'dimension length', 'dimension width', 'dimension height', 'days_since last_purchase', 'package volume', 'stock age']]\n",
        "\n",
        "# Normaliser les noms de colonnes (remplacer espaces par underscore)\n",
        "supersaver_data_info.columns = [c.strip().replace(\" \", \"_\") for c in supersaver_data_info.columns]\n",
        "supersaver_data_quantity.columns = [c.strip().replace(\" \", \"_\") for c in supersaver_data_quantity.columns]\n",
        "\n",
        "display(supersaver_data_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eb328f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "display(supersaver_data_quantity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d718e7cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "supersaver_data_final = supersaver_data_info.merge(\n",
        "    supersaver_data_quantity,\n",
        "    on=\"item_code\",   # clé commune\n",
        "    how=\"left\"        # on garde tous les items du DataFrame \"info\"\n",
        ")\n",
        "supersaver_data_final = supersaver_data_final.set_index(\"item_code\")\n",
        "\n",
        "display(supersaver_data_final)\n",
        "print(supersaver_data_final.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358b6c1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "supersaver_data_final.dtypes\n",
        "# conversion auto de toutes les colonnes numériques possibles\n",
        "for col in supersaver_data_final.columns:\n",
        "    supersaver_data_final[col] = pd.to_numeric(supersaver_data_final[col], errors=\"ignore\")\n",
        "supersaver_data_final.dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e716a08-25b0-4554-9627-285c4c03212c",
      "metadata": {},
      "source": [
        "#### HighStreet_Bazaar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0fad164-436e-46db-acba-04a634c0b00c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# read 'HighStreet_Bazaar_data.json'\n",
        "highstreet_data = pd.read_json('module4_exercise_train/HighStreet_Bazaar_data.json')\n",
        "highstreet_data=highstreet_data.set_index(\"item_code\")\n",
        "display(highstreet_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ab19c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "highstreet_data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f851e40e-4644-4b3f-9636-04ec5010ba89",
      "metadata": {},
      "source": [
        "#### Aggregate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70657621",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#display(citymart_data)\n",
        "#print(citymart_data.columns)\n",
        "print(citymart_data.dtypes)\n",
        "\n",
        "#display(greenfield_data)\n",
        "#print(greenfield_data.columns)\n",
        "print(greenfield_data.dtypes)\n",
        "\n",
        "#display(supersaver_data_final)\n",
        "#print(supersaver_data_final.columns)\n",
        "print(supersaver_data_final.dtypes)\n",
        "\n",
        "#display(highstreet_data)\n",
        "#print(highstreet_data.columns)\n",
        "print(highstreet_data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "367bf832",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31437ea7",
      "metadata": {},
      "outputs": [],
      "source": [
        "#display(citymart_data)\n",
        "#print(citymart_data.columns)\n",
        "print(citymart_data.dtypes)\n",
        "\n",
        "#display(greenfield_data)\n",
        "#print(greenfield_data.columns)\n",
        "print(greenfield_data.dtypes)\n",
        "\n",
        "#display(supersaver_data_final)\n",
        "#print(supersaver_data_final.columns)\n",
        "print(supersaver_data_final.dtypes)\n",
        "\n",
        "#display(highstreet_data)\n",
        "#print(highstreet_data.columns)\n",
        "print(highstreet_data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c5320e",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.concat([citymart_data, greenfield_data, supersaver_data_final, highstreet_data], axis=0)\n",
        "# Supposons que ton DataFrame s'appelle df\n",
        "display(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1fb8557",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f02d8db",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"citymart_data shape:\", citymart_data.shape)\n",
        "print(\"greenfield_data shape:\", greenfield_data.shape)\n",
        "print(\"supersaver_data_final shape:\", supersaver_data_final.shape)\n",
        "print(\"highstreet_data shape:\", highstreet_data.shape)\n",
        "\n",
        "print(\"\\nComposition de data par store_name:\")\n",
        "print(data['store_name'].value_counts())\n",
        "\n",
        "print(\"\\nNb de lignes sans cible (quantity_sold) dans data:\")\n",
        "print(data['quantity_sold'].isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891b07e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f9bbff-1f14-48f3-a6f8-76ac701644cf",
      "metadata": {},
      "source": [
        "#### Simple baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "143b8d21-b305-4e5a-a83a-8d1d3359d173",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "def get_simple_baseline(data, fillna_value=-1, drop_cols=None, k_fold=5, scaler='standard', model='linear', metric='mae', target_col=None, X_data_test=None):\n",
        "    \n",
        "    data = data.copy()\n",
        "    # Handle missing values\n",
        "    data.fillna(fillna_value, inplace=True)\n",
        "    if X_data_test is not None:\n",
        "        X_data_test = X_data_test.copy()\n",
        "        X_data_test.fillna(fillna_value, inplace=True)\n",
        "    \n",
        "    # Drop unwanted columns\n",
        "    if drop_cols:\n",
        "        data.drop(drop_cols, axis=1, inplace=True)\n",
        "        if X_data_test is not None:\n",
        "            X_data_test.drop(drop_cols, axis=1, inplace=True)\n",
        "\n",
        "    # Split data into features (X) and target (y)\n",
        "    y = data[target_col]\n",
        "    X = data.drop(target_col, axis=1)\n",
        "\n",
        "    # Feature scaling\n",
        "    if scaler == 'standard':\n",
        "        scaler = StandardScaler()\n",
        "    elif scaler == 'minmax':\n",
        "        scaler = MinMaxScaler()\n",
        "    else:\n",
        "        scaler = None\n",
        "    \n",
        "    if scaler:\n",
        "        X = scaler.fit_transform(X)\n",
        "        if X_data_test is not None:\n",
        "            X_data_test = scaler.transform(X_data_test)\n",
        "\n",
        "    # Initialize the model\n",
        "    if model == 'linear':\n",
        "        model = LinearRegression()\n",
        "    elif model == 'logistic':\n",
        "        model = LogisticRegression()\n",
        "    elif model == 'random_forest':\n",
        "        model = RandomForestClassifier()\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model type\")\n",
        "\n",
        "    # Initialize cross-validation\n",
        "    kf = KFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    # Train and evaluate using k-fold cross-validation\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # Evaluate using the specified metric\n",
        "        if metric == 'mae':\n",
        "            score = mean_absolute_error(y_test, y_pred)\n",
        "        elif metric == 'accuracy':\n",
        "            score = accuracy_score(y_test, np.round(y_pred))\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported metric\")\n",
        "\n",
        "        scores.append(score)\n",
        "\n",
        "    if X_data_test is not None:\n",
        "        model.fit(X, y)\n",
        "        return np.mean(scores), model.predict(X_data_test)\n",
        "    \n",
        "    # Return the average score\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b7a46a-7c5e-4288-be2d-43269d0e859e",
      "metadata": {},
      "outputs": [],
      "source": [
        "get_simple_baseline(data, fillna_value=-1, drop_cols=['store_name', 'last_modified'], k_fold=5, scaler='standard', model='linear', metric='mae', target_col='quantity_sold')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "697e0db3-f0c3-4a9e-b032-a355e23e866c",
      "metadata": {},
      "source": [
        "### API sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f3436ce-88b5-49de-8209-05291c260ac0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_api(endpoint_url):\n",
        "    try:\n",
        "        # Make the GET request to the mock API\n",
        "        response = requests.get(endpoint_url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            print(data[\"message\"])\n",
        "            return data['data']\n",
        "        else:\n",
        "            print(f\"Failed to retrieve volume data. Status code: {response.status_code}\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "password = get_api(\"https://www.raphaelcousin.com/api/exercise/auth\")\n",
        "print(password)\n",
        "link=str(\"https://www.raphaelcousin.com/api/exercise/\"+password[\"password\"]+\"/prices\")\n",
        "\n",
        "prices = get_api(link)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6dc268e",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec42de20",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_prices = pd.DataFrame.from_dict(prices, orient=\"index\", columns=[\"price\"])\n",
        "print(df_prices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c0880c2-2338-4e43-a04c-fdaf90275592",
      "metadata": {},
      "source": [
        "#### Aggregate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc3484b-5ebc-4769-9889-90253a05d44c",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.merge(data, df_prices, left_index=True, right_index=True, how='left')\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb325b3-06f6-4c01-965e-08a833ed7c49",
      "metadata": {},
      "outputs": [],
      "source": [
        "get_simple_baseline(data, fillna_value=-1, drop_cols=['store_name', 'last_modified'], k_fold=5, scaler='standard', model='linear', metric='mae', target_col='quantity_sold')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2500a918-74a0-44eb-8a95-ec35cd3617ae",
      "metadata": {},
      "source": [
        "### Scrapping sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8f373c5-452d-408c-a9a4-5e905b361175",
      "metadata": {},
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Set up the Selenium WebDriver (e.g., Chrome)\n",
        "driver = webdriver.Chrome()  # Make sure ChromeDriver is installed\n",
        "# driver = webdriver.Firefox()\n",
        "# driver = webdriver.Edge()\n",
        "# driver = webdriver.Safari()\n",
        "\n",
        "# Open the URL\n",
        "url = 'https://www.raphaelcousin.com/module4/scrapable-data'\n",
        "driver.get(url)\n",
        "\n",
        "# Wait for the page to fully load (increase time if needed)\n",
        "time.sleep(5)\n",
        "\n",
        "# Get the fully rendered page source\n",
        "html = driver.page_source\n",
        "\n",
        "# Parse the HTML with BeautifulSoup\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# Initialize lists to store scraped data\n",
        "exercise_data = []\n",
        "\n",
        "# Find both tables\n",
        "tables = soup.find_all('table')\n",
        "\n",
        "# Close the Selenium WebDriver\n",
        "driver.quit()\n",
        "\n",
        "# Scrape the second table (Exercise Data)\n",
        "course_table = tables[1]\n",
        "for row in course_table.find('tbody').find_all('tr'):\n",
        "    cols = row.find_all('td')\n",
        "    #exercise_data.append({ TODO })\n",
        "\n",
        "# Convert the lists to pandas DataFrames\n",
        "df_exercise = pd.DataFrame(exercise_data)\n",
        "df_exercise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7666fdbc-4735-4758-a3fe-8a1c87eff295",
      "metadata": {},
      "source": [
        "#### Aggregate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d8a96a-aad2-4103-92b8-8635987bfa2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.merge(data, df_exercise, left_index=True, right_index=True, how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ab523c-53e6-43f7-8602-55bb32592305",
      "metadata": {},
      "outputs": [],
      "source": [
        "get_simple_baseline(data, fillna_value=-1, drop_cols=['store_name', 'last_modified'], k_fold=5, scaler='standard', model='linear', metric='mae', target_col='quantity_sold')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "032415ae-f5d6-4689-9835-44124fa4afa2",
      "metadata": {},
      "source": [
        "### Generating Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51ebcf1c-dd7a-4dbd-8b74-326c45c81872",
      "metadata": {},
      "outputs": [],
      "source": [
        "#X_test =  read  Neighborhood_Market_data\n",
        "\n",
        "# read\n",
        "df_StoreN =  pd.read_csv(\"Neighborhood_Market_data.csv\", sep=\",\", index_col='item_code')\n",
        "df_StoreN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dada6c87-c1a3-4cfb-bd1c-326908e94276",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_StoreN = pd.merge(df_StoreN, df_prices, left_index=True, right_index=True, how='left')\n",
        "df_StoreN = pd.merge(df_StoreN, df_exercise, left_index=True, right_index=True, how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8d5c235-2415-42eb-848e-b1fe02800531",
      "metadata": {},
      "outputs": [],
      "source": [
        "_, y_pred = get_simple_baseline(data, fillna_value=-1, drop_cols=['store_name', 'last_modified'], k_fold=5, scaler='standard', model='linear', metric='mae', target_col='quantity_sold', X_data_test = df_StoreN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d179ac-e982-4a06-931f-8e6fdf24dc7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "    'item_code': df_StoreN.index,\n",
        "    'quantity_sold': y_pred # your_prediction\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False, sep=',')\n",
        "submission.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
