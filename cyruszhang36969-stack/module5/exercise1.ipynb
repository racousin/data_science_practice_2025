{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6314701b-8e9a-4984-be12-6b67ed11eb5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b02c5c8-5383-4f41-8eec-baa16e5b3300",
      "metadata": {},
      "source": [
        "### Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850f0188-75e0-4591-bfb2-430be0f5f089",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# URLs of the files\n",
        "train_data_url = 'https://www.raphaelcousin.com/modules/module5/exercise/module5_exercise_train.csv'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/module5/exercise/module5_exercise_test.csv'\n",
        "\n",
        "# Function to download a file\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure we notice bad responses\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "# Downloading the files\n",
        "download_file(train_data_url, 'module5_exercise_train.csv')\n",
        "download_file(test_data_url, 'module5_exercise_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aec8aa5-d188-407d-8422-cf4d54ccac63",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train =  pd.read_csv(\"module5_exercise_train.csv\", sep=\",\")\n",
        "df_test =  pd.read_csv(\"module5_exercise_test.csv\", sep=\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60fa867-ddfe-403d-ba84-071792339e6f",
      "metadata": {},
      "source": [
        "### Data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "823a4916-1a3a-4f43-989e-4b9441cc142d",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Make a complete analysis on data preprocessing\n",
        "# Inconsistencies 数据类型或值不一致\n",
        "# Duplicates (data.duplicated().sum()) 重复\n",
        "# Missing values (data.isnull().sum()) 缺失值\n",
        "# Categorical 分类变量及其分布\n",
        "# Outliers 数值特征中的异常值\n",
        "# Feature Engineering 特征工程的潜力\n",
        "# Feature Selection and/or Dimensionality Reduction 特征选择或降维的机会"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2a9ca3-d867-41aa-9cd2-67aadf0df23d",
      "metadata": {},
      "outputs": [],
      "source": [
        "#pd.concat将df_train和df_test按（行）纵向拼接\n",
        "data = pd.concat([df_train, df_test], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a852e1b0-224e-4db6-921e-3ac3df414bec",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c046b07a-845c-460b-a692-27a97ec3d613",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "670328c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bed93e3-c3df-44a1-ab90-9b35157ffa24",
      "metadata": {},
      "outputs": [],
      "source": [
        "#绘制指定特征在给定日期范围内的时间序列图\n",
        "def plot_feature_over_time(df, feature, date_id_start, date_id_end):\n",
        "    df_filtered = df[(df['date'] >= date_id_start) & (df['date'] <= date_id_end)]\n",
        "    \n",
        "    if feature not in df_filtered.columns:\n",
        "        print(f\"Feature '{feature}' not found in the DataFrame.\")\n",
        "        return\n",
        "    \n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(df_filtered['date'], df_filtered[feature], label=feature, linestyle='-')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(feature)\n",
        "    plt.title(f'{feature} from {date_id_start} to {date_id_end}')\n",
        "    plt.xticks(rotation=45) #横轴刻度旋转 45 度，避免文字重叠\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1fe2013-d460-46c4-a461-b9dfed5478f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['date'] = pd.to_datetime(data['date'])\n",
        "#将 data 数据框中的 date 列转换为 datetime 类型"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf0b181",
      "metadata": {},
      "source": [
        "#### Detecting Inconsistencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86edad2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "features = df_train.columns\n",
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fb28d41",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_date = pd.DataFrame(data[\"date\"])\n",
        "print(data_date.applymap(lambda x: not re.match(r\"\\d{4}-\\d{2}-\\d{2}\", str(x))).sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3de24ae2",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc561e06",
      "metadata": {},
      "outputs": [],
      "source": [
        "kmh_count=data['wind_speed'].str.contains('km/h').sum()\n",
        "ms_count=data['wind_speed'].str.contains('m/s').sum()\n",
        "\n",
        "print(f\"Number of 'km/h' in wind_speed: {kmh_count}\")\n",
        "print(f\"Number of 'm/s' in wind_speed: {ms_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfce91db",
      "metadata": {},
      "source": [
        "We should standardize the units in 'wind_speed'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d5997a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_kmh(value:str):\n",
        "    if not isinstance(value, str) or pd.isna(value):\n",
        "        return None\n",
        "    if 'km/h' in value:\n",
        "        return float(value.split()[0])\n",
        "    elif 'm/s' in value:\n",
        "        return float(value.split()[0]) * 3.6\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e46694",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['wind_speed'] = data['wind_speed'].apply(convert_to_kmh)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1bed6f6",
      "metadata": {},
      "source": [
        "#### Detecting duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eac0185",
      "metadata": {},
      "outputs": [],
      "source": [
        "exact_duplicates = data[data.duplicated()]\n",
        "print(exact_duplicates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a7b360",
      "metadata": {},
      "outputs": [],
      "source": [
        "def handle_duplicates(df):\n",
        "    df_no_duplicates = df.drop_duplicates()\n",
        "    return df_no_duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55db8a6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = handle_duplicates(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd7f1b4",
      "metadata": {},
      "source": [
        "#### Detecting Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa0acc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86449c5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25668c58",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(data.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Heatmap of Missing Values')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52f23565",
      "metadata": {},
      "source": [
        "Except for the 'oil_brent_price_indicator' column, all other columns have missing values.\n",
        "\n",
        "For the imputation of the categorical variable 'weather_condition', we decide to determine it based on its humidity.\n",
        "\n",
        "After a preliminary observation, we need to first address the outliers in **humidity** and **electricity_demand**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0508bef2",
      "metadata": {},
      "outputs": [],
      "source": [
        "outlier_indice_humidity=data[data['humidity'] > 200].index\n",
        "for i in outlier_indice_humidity:\n",
        "    print(data.loc[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1781a9a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "valid_mean_sunny = data[(data['weather_condition'] == 'Sunny') & (data['humidity'] <= 1000)]['humidity'].mean()\n",
        "data.loc[(data['weather_condition'] == 'Sunny') & (data['humidity'] > 1000), 'humidity'] = valid_mean_sunny\n",
        "\n",
        "valid_mean_rainy = data[(data['weather_condition'] == 'Rainy') & (data['humidity'] <= 1000)]['humidity'].mean()\n",
        "data.loc[(data['weather_condition'] == 'Rainy') & (data['humidity'] > 1000), 'humidity'] = valid_mean_rainy\n",
        "\n",
        "sns.boxplot(x=data['humidity'])\n",
        "plt.title('Box Plot for Outlier Detection')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829ea8c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.boxplot(x=data['electricity_demand'])\n",
        "plt.title('Box Plot for Outlier Detection')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69a19d0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.loc[data['electricity_demand'] <= 0, 'electricity_demand'] = abs(data['electricity_demand'])/1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "253abfc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.boxplot(x=data['electricity_demand'])\n",
        "plt.title('Box Plot for Outlier Detection')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21ba5856",
      "metadata": {},
      "source": [
        "Now we can start handling the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ebd60f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fill_weather_condition(weather_series):\n",
        "    weather_series = weather_series.copy()  # 避免修改原数据\n",
        "    n = len(weather_series)\n",
        "    \n",
        "    i = 0\n",
        "    while i < n:\n",
        "        if pd.isna(weather_series.iloc[i]):  # 如果当前值是缺失值\n",
        "            start = i  # 记录缺失值的起始位置\n",
        "            \n",
        "            # 找到连续缺失值的结束位置\n",
        "            while i < n and pd.isna(weather_series.iloc[i]):\n",
        "                i += 1\n",
        "            end = i  # 连续缺失值的结束位置（不包含）\n",
        "            \n",
        "            # 获取前后值\n",
        "            prev_value = weather_series.iloc[start - 1] if start > 0 else None\n",
        "            next_value = weather_series.iloc[end] if end < n else None\n",
        "            \n",
        "            # 填充逻辑\n",
        "            if prev_value == next_value and pd.notna(prev_value):\n",
        "                # 前后值相同，填充相同值\n",
        "                weather_series.iloc[start:end] = prev_value\n",
        "            elif pd.notna(prev_value) and pd.notna(next_value):\n",
        "                # 前后值不同，随机选择一个值填充\n",
        "                weather_series.iloc[start:end] = np.random.choice([prev_value, next_value])\n",
        "            elif pd.notna(prev_value):\n",
        "                # 只有前值存在，用前值填充\n",
        "                weather_series.iloc[start:end] = prev_value\n",
        "            elif pd.notna(next_value):\n",
        "                # 只有后值存在，用后值填充\n",
        "                weather_series.iloc[start:end] = next_value\n",
        "        else:\n",
        "            i += 1  # 非缺失值，继续向后遍历\n",
        "    \n",
        "    return weather_series\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb329b65",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['weather_condition'] = fill_weather_condition(data['weather_condition'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4fd511",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 按 weather_condition 分组，计算 humidity 的均值\n",
        "weather_condition_mean = data.groupby('weather_condition')['humidity'].mean()\n",
        "\n",
        "# 用对应的均值填补缺失值\n",
        "data['humidity'] = data.apply(\n",
        "    lambda row: weather_condition_mean[row['weather_condition']] if pd.isna(row['humidity']) else row['humidity'],\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc5827a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 按 weather_condition 分组，计算 wind_speed 的均值\n",
        "weather_condition_mean_wind_speed = data.groupby('weather_condition')['wind_speed'].mean()\n",
        "\n",
        "# 用对应的均值填补 wind_speed 的缺失值\n",
        "data['wind_speed'] = data.apply(\n",
        "    lambda row: weather_condition_mean_wind_speed[row['weather_condition']] if pd.isna(row['wind_speed']) else row['wind_speed'],\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d0bf3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 提取 temperature_station1 到 temperature_station10 的列名\n",
        "temperature_columns = [f'temperature_station{i}' for i in range(1, 11)]\n",
        "\n",
        "# 绘制折线图\n",
        "plt.figure(figsize=(14, 8))\n",
        "for col in temperature_columns:\n",
        "    plt.plot(data.index, data[col], label=col, alpha=0.7)  # 添加透明度以区分线条\n",
        "\n",
        "# 设置图表标题和轴标签\n",
        "plt.title('Temperature Trends Across Stations', fontsize=16)\n",
        "plt.xlabel('Index', fontsize=14)\n",
        "plt.ylabel('Temperature', fontsize=14)\n",
        "plt.legend(title='Stations', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9787eefa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 将 date 列设置为索引\n",
        "data = data.set_index('date')\n",
        "\n",
        "# 使用时间插值填补缺失值\n",
        "for col in [f'temperature_station{i}' for i in range(1, 11)]:\n",
        "    data[col] = data[col].interpolate(method='time')\n",
        "\n",
        "# 如果需要恢复索引\n",
        "data = data.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "777575bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 获取除了 temperature_station2 的其他列名\n",
        "stations = [f'temperature_station{i}' for i in range(1, 11) if i != 2]\n",
        "\n",
        "# 计算其他站点的均值并填补 temperature_station2 前两个缺失值\n",
        "data.loc[:1, 'temperature_station2'] = data.loc[:1, stations].mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb30ccc",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "for col in temperature_columns:\n",
        "    plt.plot(data.index[0:100], data[col][0:100], label=col, alpha=0.7)  # 添加透明度以区分线条\n",
        "\n",
        "# 设置图表标题和轴标签\n",
        "plt.title('Temperature Trends Across Stations', fontsize=16)\n",
        "plt.xlabel('Index', fontsize=14)\n",
        "plt.ylabel('Temperature', fontsize=14)\n",
        "plt.legend(title='Stations', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74456f8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab0e4d61",
      "metadata": {},
      "source": [
        "#### Detecting Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab73844",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78ab0452",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "for column in data.columns:\n",
        "    if column != 'oil_brent_price_indicator':\n",
        "        sns.boxplot(x=data[column])\n",
        "        plt.title('Box Plot for Outlier Detection')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea9cd9ce",
      "metadata": {},
      "source": [
        "#### Detecting Categorical Values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a52ca9",
      "metadata": {},
      "source": [
        "For the two categorical variables, `oil_brent_price_indicator` and `weather_condition`, we will convert them into numerical variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d0751dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_encoded = pd.get_dummies(data, columns=['oil_brent_price_indicator', 'weather_condition'])\n",
        "bool_columns = data_encoded.select_dtypes(include=['bool']).columns\n",
        "data_encoded[bool_columns] = data_encoded[bool_columns].astype(float)\n",
        "\n",
        "data_encoded.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "becf746d",
      "metadata": {},
      "source": [
        "#### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "457a892f",
      "metadata": {},
      "source": [
        "##### DateTime Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f51d4b55",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['year'] = data['date'].dt.year\n",
        "data['month'] = data['date'].dt.month\n",
        "data['day'] = data['date'].dt.day\n",
        "data['hour'] = data['date'].dt.hour\n",
        "\n",
        "# 检查处理结果\n",
        "print(data[['date', 'year', 'month', 'day', 'hour']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22cd440",
      "metadata": {},
      "source": [
        "##### Domain-Specific Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19643341",
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(1, 11):\n",
        "    station_col = f'temperature_station{i}'\n",
        "    feel_col = f'temperature_feel_station{i}'\n",
        "    data[feel_col] = data[station_col] - 0.55 * (1 - data['humidity'] / 100) * (data[station_col] - 14.5)\n",
        "\n",
        "# 检查结果\n",
        "feel_columns = [f'temperature_feel_station{i}' for i in range(1, 11)]\n",
        "print(data[feel_columns].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be577dec",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49044198",
      "metadata": {},
      "source": [
        "#### Feature Selection and Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6c580d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d99a81",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_with_demand = data[data['electricity_demand'].notna()].copy()\n",
        "data_without_demand = data[data['electricity_demand'].isna()].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15c84d43",
      "metadata": {},
      "outputs": [],
      "source": [
        "X=data_with_demand.drop(columns=['electricity_demand','date','weather_condition','oil_brent_price_indicator'])\n",
        "y=data_with_demand['electricity_demand']\n",
        "\n",
        "selector = SelectKBest(f_classif, k=5)  # Select top 5 features\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_features = selector.get_support(indices=True)\n",
        "feature_names = X.columns[selected_features]\n",
        "print(\"Selected features:\", feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212cb3f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 划分训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# 模型训练\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 模型预测\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# 计算误差\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# 输出结果\n",
        "print(f\"Train MSE: {train_mse:.4f}\")\n",
        "print(f\"Test MSE: {test_mse:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d00dd628-b436-4f3b-829d-38b18589a12b",
      "metadata": {},
      "source": [
        "### Data Preprocessing Evaluation Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86971ab4-1ef8-464b-afb5-0d750a8c4035",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Provide a complete data preprocessing transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c0d2c71-4cc8-4b7c-855b-9cfa19106d1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 1. Handle Inconsistencies\n",
        "# def handle_inconsistencies(X_train, y_train):\n",
        "#     X_train_no_inconsistencies = X_train.copy()\n",
        "#     X_train_no_inconsistencies['date'] =pd.to_datetime(X_train['date'])\n",
        "#     X_train_no_inconsistencies['wind_speed'] = X_train_no_inconsistencies['wind_speed'].apply(convert_to_kmh)\n",
        "#     return X_train_no_inconsistencies, y_train.copy()\n",
        "\n",
        "# # 2. Handling Duplicates\n",
        "# def handle_duplicates_2(X_train, y_train, X_val=None):\n",
        "#     X_train_no_duplicates = X_train.drop_duplicates()\n",
        "#     y_train_no_duplicates = y_train[X_train_no_duplicates.index]\n",
        "#     return X_train_no_duplicates, y_train_no_duplicates\n",
        "\n",
        "# # 3. Handling Outliers\n",
        "# def handle_outliers(X_train, y_train, X_val=None):\n",
        "#     if X_val is not None:\n",
        "#         #humidity\n",
        "#         valid_mean_sunny_def = X_train[(X_train['weather_condition'] == 'Sunny') & (X_train['humidity'] <= 1000)]['humidity'].mean()\n",
        "#         X_train.loc[(X_train['weather_condition'] == 'Sunny') & (X_train['humidity'] > 1000), 'humidity'] = valid_mean_sunny_def\n",
        "\n",
        "#         valid_mean_rainy_def = X_train[(X_train['weather_condition'] == 'Rainy') & (X_train['humidity'] <= 1000)]['humidity'].mean()\n",
        "#         X_train.loc[(X_train['weather_condition'] == 'Rainy') & (X_train['humidity'] > 1000), 'humidity'] = valid_mean_rainy_def\n",
        "\n",
        "#         #electricity_demand\n",
        "#         X_train.loc[X_train['electricity_demand'] <= 0, 'electricity_demand'] = abs(X_train['electricity_demand'])/1000\n",
        "\n",
        "#         return X_train.copy(), y_train, X_val.copy()\n",
        "#     else:\n",
        "#         return X_train.copy(), y_train\n",
        "\n",
        "# # 4. Handling Missing Values\n",
        "# def handle_missing_values(X_train, y_train, X_val=None):\n",
        "#     if X_val is not None:\n",
        "#         X_train['weather_condition'] = X_train['weather_condition'].apply(fill_weather_condition).fillna(-1)\n",
        "#         X_val = X_val.fillna(-1)\n",
        "#         return X_train.copy(), X_val.copy()\n",
        "#     else:\n",
        "#         X_train['weather_condition'] = X_train['weather_condition'].apply(fill_weather_condition).fillna(-1)\n",
        "#         return X_train\n",
        "    \n",
        "# # 5. Handling Categorical Values\n",
        "# def handle_categorical(X_train, y_train, X_val=None):\n",
        "#     if X_val is not None:\n",
        "#         return X_train.copy(), X_val.copy()\n",
        "#     else:\n",
        "#         return X_train.copy()\n",
        "\n",
        "# # 6. Feature Engineering\n",
        "# def feature_engineering(X_train, y_train, X_val=None):\n",
        "#     if X_val is not None:\n",
        "#         return X_train.copy(), y_train, X_val.copy()\n",
        "#     else:\n",
        "#         return X_train.copy(), y_train\n",
        "\n",
        "# # 7. Feature Selection and Dimensionality Reduction\n",
        "# def feature_selection(X_train, y_train, X_val=None):\n",
        "#     selected_columns = ['humidity', 'temperature_station1',\n",
        "#        'temperature_station2', 'temperature_station3', 'temperature_station4',\n",
        "#        'temperature_station5', 'temperature_station6', 'temperature_station7',\n",
        "#        'temperature_station8', 'temperature_station9', 'temperature_station10']\n",
        "#     if X_val is not None:\n",
        "#         return X_train[selected_columns], X_val[selected_columns]\n",
        "#     else:\n",
        "#         return X_train[selected_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b18081c-17f2-4809-bdf6-7181aac77199",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def evaluate_pipeline(X, y, n_splits=5):\n",
        "\n",
        "#     ### call transformations here, if there is no learning and no need to be crossval\n",
        "#     X, y = handle_inconsistencies(X, y)\n",
        "#     # X, y = handle_duplicates(X, y)\n",
        "#     X  = handle_missing_values(X, y)\n",
        "#     # X_train = handle_categorical(X, y)\n",
        "#     X, y = handle_outliers(X, y)\n",
        "#     # X, y = feature_engineering(XX, y)\n",
        "#     X = feature_selection(X, y)\n",
        "    \n",
        "#     model = LinearRegression()\n",
        "    \n",
        "#     tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "    \n",
        "#     train_scores = []\n",
        "#     val_scores = []\n",
        "    \n",
        "#     for fold, (train_index, val_index) in enumerate(tscv.split(X)):\n",
        "#         print(f\"Processing fold {fold + 1}/{n_splits}...\")\n",
        "        \n",
        "#         # Split data into train and validation sets\n",
        "#         X_train, X_val = X.iloc[train_index].copy(), X.iloc[val_index].copy()\n",
        "#         y_train, y_val = y.iloc[train_index].copy(), y.iloc[val_index].copy()\n",
        "\n",
        "#         ### call transformations here, if there is learning\n",
        "#         # X_train, y_train, X_val = handle_inconsistencies(X_train, y_train, X_val)\n",
        "#         X_train, y_train, X_val = handle_duplicates(X_train, y_train, X_val)\n",
        "#         # X_train, X_val = handle_missing_values(X_train, y_train, X_val)\n",
        "#         X_train, X_val = handle_categorical(X_train, y_train, X_val)\n",
        "#         # X_train, y_train, X_val = handle_outliers(X_train, y_train, X_val)\n",
        "#         X_train, y_train, X_val = feature_engineering(X_train, y_train, X_val)\n",
        "#         # X_train, X_val = feature_selection(X_train, y_train, X_val)\n",
        "        \n",
        "#         # Train the model\n",
        "#         model.fit(X_train, y_train)\n",
        "        \n",
        "#         # Predict on training set\n",
        "#         y_train_pred = model.predict(X_train)\n",
        "#         train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "#         train_scores.append(train_mse)\n",
        "        \n",
        "#         # Predict on validation set\n",
        "#         y_val_pred = model.predict(X_val)\n",
        "#         val_mse = mean_squared_error(y_val, y_val_pred)\n",
        "#         val_scores.append(val_mse)\n",
        "        \n",
        "#         print(f\"Fold {fold + 1} Train MSE: {train_mse:.4f}, Validation MSE: {val_mse:.4f}\")\n",
        "    \n",
        "#     # Compute mean, max, and min values for train and validation MSE\n",
        "#     mean_train_mse = np.mean(train_scores)\n",
        "#     max_train_mse = np.max(train_scores)\n",
        "#     min_train_mse = np.min(train_scores)\n",
        "    \n",
        "#     mean_val_mse = np.mean(val_scores)\n",
        "#     max_val_mse = np.max(val_scores)\n",
        "#     min_val_mse = np.min(val_scores)\n",
        "    \n",
        "#     # Print results\n",
        "#     print(\"\\nTrain MSE:\")\n",
        "#     print(f\"Mean: {mean_train_mse:.4f}, Max: {max_train_mse:.4f}, Min: {min_train_mse:.4f}\")\n",
        "    \n",
        "#     print(\"\\nValidation MSE:\")\n",
        "#     print(f\"Mean: {mean_val_mse:.4f}, Max: {max_val_mse:.4f}, Min: {min_val_mse:.4f}\")\n",
        "    \n",
        "#     return mean_val_mse  # Return mean validation MSE as the overall score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b67a4532-14bc-4590-90ed-d39044dfc6fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Prepare X and y\n",
        "# X = df_train.copy().drop(columns=['electricity_demand'], axis=1)\n",
        "# y = df_train.copy().pop('electricity_demand')\n",
        "\n",
        "# # Run the evaluation\n",
        "# evaluate_pipeline(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30e27e3b-7641-4107-be8c-50104d473cd9",
      "metadata": {},
      "source": [
        "### Generating Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49733a5-e2f6-4839-8063-2a6f5b2dfc28",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and submit your results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81488d3e-2dde-4904-ac69-430e55df0cc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Prepare X_train and y_train from your data\n",
        "# df_train =  pd.read_csv(\"module5_exercise_train.csv\", sep=\",\")\n",
        "\n",
        "# X_train = df_train.drop(columns=['electricity_demand'], axis=1)\n",
        "# y_train = df_train['electricity_demand']\n",
        "\n",
        "# X_test =  pd.read_csv(\"module5_exercise_test.csv\", sep=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f558b85-7970-4c24-95a8-fd6a37da930b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def train_and_predict_to_submit(X_train, y_train, X_test):\n",
        "#     model = LinearRegression()\n",
        "    \n",
        "#     X_train, y_train, X_test = handle_inconsistencies(X_train, y_train, X_test)\n",
        "#     X_train, y_train, X_test = handle_duplicates(X_train, y_train, X_test)\n",
        "#     X_train, X_test = handle_missing_values(X_train, y_train, X_test)\n",
        "#     X_train, X_test = handle_categorical(X_train, y_train, X_test)\n",
        "#     X_train, y_train, X_test = handle_outliers(X_train, y_train, X_test)\n",
        "#     X_train, y_train, X_test = feature_engineering(X_train, y_train, X_test)\n",
        "#     X_train, X_test = feature_selection(X_train, y_train, X_test)\n",
        "\n",
        "#     # Train the model on the entire training set\n",
        "#     print(f\"Training model on entire dataset of shape: {X_train.shape}\")\n",
        "#     model.fit(X_train, y_train)\n",
        "    \n",
        "#     # Predict on the test set\n",
        "#     print(f\"Predicting on test dataset of shape: {X_test.shape}\")\n",
        "#     y_test_pred = model.predict(X_test)\n",
        "    \n",
        "#     return y_test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44a7efc0-16fa-41f9-a8d9-6e90ba3c8bb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call serve_model to train and predict\n",
        "X_test_after_pocess=data_without_demand.drop(columns=['electricity_demand','date','weather_condition','oil_brent_price_indicator'])\n",
        "y_test_pred = model.predict(X_test_after_pocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "538cf936-7872-46ad-b02f-422a0aec3806",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generating Submission File\n",
        "submission = pd.DataFrame({\n",
        "    'date': data_without_demand['date'],\n",
        "    'electricity_demand': y_test_pred\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission.to_csv('submission.csv', index=False, sep=',')\n",
        "print(\"Submission file saved as 'submission.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4cd1a5",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "stat",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
