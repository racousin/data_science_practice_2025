{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32854d75-093f-46c0-8b84-1fe9c6c1bfa5",
      "metadata": {
        "id": "32854d75-093f-46c0-8b84-1fe9c6c1bfa5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "623f9a8c-e5e1-46a7-9dd1-1ef0e9cec868",
      "metadata": {
        "id": "623f9a8c-e5e1-46a7-9dd1-1ef0e9cec868"
      },
      "source": [
        "### Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac2bf4b-cce6-4f01-a906-21c6b83ee515",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cac2bf4b-cce6-4f01-a906-21c6b83ee515",
        "outputId": "57131edf-19c4-46c8-ba81-804288a5ff7e"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# URLs of the files\n",
        "train_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module3/exercise/module3_exercise_train.csv'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module3/exercise/module3_exercise_test.csv'\n",
        "\n",
        "# Function to download a file\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure we notice bad responses\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "# Downloading the files\n",
        "download_file(train_data_url, 'module3_exercise_train.csv')\n",
        "download_file(test_data_url, 'module3_exercise_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "923f12cb-09c7-4952-b9d3-faf1ff9ada52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "923f12cb-09c7-4952-b9d3-faf1ff9ada52",
        "outputId": "d0f7abd2-2810-4e5a-80d8-303b2f260839"
      },
      "outputs": [],
      "source": [
        "df_train =  pd.read_csv(\"module3_exercise_train.csv\", sep=\",\", index_col='id')\n",
        "df_test = pd.read_csv(\"module3_exercise_test.csv\", sep=\",\", index_col='id')\n",
        "print(\"训练数据形状:\", df_train.shape)\n",
        "print(\"测试数据形状:\", df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5a30503-71a9-44b4-aa3d-9673e52d3491",
      "metadata": {
        "id": "f5a30503-71a9-44b4-aa3d-9673e52d3491"
      },
      "source": [
        "### Data analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix\n",
        "import requests\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 设置中文显示（用于可能的文本内容）\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 修正下载函数和文件读取\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "# 下载文件\n",
        "train_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module3/exercise/module3_exercise_train.csv'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module3/exercise/module3_exercise_test.csv'\n",
        "\n",
        "download_file(train_data_url, 'module3_exercise_train.csv')\n",
        "download_file(test_data_url, 'module3_exercise_test.csv')\n",
        "\n",
        "# 修正读取代码\n",
        "df_train = pd.read_csv(\"module3_exercise_train.csv\", sep=\",\", index_col='id')\n",
        "df_test = pd.read_csv(\"module3_exercise_test.csv\", sep=\",\", index_col='id')\n",
        "\n",
        "print(\"Training data shape:\", df_train.shape)\n",
        "print(\"Test data shape:\", df_test.shape)\n",
        "\n",
        "# 英语单词转阿拉伯数字的函数\n",
        "def convert_word_to_number(word):\n",
        "    \"\"\"\n",
        "    将英语单词转换为阿拉伯数字\n",
        "    \"\"\"\n",
        "    if pd.isna(word):\n",
        "        return word\n",
        "\n",
        "    word_str = str(word).lower().strip()\n",
        "\n",
        "    # 定义映射字典\n",
        "    number_mapping = {\n",
        "        'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',\n",
        "        'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9',\n",
        "        'ten': '10', 'eleven': '11', 'twelve': '12',\n",
        "        'none': '0', 'no': '0', 'zero cars': '0'\n",
        "    }\n",
        "\n",
        "    # 尝试映射\n",
        "    if word_str in number_mapping:\n",
        "        return number_mapping[word_str]\n",
        "\n",
        "    # 如果已经是数字，直接返回\n",
        "    try:\n",
        "        float(word_str)\n",
        "        return word_str\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    return word  # 无法转换，返回原值\n",
        "\n",
        "def process_word_columns(df, word_columns=None):\n",
        "    \"\"\"\n",
        "    处理包含英语单词的列，将其转换为阿拉伯数字\n",
        "    \"\"\"\n",
        "    if word_columns is None:\n",
        "        # 自动检测可能包含英语数字的列\n",
        "        word_columns = []\n",
        "        for col in df.columns:\n",
        "            # 检查列中是否包含常见的英语数字单词\n",
        "            sample_values = df[col].dropna().astype(str).str.lower().unique()\n",
        "            english_numbers = ['zero', 'one', 'two', 'three', 'four', 'five',\n",
        "                             'six', 'seven', 'eight', 'nine', 'ten']\n",
        "            if any(any(word in str(val) for word in english_numbers) for val in sample_values[:10]):\n",
        "                word_columns.append(col)\n",
        "\n",
        "    for col in word_columns:\n",
        "        if col in df.columns:\n",
        "            print(f\"Processing column: {col}\")\n",
        "            print(f\"Before conversion unique values: {df[col].unique()}\")\n",
        "\n",
        "            # 应用转换\n",
        "            df[col] = df[col].apply(convert_word_to_number)\n",
        "\n",
        "            print(f\"After conversion unique values: {df[col].unique()}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 应用英语单词转换（特别处理garagecars列）\n",
        "print(\"\\n=== Processing English Words to Arabic Numbers ===\")\n",
        "\n",
        "# 明确指定要处理的列（包括garagecars）\n",
        "columns_to_convert = ['garagecars']  # 可以添加其他列名\n",
        "\n",
        "# 处理训练集\n",
        "df_train = process_word_columns(df_train, columns_to_convert)\n",
        "\n",
        "# 处理测试集\n",
        "df_test = process_word_columns(df_test, columns_to_convert)\n",
        "\n",
        "\n",
        "# Data Exploration Analysis\n",
        "print(\"\\n=== Basic Data Information ===\")\n",
        "print(\"First 5 rows of training data:\")\n",
        "print(df_train.head())\n",
        "\n",
        "print(\"\\nTraining data info:\")\n",
        "print(df_train.info())\n",
        "\n",
        "print(\"\\nDescriptive statistics:\")\n",
        "print(df_train.describe())\n",
        "\n",
        "print(\"\\nMissing values summary:\")\n",
        "print(df_train.isnull().sum())\n",
        "\n",
        "# Data Visualization Analysis\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# 1. Distribution of numerical variables\n",
        "numerical_cols = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if 'target' in numerical_cols:\n",
        "    numerical_cols.remove('target')\n",
        "\n",
        "n_numerical = len(numerical_cols)\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "if n_numerical > 0:\n",
        "    for col in numerical_cols[:min(5, len(numerical_cols))]:\n",
        "        sns.kdeplot(df_train[col], label=col, alpha=0.7)\n",
        "    plt.title('Distribution of Numerical Variables')\n",
        "    plt.legend()\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No numerical variables', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Distribution of Numerical Variables')\n",
        "\n",
        "# 2. Target variable analysis (if exists)\n",
        "if 'target' in df_train.columns:\n",
        "    plt.subplot(2, 2, 2)\n",
        "    if df_train['target'].dtype == 'object' or df_train['target'].nunique() < 10:\n",
        "        # Categorical target variable\n",
        "        df_train['target'].value_counts().plot(kind='bar')\n",
        "        plt.title('Target Variable Distribution (Classification)')\n",
        "        plt.xlabel('Categories')\n",
        "        plt.ylabel('Count')\n",
        "    else:\n",
        "        # Numerical target variable\n",
        "        sns.histplot(df_train['target'], kde=True)\n",
        "        plt.title('Target Variable Distribution (Regression)')\n",
        "        plt.xlabel('Target Values')\n",
        "        plt.ylabel('Frequency')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No target variable', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Target Variable Distribution')\n",
        "\n",
        "# 3. Correlation heatmap\n",
        "plt.subplot(2, 2, 3)\n",
        "numeric_df = df_train.select_dtypes(include=[np.number])\n",
        "if len(numeric_df.columns) > 1:\n",
        "    correlation_matrix = numeric_df.corr()\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "                fmt='.2f', linewidths=0.5)\n",
        "    plt.title('Correlation Heatmap')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'Insufficient numerical variables\\nfor correlation analysis',\n",
        "             ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Correlation Heatmap')\n",
        "\n",
        "# 4. Boxplot for outlier detection\n",
        "plt.subplot(2, 2, 4)\n",
        "if len(numerical_cols) > 0:\n",
        "    df_train[numerical_cols[:min(5, len(numerical_cols))]].boxplot()\n",
        "    plt.title('Boxplot of Numerical Variables (Outlier Detection)')\n",
        "    plt.xticks(rotation=45)\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No numerical variables', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Boxplot of Numerical Variables')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Categorical variables analysis (if exist)\n",
        "categorical_cols = df_train.select_dtypes(include=['object']).columns.tolist()\n",
        "if categorical_cols:\n",
        "    print(\"\\n=== Categorical Variables Analysis ===\")\n",
        "    for col in categorical_cols:\n",
        "        print(f\"\\nValue distribution for {col}:\")\n",
        "        print(df_train[col].value_counts())\n",
        "\n",
        "    # Categorical variables visualization\n",
        "    n_categorical = len(categorical_cols)\n",
        "    if n_categorical > 0:\n",
        "        fig, axes = plt.subplots(1, min(3, n_categorical), figsize=(15, 5))\n",
        "        if n_categorical == 1:\n",
        "            axes = [axes]\n",
        "        elif n_categorical == 0:\n",
        "            axes = []\n",
        "\n",
        "        for i, col in enumerate(categorical_cols[:3]):\n",
        "            if i < len(axes):\n",
        "                value_counts = df_train[col].value_counts()\n",
        "                # Show only top 10 categories if too many\n",
        "                if len(value_counts) > 10:\n",
        "                    value_counts = value_counts.head(10)\n",
        "                    axes[i].set_title(f'Distribution of {col} (Top 10)')\n",
        "                else:\n",
        "                    axes[i].set_title(f'Distribution of {col}')\n",
        "\n",
        "                value_counts.plot(kind='bar', ax=axes[i])\n",
        "                axes[i].set_xlabel('Categories')\n",
        "                axes[i].set_ylabel('Count')\n",
        "                axes[i].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Hide empty subplots\n",
        "        for j in range(i+1, len(axes)):\n",
        "            axes[j].set_visible(False)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Relationship analysis between variables and target (if target exists)\n",
        "if 'target' in df_train.columns:\n",
        "    print(\"\\n=== Relationship Analysis with Target Variable ===\")\n",
        "\n",
        "    # Numerical variables vs target\n",
        "    if df_train['target'].dtype in ['int64', 'float64'] and df_train['target'].nunique() > 10:\n",
        "        # Numerical target - scatter plots\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "        axes = axes.ravel()\n",
        "\n",
        "        for i, col in enumerate(numerical_cols[:min(6, len(numerical_cols))]):\n",
        "            axes[i].scatter(df_train[col], df_train['target'], alpha=0.5)\n",
        "            axes[i].set_xlabel(col)\n",
        "            axes[i].set_ylabel('Target Variable')\n",
        "            axes[i].set_title(f'{col} vs Target')\n",
        "\n",
        "        # Hide empty subplots\n",
        "        for j in range(i+1, len(axes)):\n",
        "            axes[j].set_visible(False)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    elif df_train['target'].dtype == 'object' or df_train['target'].nunique() <= 10:\n",
        "        # Categorical target - grouped analysis\n",
        "        if len(numerical_cols) > 0:\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "            axes = axes.ravel()\n",
        "\n",
        "            # Boxplot of numerical variables grouped by target\n",
        "            for i, col in enumerate(numerical_cols[:min(4, len(numerical_cols))]):\n",
        "                df_train.boxplot(column=col, by='target', ax=axes[i])\n",
        "                axes[i].set_title(f'{col} by Target')\n",
        "                axes[i].set_xlabel('Target Variable')\n",
        "                axes[i].set_ylabel(col)\n",
        "\n",
        "            # Hide empty subplots\n",
        "            for j in range(i+1, len(axes)):\n",
        "                axes[j].set_visible(False)\n",
        "\n",
        "            plt.suptitle('')  # Remove auto-generated title\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "# Data Quality Report\n",
        "print(\"\\n=== Data Quality Report ===\")\n",
        "print(f\"Total samples: {len(df_train)}\")\n",
        "print(f\"Total features: {len(df_train.columns)}\")\n",
        "print(f\"Numerical features: {len(numerical_cols)}\")\n",
        "print(f\"Categorical features: {len(categorical_cols)}\")\n",
        "\n",
        "if 'target' in df_train.columns:\n",
        "    print(f\"Target variable type: {df_train['target'].dtype}\")\n",
        "    if df_train['target'].dtype == 'object' or df_train['target'].nunique() <= 10:\n",
        "        print(\"Problem type: Classification\")\n",
        "        print(\"Class distribution:\")\n",
        "        target_counts = df_train['target'].value_counts()\n",
        "        for value, count in target_counts.items():\n",
        "            percentage = count / len(df_train) * 100\n",
        "            print(f\"  {value}: {count} samples ({percentage:.2f}%)\")\n",
        "    else:\n",
        "        print(\"Problem type: Regression\")\n",
        "        print(f\"Target range: {df_train['target'].min():.2f} - {df_train['target'].max():.2f}\")\n",
        "        print(f\"Target mean: {df_train['target'].mean():.2f}\")\n",
        "        print(f\"Target std: {df_train['target'].std():.2f}\")\n",
        "\n",
        "# Outlier Detection\n",
        "print(\"\\n=== Outlier Detection ===\")\n",
        "if len(numerical_cols) > 0:\n",
        "    outlier_summary = []\n",
        "    for col in numerical_cols:\n",
        "        Q1 = df_train[col].quantile(0.25)\n",
        "        Q3 = df_train[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        outliers = df_train[(df_train[col] < lower_bound) | (df_train[col] > upper_bound)]\n",
        "        outlier_percentage = len(outliers) / len(df_train) * 100\n",
        "        outlier_summary.append((col, len(outliers), outlier_percentage))\n",
        "        print(f\"{col}: {len(outliers)} outliers ({outlier_percentage:.2f}%)\")\n",
        "\n",
        "    # Outlier visualization\n",
        "    if outlier_summary:\n",
        "        outlier_df = pd.DataFrame(outlier_summary, columns=['Variable', 'Outlier Count', 'Outlier Percentage'])\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.barh(outlier_df['Variable'], outlier_df['Outlier Percentage'])\n",
        "        plt.xlabel('Outlier Percentage (%)')\n",
        "        plt.title('Outlier Percentage by Variable')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"No numerical variables for outlier detection\")\n",
        "\n",
        "print(\"\\nData analysis completed! Based on the above analysis, you can proceed with feature engineering and model building.\")\n",
        "\n",
        "# Save processed data (optional)\n",
        "df_train.to_csv('processed_train_data.csv', encoding='utf-8')\n",
        "df_test.to_csv('processed_test_data.csv', encoding='utf-8')\n",
        "print(\"Processed data saved as CSV files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o1bOwGIM4g7K",
        "outputId": "92c69929-9a79-4065-88b9-c8cd420413c5"
      },
      "id": "o1bOwGIM4g7K",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
