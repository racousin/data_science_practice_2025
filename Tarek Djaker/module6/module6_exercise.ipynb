{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Tarek Djaker notebook profile ---\nimport sys, os\nsys.path.append(r'C:\\Users\\pigio\\OneDrive\\Documents\\OneDrive\\Desktop\\projets\\data_science_practice_2025\\Tarek Djaker\\lib')\nfrom tarek_profile import nb_init, profile_banner\nnb_init()\nprofile_banner(title=None)\n# -------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fd09113-2f55-43ea-914c-ab3c0e3ee3d1",
      "metadata": {
        "id": "0fd09113-2f55-43ea-914c-ab3c0e3ee3d1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge, RidgeClassifier\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, BaggingRegressor, StackingRegressor, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.base import RegressorMixin, ClassifierMixin, BaseEstimator\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from lightgbm import LGBMClassifier, LGBMRegressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80dc69a1-e21d-4310-a0a4-5cb5b7d69fb4",
      "metadata": {
        "id": "80dc69a1-e21d-4310-a0a4-5cb5b7d69fb4"
      },
      "source": [
        "### Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae3aeb5-dcdf-4690-b869-d211a02f303c",
      "metadata": {
        "id": "fae3aeb5-dcdf-4690-b869-d211a02f303c",
        "outputId": "25776b23-3ae5-465d-d488-0c7a4f99d5ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# URLs of the files\n",
        "train_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module6/exercise/module6_exercise_train.csv'\n",
        "test_data_url = 'https://www.raphaelcousin.com/modules/data-science-practice/module6/exercise/module6_exercise_test.csv'\n",
        "\n",
        "# Function to download a file\n",
        "def download_file(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure we notice bad responses\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'Downloaded {file_name} from {url}')\n",
        "\n",
        "# Downloading the files\n",
        "download_file(train_data_url, 'module6_exercise_train.csv')\n",
        "download_file(test_data_url, 'module6_exercise_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83ae6bb0-639c-472a-8748-4bbbdb96e142",
      "metadata": {
        "id": "83ae6bb0-639c-472a-8748-4bbbdb96e142"
      },
      "outputs": [],
      "source": [
        "data_train = pd.read_csv('module6_exercise_train.csv', index_col='index')\n",
        "data_test = pd.read_csv('module6_exercise_test.csv', index_col='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea77dab9-6dcc-42bc-894b-1d8a23774d33",
      "metadata": {
        "id": "ea77dab9-6dcc-42bc-894b-1d8a23774d33"
      },
      "source": [
        "### Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a92c5579-a099-4018-a22e-06513a885133",
      "metadata": {
        "id": "a92c5579-a099-4018-a22e-06513a885133",
        "outputId": "a0205fa1-7df3-43db-8bba-6c03e58cf697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead6e347-8a41-489d-a184-98d4259ff9be",
      "metadata": {
        "id": "ead6e347-8a41-489d-a184-98d4259ff9be"
      },
      "outputs": [],
      "source": [
        "data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d62d9ab-50b9-4d5b-9611-adbd10840ae5",
      "metadata": {
        "id": "4d62d9ab-50b9-4d5b-9611-adbd10840ae5"
      },
      "outputs": [],
      "source": [
        "data_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5babb7-ad30-43eb-b3ec-4eebca726764",
      "metadata": {
        "id": "6b5babb7-ad30-43eb-b3ec-4eebca726764"
      },
      "outputs": [],
      "source": [
        "data_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e5dd21-1d73-415c-a4a7-c1c869ded46b",
      "metadata": {
        "id": "56e5dd21-1d73-415c-a4a7-c1c869ded46b"
      },
      "outputs": [],
      "source": [
        "data_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314189f7-31bb-47a9-afca-97d9ec489b60",
      "metadata": {
        "id": "314189f7-31bb-47a9-afca-97d9ec489b60"
      },
      "outputs": [],
      "source": [
        "# Plot the distribution using seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data_train['end_of_day_return'], bins=50, kde=True)\n",
        "plt.title('Distribution of End of Day Return')\n",
        "plt.xlabel('End of Day Return')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab85a4fe-b7d4-47f7-9d4a-4a155c44e24c",
      "metadata": {
        "id": "ab85a4fe-b7d4-47f7-9d4a-4a155c44e24c"
      },
      "source": [
        "### Model Building and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a86f0e4-55fa-46a9-8f53-735cf62aa6ff",
      "metadata": {
        "id": "6a86f0e4-55fa-46a9-8f53-735cf62aa6ff"
      },
      "outputs": [],
      "source": [
        "y = data_train.pop('end_of_day_return')\n",
        "X = data_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "746ed3ab-0de5-4c35-94aa-76251187dede",
      "metadata": {
        "id": "746ed3ab-0de5-4c35-94aa-76251187dede"
      },
      "outputs": [],
      "source": [
        "def weighted_accuracy(y_true, y_pred):\n",
        "    weights = np.abs(y_true)\n",
        "\n",
        "    # Compute the sign of true and predicted values\n",
        "    sign_true = np.sign(y_true)\n",
        "    sign_pred = np.sign(y_pred)\n",
        "\n",
        "    # Correct predictions where the sign of the true and predicted values match\n",
        "    correct_predictions = sign_true == sign_pred\n",
        "\n",
        "    # Compute the weighted accuracy\n",
        "    weighted_acc = np.sum(weights * correct_predictions) / np.sum(weights)\n",
        "\n",
        "    return weighted_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04424025-b909-46d3-af2d-0e7d6fb9107b",
      "metadata": {
        "id": "04424025-b909-46d3-af2d-0e7d6fb9107b"
      },
      "outputs": [],
      "source": [
        "# Function to plot the evaluation results\n",
        "def plot_results(mse_train, mse_test, w_acc_train, w_acc_test):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # MSE plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(mse_train, label=\"Train MSE\", marker='o')\n",
        "    plt.plot(mse_test, label=\"Test MSE\", marker='o')\n",
        "    plt.fill_between(range(len(mse_train)), np.min(mse_train), np.max(mse_train), color='blue', alpha=0.1)\n",
        "    plt.fill_between(range(len(mse_test)), np.min(mse_test), np.max(mse_test), color='orange', alpha=0.1)\n",
        "    plt.title(\"MSE over Folds\")\n",
        "    plt.xlabel(\"Fold\")\n",
        "    plt.ylabel(\"MSE\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # weighted_accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(w_acc_train, label=\"Train weighted_accuracy\", marker='o')\n",
        "    plt.plot(w_acc_test, label=\"Test weighted_accuracy\", marker='o')\n",
        "    plt.fill_between(range(len(w_acc_train)), np.min(w_acc_train), np.max(w_acc_train), color='blue', alpha=0.1)\n",
        "    plt.fill_between(range(len(w_acc_test)), np.min(w_acc_test), np.max(w_acc_test), color='orange', alpha=0.1)\n",
        "    plt.title(\"weighted_accuracy over Folds\")\n",
        "    plt.xlabel(\"Fold\")\n",
        "    plt.ylabel(\"weighted_accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_multi_model_results(results):\n",
        "    # Set up the plot\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 20))\n",
        "\n",
        "    # Colors for train and test\n",
        "    train_color = 'skyblue'\n",
        "    test_color = 'lightgreen'\n",
        "\n",
        "    # Plot MSE\n",
        "    ax1.set_title('Mean Squared Error (MSE) Comparison', fontsize=16)\n",
        "    ax1.set_ylabel('MSE', fontsize=12)\n",
        "    ax1.set_xlabel('Models', fontsize=12)\n",
        "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Plot weighted_accuracy\n",
        "    ax2.set_title('weighted_accuracy Comparison', fontsize=16)\n",
        "    ax2.set_ylabel('weighted_accuracy', fontsize=12)\n",
        "    ax2.set_xlabel('Models', fontsize=12)\n",
        "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    x = np.arange(len(results))\n",
        "    width = 0.35\n",
        "\n",
        "    for i, (model_name, scores) in enumerate(results.items()):\n",
        "        # MSE\n",
        "        mse_train = scores['mse_train']\n",
        "        mse_test = scores['mse_test']\n",
        "\n",
        "        ax1.bar(x[i] - width/2, np.mean(mse_train), width, label='Train' if i == 0 else \"\",\n",
        "                color=train_color, alpha=0.7)\n",
        "        ax1.bar(x[i] + width/2, np.mean(mse_test), width, label='Test' if i == 0 else \"\",\n",
        "                color=test_color, alpha=0.7)\n",
        "\n",
        "        ax1.errorbar(x[i] - width/2, np.mean(mse_train),\n",
        "                     yerr=[[np.mean(mse_train)-np.min(mse_train)], [np.max(mse_train)-np.mean(mse_train)]],\n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "        ax1.errorbar(x[i] + width/2, np.mean(mse_test),\n",
        "                     yerr=[[np.mean(mse_test)-np.min(mse_test)], [np.max(mse_test)-np.mean(mse_test)]],\n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "\n",
        "        # weighted_accuracy\n",
        "        w_acc_train = scores['w_acc_train']\n",
        "        w_acc_test = scores['w_acc_test']\n",
        "\n",
        "        ax2.bar(x[i] - width/2, np.mean(w_acc_train), width, label='Train' if i == 0 else \"\",\n",
        "                color=train_color, alpha=0.7)\n",
        "        ax2.bar(x[i] + width/2, np.mean(w_acc_test), width, label='Test' if i == 0 else \"\",\n",
        "                color=test_color, alpha=0.7)\n",
        "\n",
        "        ax2.errorbar(x[i] - width/2, np.mean(w_acc_train),\n",
        "                     yerr=[[np.mean(w_acc_train)-np.min(w_acc_train)], [np.max(w_acc_train)-np.mean(w_acc_train)]],\n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "        ax2.errorbar(x[i] + width/2, np.mean(w_acc_test),\n",
        "                     yerr=[[np.mean(w_acc_test)-np.min(w_acc_test)], [np.max(w_acc_test)-np.mean(w_acc_test)]],\n",
        "                     fmt='none', ecolor='black', capsize=5)\n",
        "\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(results.keys(), rotation=45, ha='right')\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels(results.keys(), rotation=45, ha='right')\n",
        "\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax2.legend(loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6c73c55-9684-411c-9ad3-ba6f9ba7de8d",
      "metadata": {
        "id": "f6c73c55-9684-411c-9ad3-ba6f9ba7de8d"
      },
      "source": [
        "#### Simple Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d6a7f41-1184-4172-ab8b-220f45ab2172",
      "metadata": {
        "id": "3d6a7f41-1184-4172-ab8b-220f45ab2172"
      },
      "outputs": [],
      "source": [
        "# Function to handle train-test evaluation in a fold\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test, model):\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on train set\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    # Make predictions on train set\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Compute MSE for train and test\n",
        "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "    # Compute weighted_accuracy\n",
        "\n",
        "    w_acc_train = weighted_accuracy(y_train, y_pred_train)\n",
        "    w_acc_test = weighted_accuracy(y_test, y_pred_test)\n",
        "\n",
        "    return mse_train, mse_test, w_acc_train, w_acc_test\n",
        "\n",
        "\n",
        "def run_multi_model_cv(X, y, models, n_splits=5):\n",
        "    fold = KFold(n_splits=n_splits)\n",
        "    results = {name: {'mse_train': [], 'mse_test': [], 'w_acc_train': [], 'w_acc_test': []}\n",
        "               for name in models.keys()}\n",
        "\n",
        "    for train_index, test_index in fold.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
        "        y_train, y_test = y.iloc[train_index].copy(), y.iloc[test_index].copy()\n",
        "\n",
        "        for name, model in models.items():\n",
        "            mse_train, mse_test, w_acc_train, w_acc_test = train_and_evaluate(\n",
        "                X_train, X_test, y_train, y_test, model\n",
        "            )\n",
        "            results[name]['mse_train'].append(mse_train)\n",
        "            results[name]['mse_test'].append(mse_test)\n",
        "            results[name]['w_acc_train'].append(w_acc_train)\n",
        "            results[name]['w_acc_test'].append(w_acc_test)\n",
        "        # Find the model with the best mean w_acc test score\n",
        "    best_mean_w_acc = -1\n",
        "    best_model = None\n",
        "    best_min_w_acc = None\n",
        "    best_max_w_acc = None\n",
        "\n",
        "    for name, result in results.items():\n",
        "        w_acc_test_scores = result['w_acc_test']\n",
        "        mean_w_acc_test = sum(w_acc_test_scores) / len(w_acc_test_scores)  # Calculate mean w_acc score\n",
        "        min_w_acc_test = min(w_acc_test_scores)  # Minimum w_acc score\n",
        "        max_w_acc_test = max(w_acc_test_scores)  # Maximum w_acc score\n",
        "\n",
        "        if mean_w_acc_test > best_mean_w_acc:\n",
        "            best_mean_w_acc = mean_w_acc_test\n",
        "            best_min_w_acc = min_w_acc_test\n",
        "            best_max_w_acc = max_w_acc_test\n",
        "            best_model = name\n",
        "\n",
        "    # Print the best mean w_acc test score, min, max, and the associated model\n",
        "    print(f\"Best mean w_acc test score: {best_mean_w_acc:.4f} by model: {best_model}\")\n",
        "    print(f\"Min w_acc test score: {best_min_w_acc:.4f}, Max w_acc test score: {best_max_w_acc:.4f}\")\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891e158b-b199-41ac-a244-537429eb1d22",
      "metadata": {
        "id": "891e158b-b199-41ac-a244-537429eb1d22",
        "outputId": "28df7dbe-c354-4c24-f227-b1346bf15bff"
      },
      "outputs": [],
      "source": [
        "# Step 1: Run cross-validation\n",
        "results = run_multi_model_cv(X, y, {\"RandomForestRegressor\": RandomForestRegressor(n_jobs=-1)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b0380d-c7ee-413e-9b13-756f8e7e3847",
      "metadata": {
        "id": "34b0380d-c7ee-413e-9b13-756f8e7e3847",
        "outputId": "2e545863-7661-4a15-9308-713558d4ab3c"
      },
      "outputs": [],
      "source": [
        "# Step 2: Plot the results\n",
        "plot_results(results[\"RandomForestRegressor\"][\"mse_train\"],\n",
        "             results[\"RandomForestRegressor\"][\"mse_test\"],\n",
        "             results[\"RandomForestRegressor\"][\"w_acc_train\"],\n",
        "             results[\"RandomForestRegressor\"][\"w_acc_test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc76e0a4-6af0-43eb-af13-0bad0adbbdbd",
      "metadata": {
        "id": "bc76e0a4-6af0-43eb-af13-0bad0adbbdbd"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Lasso': Lasso(),\n",
        "    'Ridge': Ridge(),\n",
        "    'Decision Tree Regressor_': DecisionTreeRegressor(),\n",
        "    'Ridge': Ridge(),\n",
        "    'Decision Tree Regressor': RandomForestRegressor(n_jobs=-1)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "264692a5-ce69-4567-a108-669d0cfcc3a1",
      "metadata": {
        "id": "264692a5-ce69-4567-a108-669d0cfcc3a1",
        "outputId": "d7c4fa3b-50d9-45a4-d29f-3d8ff38d8f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [],
      "source": [
        "# Run cross-validation for regression models\n",
        "results = run_multi_model_cv(X, y, models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250f1f68-32b7-47d3-8934-952785a3046f",
      "metadata": {
        "id": "250f1f68-32b7-47d3-8934-952785a3046f",
        "outputId": "4da76328-4707-456b-ff1a-e81d86cda3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [],
      "source": [
        "# Plot MSE results for regression models\n",
        "plot_multi_model_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0e21e12-8f5d-4fe5-beb0-566d8a971ae7",
      "metadata": {
        "id": "b0e21e12-8f5d-4fe5-beb0-566d8a971ae7"
      },
      "source": [
        "#### Manage properly the objective weighted_accuracy\n",
        "should we create different classes? custom loss?\n",
        "\n",
        "Create Compare and Optimize different models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0431ff6-0e5d-4ead-8735-84e1a728ef11",
      "metadata": {
        "id": "f0431ff6-0e5d-4ead-8735-84e1a728ef11"
      },
      "source": [
        "### Submission:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe4a5d9-be2e-40f1-b1b4-59cac5e7197b",
      "metadata": {
        "id": "dbe4a5d9-be2e-40f1-b1b4-59cac5e7197b"
      },
      "outputs": [],
      "source": [
        "data_train = pd.read_csv('module6_exercise_train.csv', index_col='index')\n",
        "X_test = pd.read_csv('module6_exercise_test.csv', index_col='index')\n",
        "y_train = data_train.pop('end_of_day_return')\n",
        "X_train = data_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db2ea4cd-5463-41ac-b49a-6ec38252b5b6",
      "metadata": {
        "id": "db2ea4cd-5463-41ac-b49a-6ec38252b5b6",
        "outputId": "ef9e7253-d157-40f9-d521-42ff32df7259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [],
      "source": [
        "wei = [30,50,100, 500, 750, 1000, 1250]\n",
        "l1_ratio_value = 0.5\n",
        "\n",
        "try:\n",
        "    from sklearn.linear_model import ElasticNet\n",
        "except ImportError:\n",
        "    class ElasticNet:\n",
        "        def __init__(self, alpha, l1_ratio):\n",
        "            self.alpha = alpha\n",
        "            self.l1_ratio = l1_ratio\n",
        "\n",
        "elastic_net_models = {}\n",
        "\n",
        "for w in wei:\n",
        "    name = f\"elasticnet_alpha{w}_l1ratio{l1_ratio_value}\"\n",
        "    elastic_net_models[name] = ElasticNet(alpha=w, l1_ratio=l1_ratio_value)\n",
        "\n",
        "print(\"--- Dictionnaire des modèles Elastic Net créés ---\")\n",
        "for k, v in list(elastic_net_models.items()):\n",
        "    print(k, \":\", v)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from scipy.stats import randint as sp_randint, uniform as sp_uniform\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "except ImportError:\n",
        "    class XGBRegressor:\n",
        "        def __init__(self, random_state, n_jobs, objective, tree_method):\n",
        "            self.random_state = random_state\n",
        "            self.n_jobs = n_jobs\n",
        "            self.objective = objective\n",
        "            self.tree_method = tree_method\n",
        "        def fit(self, X, y): pass\n",
        "        def predict(self, X): return np.zeros(len(X))\n",
        "\n",
        "try:\n",
        "    pass\n",
        "except ImportError:\n",
        "    X = pd.DataFrame(np.random.rand(200, 10))\n",
        "    y = pd.Series(np.random.rand(200) * 10)\n",
        "    def weighted_accuracy(y_true, y_pred):\n",
        "        if np.var(y_true) == 0: return 0.0\n",
        "        return 1.0 - mean_squared_error(y_true, y_pred) / np.var(y_true)\n",
        "\n",
        "w_acc_scorer = make_scorer(weighted_accuracy, greater_is_better=True)\n",
        "\n",
        "xgb_model = XGBRegressor(\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    objective='reg:squarederror',\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators': sp_randint(100, 1000),\n",
        "    'learning_rate': sp_uniform(0.005, 0.2),\n",
        "    'max_depth': sp_randint(3, 15),\n",
        "    'min_child_weight': sp_randint(1, 10),\n",
        "    'colsample_bytree': sp_uniform(0.5, 0.4),\n",
        "    'subsample': sp_uniform(0.6, 0.3),\n",
        "    'reg_alpha': sp_uniform(0.001, 0.2),\n",
        "    'reg_lambda': sp_uniform(0.001, 0.2)\n",
        "}\n",
        "\n",
        "cv_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=50,\n",
        "    scoring=w_acc_scorer,\n",
        "    cv=cv_fold,\n",
        "    verbose=0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "tVqCIuFRPe-3"
      },
      "id": "tVqCIuFRPe-3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_results = run_multi_model_cv(X, y, elastic_net_models)"
      ],
      "metadata": {
        "id": "_rbB1aHNpgiB",
        "outputId": "a7ff5156-8367-41e1-d24d-e6c23ebbb6ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_rbB1aHNpgiB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = best_xgb_model\n",
        "best_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "QbghYix_rDFr",
        "outputId": "80c23ff8-e2af-41af-9ca0-3505c6fd6051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "id": "QbghYix_rDFr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9877df-0e30-40ed-91a0-69511d359033",
      "metadata": {
        "id": "ac9877df-0e30-40ed-91a0-69511d359033"
      },
      "outputs": [],
      "source": [
        "\n",
        "submission = pd.DataFrame({\n",
        "    'index': X_test.index,\n",
        "    'end_of_day_return':  best_model.predict(X_test)\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False, sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d162216-2f3a-4d63-bbbb-66f0a4ce6bcb",
      "metadata": {
        "id": "1d162216-2f3a-4d63-bbbb-66f0a4ce6bcb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
